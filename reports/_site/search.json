[
  {
    "objectID": "02_unit_tests.html",
    "href": "02_unit_tests.html",
    "title": "Unit Test Coverage",
    "section": "",
    "text": "NoteStatus: Not Started\n\n\n\nThis report is a placeholder. Content will be added as the test documentation is developed."
  },
  {
    "objectID": "02_unit_tests.html#coverage-summary",
    "href": "02_unit_tests.html#coverage-summary",
    "title": "Unit Test Coverage",
    "section": "1. Coverage Summary",
    "text": "1. Coverage Summary\n\nOverall Statistics\n\n\n\nMetric\nValue\n\n\n\n\nTotal Test Files\n-\n\n\nTotal Test Cases\n-\n\n\nPassing\n-\n\n\nFailing\n-\n\n\nCoverage %\n-\n\n\n\n\n\nCoverage by Module\n\n\n\nModule\nTests\nCoverage\n\n\n\n\nHazard\n-\n-\n\n\nLikelihood\n-\n-\n\n\nSimulation\n-\n-\n\n\nInference\n-\n-\n\n\nSplines\n-\n-\n\n\nPhase-Type\n-\n-"
  },
  {
    "objectID": "02_unit_tests.html#hazard-functions",
    "href": "02_unit_tests.html#hazard-functions",
    "title": "Unit Test Coverage",
    "section": "2. Hazard Functions",
    "text": "2. Hazard Functions\n\nTest Summary\n\n\n\nFunction\nTest File\nCondition\nStatus\n\n\n\n\neval_hazard (Exp)\ntest_hazards.jl\nBaseline\n⏳\n\n\neval_hazard (Wei)\ntest_hazards.jl\nBaseline\n⏳\n\n\neval_hazard (Gom)\ntest_hazards.jl\nBaseline\n⏳\n\n\neval_cumhaz (Exp)\ntest_hazards.jl\nWith covariate\n⏳\n\n\neval_cumhaz (Wei)\ntest_hazards.jl\nAFT effect\n⏳\n\n\neval_cumhaz (Gom)\ntest_hazards.jl\nPH effect\n⏳\n\n\n\n\n\nValidation Approach\nTo be documented"
  },
  {
    "objectID": "02_unit_tests.html#likelihood-functions",
    "href": "02_unit_tests.html#likelihood-functions",
    "title": "Unit Test Coverage",
    "section": "3. Likelihood Functions",
    "text": "3. Likelihood Functions\n\nTest Summary\n\n\n\n\n\n\n\n\n\nFunction\nTest File\nCondition\nStatus\n\n\n\n\nloglik_path\ntest_mll_consistency.jl\nExact observation\n⏳\n\n\nloglik\ntest_mll_consistency.jl\nPanel data\n⏳\n\n\ntvc_loglik\ntest_reversible_tvc_loglik.jl\nTime-varying covariates\n⏳\n\n\n\n\n\nValidation Approach\nTo be documented"
  },
  {
    "objectID": "02_unit_tests.html#simulation",
    "href": "02_unit_tests.html#simulation",
    "title": "Unit Test Coverage",
    "section": "4. Simulation",
    "text": "4. Simulation\n\nTest Summary\n\n\n\nFunction\nTest File\nCondition\nStatus\n\n\n\n\nsimulate_path\ntest_simulation.jl\nSingle subject\n⏳\n\n\nsimulate\ntest_simulation.jl\nMultiple subjects\n⏳\n\n\n\n\n\nValidation Approach\nTo be documented"
  },
  {
    "objectID": "02_unit_tests.html#model-construction",
    "href": "02_unit_tests.html#model-construction",
    "title": "Unit Test Coverage",
    "section": "5. Model Construction",
    "text": "5. Model Construction\n\nTest Summary\n\n\n\n\n\n\n\n\n\nFunction\nTest File\nCondition\nStatus\n\n\n\n\nmultistatemodel\ntest_modelgeneration.jl\nBasic model\n⏳\n\n\nHazard\ntest_hazards.jl\nAll families\n⏳\n\n\nset_parameters!\ntest_initialization.jl\nParameter setting\n⏳\n\n\n\n\n\nValidation Approach\nTo be documented"
  },
  {
    "objectID": "02_unit_tests.html#splines-penalization",
    "href": "02_unit_tests.html#splines-penalization",
    "title": "Unit Test Coverage",
    "section": "6. Splines & Penalization",
    "text": "6. Splines & Penalization\n\nTest Summary\n\n\n\nFunction\nTest File\nCondition\nStatus\n\n\n\n\nB-spline basis\ntest_splines.jl\nEvaluation\n⏳\n\n\nPenalty matrix\ntest_splines.jl\nSecond derivative\n⏳\n\n\n\n\n\nValidation Approach\nTo be documented"
  },
  {
    "objectID": "02_unit_tests.html#phase-type-models",
    "href": "02_unit_tests.html#phase-type-models",
    "title": "Unit Test Coverage",
    "section": "7. Phase-Type Models",
    "text": "7. Phase-Type Models\n\nTest Summary\n\n\n\nFunction\nTest File\nCondition\nStatus\n\n\n\n\nExpansion\ntest_phasetype.jl\nState expansion\n⏳\n\n\nCollapse\ntest_phasetype.jl\nState collapse\n⏳\n\n\nFFBS\ntest_phasetype.jl\nForward-backward\n⏳\n\n\n\n\n\nValidation Approach\nTo be documented"
  },
  {
    "objectID": "02_unit_tests.html#helpers-utilities",
    "href": "02_unit_tests.html#helpers-utilities",
    "title": "Unit Test Coverage",
    "section": "8. Helpers & Utilities",
    "text": "8. Helpers & Utilities\n\nTest Summary\n\n\n\nFunction\nTest File\nCondition\nStatus\n\n\n\n\nextract_covariates\ntest_helpers.jl\nCovariate extraction\n⏳\n\n\nget_hazard_params\ntest_helpers.jl\nParameter retrieval\n⏳\n\n\n\n\n\nValidation Approach\nTo be documented"
  },
  {
    "objectID": "simulation_diagnostics.html",
    "href": "simulation_diagnostics.html",
    "title": "Simulation Diagnostics",
    "section": "",
    "text": "This report validates that MultistateModels.jl correctly simulates event times by comparing:\n\nEmpirical CDFs of simulated event times against theoretical CDFs\nHazard functions computed by the package against analytical formulas\nCumulative hazard functions computed vs. expected\n\nFor each hazard family (Exponential, Weibull, Gompertz) and covariate effect type (PH, AFT), we: - Simulate many event times from a 2-state model - Compare the empirical distribution to the theoretical distribution - Report the maximum absolute difference in CDF (should be ≈ 0)"
  },
  {
    "objectID": "simulation_diagnostics.html#overview",
    "href": "simulation_diagnostics.html#overview",
    "title": "Simulation Diagnostics",
    "section": "",
    "text": "This report validates that MultistateModels.jl correctly simulates event times by comparing:\n\nEmpirical CDFs of simulated event times against theoretical CDFs\nHazard functions computed by the package against analytical formulas\nCumulative hazard functions computed vs. expected\n\nFor each hazard family (Exponential, Weibull, Gompertz) and covariate effect type (PH, AFT), we: - Simulate many event times from a 2-state model - Compare the empirical distribution to the theoretical distribution - Report the maximum absolute difference in CDF (should be ≈ 0)"
  },
  {
    "objectID": "simulation_diagnostics.html#configuration",
    "href": "simulation_diagnostics.html#configuration",
    "title": "Simulation Diagnostics",
    "section": "Configuration",
    "text": "Configuration\n\n\nShow code\nconst COVARIATE_VALUE = 1.5\nconst SIM_SAMPLES = 40_000\nconst DIST_GRID_POINTS = 400\n\n# Horizons must be large enough to ensure negligible right-truncation (&lt;0.1%)\n# For Exponential with AFT covariates: effective rate = 0.35 * exp(-0.6*1.5) ≈ 0.14\n# Need: exp(-rate * horizon) &lt; 0.001 =&gt; horizon &gt; log(1000)/rate ≈ 50\n# Setting horizon = 100 provides ample margin\nconst FAMILY_CONFIG = Dict(\n    \"exp\" =&gt; (; rate = 0.35, beta = 0.6, horizon = 100.0),\n    \"wei\" =&gt; (; shape = 1.35, scale = 0.4, beta = -0.35, horizon = 50.0),\n    \"gom\" =&gt; (; shape = 0.6, rate = 0.4, beta = 0.5, horizon = 10.0),  # Gompertz diverges quickly\n)\n\n\nDict{String, NamedTuple} with 3 entries:\n  \"exp\" =&gt; (rate = 0.35, beta = 0.6, horizon = 100.0)\n  \"wei\" =&gt; (shape = 1.35, scale = 0.4, beta = -0.35, horizon = 50.0)\n  \"gom\" =&gt; (shape = 0.6, rate = 0.4, beta = 0.5, horizon = 10.0)"
  },
  {
    "objectID": "simulation_diagnostics.html#analytical-reference-formulas",
    "href": "simulation_diagnostics.html#analytical-reference-formulas",
    "title": "Simulation Diagnostics",
    "section": "Analytical Reference Formulas",
    "text": "Analytical Reference Formulas\n\nExponential Distribution\n\nHazard: \\(h(t) = \\lambda\\)\nCumulative hazard: \\(H(t) = \\lambda t\\)\nCDF: \\(F(t) = 1 - e^{-\\lambda t}\\)\n\n\n\nWeibull Distribution (shape \\(\\kappa\\), scale \\(\\lambda\\))\n\nHazard: \\(h(t) = \\kappa \\lambda t^{\\kappa-1}\\)\nCumulative hazard: \\(H(t) = \\lambda t^\\kappa\\)\nCDF: \\(F(t) = 1 - e^{-\\lambda t^\\kappa}\\)\n\n\n\nGompertz Distribution (flexsurv parameterization: shape \\(a\\), rate \\(b\\))\n\nHazard: \\(h(t) = b e^{at}\\)\nCumulative hazard: \\(H(t) = \\frac{b}{a}(e^{at} - 1)\\)\nCDF: \\(F(t) = 1 - e^{-H(t)}\\)\n\n\n\nCovariate Effects\nProportional Hazards (PH): \\(h(t|x) = h_0(t) e^{\\beta x}\\)\nAccelerated Failure Time (AFT): \\(h(t|x) = h_0(t \\cdot e^{-\\beta x}) \\cdot e^{-\\beta x}\\)"
  },
  {
    "objectID": "simulation_diagnostics.html#helper-functions",
    "href": "simulation_diagnostics.html#helper-functions",
    "title": "Simulation Diagnostics",
    "section": "Helper Functions",
    "text": "Helper Functions\n\n\nShow code\n# Create a 2-state model for a given scenario\nfunction build_test_model(family::String, effect::Symbol, with_covariate::Bool)\n    cfg = FAMILY_CONFIG[family]\n    \n    # Build data frame\n    if with_covariate\n        data = DataFrame(\n            id = [1], tstart = [0.0], tstop = [cfg.horizon],\n            statefrom = [1], stateto = [2], obstype = [1],\n            x = [COVARIATE_VALUE]\n        )\n        formula = @formula(0 ~ x)\n    else\n        data = DataFrame(\n            id = [1], tstart = [0.0], tstop = [cfg.horizon],\n            statefrom = [1], stateto = [2], obstype = [1]\n        )\n        formula = @formula(0 ~ 1)\n    end\n    \n    # Build hazard\n    hazard = Hazard(formula, family, 1, 2; linpred_effect = effect)\n    model = multistatemodel(hazard; data = data)\n    \n    # Set parameters\n    if family == \"exp\"\n        base = [log(cfg.rate)]\n    elseif family == \"wei\"\n        base = [log(cfg.shape), log(cfg.scale)]\n    elseif family == \"gom\"\n        base = [cfg.shape, log(cfg.rate)]  # shape unconstrained, rate log-transformed\n    end\n    \n    pars = with_covariate ? vcat(base, [cfg.beta]) : base\n    hazname = model.hazards[1].hazname\n    set_parameters!(model, NamedTuple{(hazname,)}((pars,)))\n    \n    return model, cfg\nend\n\n# Compute expected CDF for given scenario\nfunction expected_cdf(family::String, effect::Symbol, with_covariate::Bool, t::Float64)\n    cfg = FAMILY_CONFIG[family]\n    xval = with_covariate ? COVARIATE_VALUE : 0.0\n    beta = with_covariate ? cfg.beta : 0.0\n    \n    cumhaz = if family == \"exp\"\n        rate = effect == :ph ? cfg.rate * exp(beta * xval) : cfg.rate * exp(-beta * xval)\n        rate * t\n    elseif family == \"wei\"\n        shape, scale = cfg.shape, cfg.scale\n        mult = effect == :ph ? exp(beta * xval) : exp(-shape * beta * xval)\n        scale * mult * (t^shape)\n    elseif family == \"gom\"\n        shape, rate = cfg.shape, cfg.rate\n        linpred = beta * xval\n        if effect == :ph\n            (rate / shape) * exp(linpred) * (exp(shape * t) - 1)\n        else\n            time_scale = exp(-linpred)\n            scaled_shape = shape * time_scale\n            scaled_rate = rate * time_scale\n            (scaled_rate / scaled_shape) * (exp(scaled_shape * t) - 1)\n        end\n    end\n    \n    return 1 - exp(-cumhaz)\nend\n\n# Simulate event times from model\n# WARNING: Only collects paths where a transition occurred within horizon.\n# Set horizon large enough so P(T &gt; horizon) &lt; 0.001 to avoid right-truncation bias.\nfunction simulate_event_times(model, nsim::Int; rng = Random.default_rng())\n    durations = Float64[]\n    n_censored = 0\n    strategy = CachedTransformStrategy()\n    total_attempts = 0\n    max_attempts = nsim * 20  # Safety limit\n    \n    while length(durations) &lt; nsim && total_attempts &lt; max_attempts\n        total_attempts += 1\n        path = simulate_path(model, 1; strategy = strategy, rng = rng)\n        if path.states[end] != path.states[1]\n            push!(durations, path.times[end] - path.times[1])\n        else\n            n_censored += 1\n        end\n    end\n    \n    # Warn if significant truncation detected\n    truncation_rate = n_censored / total_attempts\n    if truncation_rate &gt; 0.01\n        @warn \"High right-truncation rate: $(round(truncation_rate*100, digits=1))%. Increase horizon.\"\n    end\n    \n    return durations\nend\n\n# Compute maximum CDF difference\nfunction max_cdf_diff(durations::Vector{Float64}, cdf_func, horizon::Float64)\n    # Compute empirical CDF\n    sorted = sort(durations)\n    n = length(sorted)\n    ecdf_vals = (1:n) ./ n\n    \n    # Compute theoretical CDF at each point\n    tcdf_vals = [cdf_func(t) for t in sorted]\n    \n    # Max absolute difference\n    return maximum(abs.(ecdf_vals .- tcdf_vals))\nend\n\n\nmax_cdf_diff (generic function with 1 method)"
  },
  {
    "objectID": "simulation_diagnostics.html#diagnostic-results",
    "href": "simulation_diagnostics.html#diagnostic-results",
    "title": "Simulation Diagnostics",
    "section": "Diagnostic Results",
    "text": "Diagnostic Results\n\n\nShow code\n# Run diagnostics for all scenarios\nresults = DataFrame(\n    Family = String[],\n    Effect = String[],\n    Covariate = String[],\n    MaxCDFDiff = Float64[],\n    Status = String[]\n)\n\nscenarios = [\n    (\"exp\", :ph, false), (\"exp\", :ph, true),\n    (\"exp\", :aft, false), (\"exp\", :aft, true),\n    (\"wei\", :ph, false), (\"wei\", :ph, true),\n    (\"wei\", :aft, false), (\"wei\", :aft, true),\n    (\"gom\", :ph, false), (\"gom\", :ph, true),\n    (\"gom\", :aft, false), (\"gom\", :aft, true),\n]\n\nRandom.seed!(12345)\n\nfor (family, effect, with_cov) in scenarios\n    model, cfg = build_test_model(family, effect, with_cov)\n    \n    # Simulate event times\n    durations = simulate_event_times(model, SIM_SAMPLES)\n    \n    # Expected CDF function\n    cdf_func = t -&gt; expected_cdf(family, effect, with_cov, t)\n    \n    # Compute max difference\n    max_diff = max_cdf_diff(durations, cdf_func, cfg.horizon)\n    \n    push!(results, (\n        uppercasefirst(family),\n        uppercase(String(effect)),\n        with_cov ? \"Yes\" : \"No\",\n        round(max_diff, digits=4),\n        max_diff &lt; 0.02 ? \"✅ Pass\" : \"❌ Fail\"\n    ))\nend\n\nresults\n\n\n\n******************************************************************************\nThis program contains Ipopt, a library for large-scale nonlinear optimization.\n Ipopt is released as open source code under the Eclipse Public License (EPL).\n         For more information visit https://github.com/coin-or/Ipopt\n******************************************************************************\n\n\n\n\n\nTable 1: Simulation Diagnostic Summary\n\n\n\n12×5 DataFrame\n\n\n\nRow\nFamily\nEffect\nCovariate\nMaxCDFDiff\nStatus\n\n\n\nString\nString\nString\nFloat64\nString\n\n\n\n\n1\nExp\nPH\nNo\n0.0042\n✅ Pass\n\n\n2\nExp\nPH\nYes\n0.0034\n✅ Pass\n\n\n3\nExp\nAFT\nNo\n0.0039\n✅ Pass\n\n\n4\nExp\nAFT\nYes\n0.0042\n✅ Pass\n\n\n5\nWei\nPH\nNo\n0.0063\n✅ Pass\n\n\n6\nWei\nPH\nYes\n0.0035\n✅ Pass\n\n\n7\nWei\nAFT\nNo\n0.0063\n✅ Pass\n\n\n8\nWei\nAFT\nYes\n0.0031\n✅ Pass\n\n\n9\nGom\nPH\nNo\n0.0088\n✅ Pass\n\n\n10\nGom\nPH\nYes\n0.0045\n✅ Pass\n\n\n11\nGom\nAFT\nNo\n0.0054\n✅ Pass\n\n\n12\nGom\nAFT\nYes\n0.0046\n✅ Pass"
  },
  {
    "objectID": "simulation_diagnostics.html#diagnostic-plots",
    "href": "simulation_diagnostics.html#diagnostic-plots",
    "title": "Simulation Diagnostics",
    "section": "Diagnostic Plots",
    "text": "Diagnostic Plots\n\nExponential Distribution\n\n\nShow code\nfig = Figure(size=(900, 700))\n\nRandom.seed!(11111)\n\n# Baseline PH\nmodel_exp_base, cfg_exp = build_test_model(\"exp\", :ph, false)\ndurations_exp_base = simulate_event_times(model_exp_base, SIM_SAMPLES)\n\nax1 = Axis(fig[1, 1], xlabel=\"Time\", ylabel=\"CDF\", title=\"Exp PH Baseline\")\nt_grid = range(0, cfg_exp.horizon, length=DIST_GRID_POINTS)\necdf_exp = ecdf(durations_exp_base)\nlines!(ax1, t_grid, [ecdf_exp(t) for t in t_grid], label=\"Empirical\", linewidth=2)\nlines!(ax1, t_grid, [expected_cdf(\"exp\", :ph, false, t) for t in t_grid], \n       label=\"Theoretical\", linestyle=:dash, linewidth=2, color=:red)\naxislegend(ax1, position=:rb)\n\n# With covariate PH\nmodel_exp_cov, _ = build_test_model(\"exp\", :ph, true)\ndurations_exp_cov = simulate_event_times(model_exp_cov, SIM_SAMPLES)\n\nax2 = Axis(fig[1, 2], xlabel=\"Time\", ylabel=\"CDF\", title=\"Exp PH with Covariate\")\necdf_exp_cov = ecdf(durations_exp_cov)\nlines!(ax2, t_grid, [ecdf_exp_cov(t) for t in t_grid], label=\"Empirical\", linewidth=2)\nlines!(ax2, t_grid, [expected_cdf(\"exp\", :ph, true, t) for t in t_grid], \n       label=\"Theoretical\", linestyle=:dash, linewidth=2, color=:red)\naxislegend(ax2, position=:rb)\n\n# AFT baseline\nmodel_exp_aft, _ = build_test_model(\"exp\", :aft, false)\ndurations_exp_aft = simulate_event_times(model_exp_aft, SIM_SAMPLES)\n\nax3 = Axis(fig[2, 1], xlabel=\"Time\", ylabel=\"CDF\", title=\"Exp AFT Baseline\")\necdf_exp_aft = ecdf(durations_exp_aft)\nlines!(ax3, t_grid, [ecdf_exp_aft(t) for t in t_grid], label=\"Empirical\", linewidth=2)\nlines!(ax3, t_grid, [expected_cdf(\"exp\", :aft, false, t) for t in t_grid], \n       label=\"Theoretical\", linestyle=:dash, linewidth=2, color=:red)\naxislegend(ax3, position=:rb)\n\n# AFT with covariate\nmodel_exp_aft_cov, _ = build_test_model(\"exp\", :aft, true)\ndurations_exp_aft_cov = simulate_event_times(model_exp_aft_cov, SIM_SAMPLES)\n\nax4 = Axis(fig[2, 2], xlabel=\"Time\", ylabel=\"CDF\", title=\"Exp AFT with Covariate\")\necdf_exp_aft_cov = ecdf(durations_exp_aft_cov)\nlines!(ax4, t_grid, [ecdf_exp_aft_cov(t) for t in t_grid], label=\"Empirical\", linewidth=2)\nlines!(ax4, t_grid, [expected_cdf(\"exp\", :aft, true, t) for t in t_grid], \n       label=\"Theoretical\", linestyle=:dash, linewidth=2, color=:red)\naxislegend(ax4, position=:rb)\n\nfig\n\n\n\n\n\n\n\n\nFigure 1: Exponential Hazard Diagnostics\n\n\n\n\n\n\n\nWeibull Distribution\n\n\nShow code\nfig = Figure(size=(900, 700))\n\nRandom.seed!(22222)\ncfg_wei = FAMILY_CONFIG[\"wei\"]\nt_grid_wei = range(0.02, cfg_wei.horizon, length=DIST_GRID_POINTS)  # Start &gt; 0 for Weibull\n\n# Baseline PH\nmodel_wei_base, _ = build_test_model(\"wei\", :ph, false)\ndurations_wei_base = simulate_event_times(model_wei_base, SIM_SAMPLES)\n\nax1 = Axis(fig[1, 1], xlabel=\"Time\", ylabel=\"CDF\", title=\"Weibull PH Baseline\")\necdf_wei = ecdf(durations_wei_base)\nlines!(ax1, t_grid_wei, [ecdf_wei(t) for t in t_grid_wei], label=\"Empirical\", linewidth=2)\nlines!(ax1, t_grid_wei, [expected_cdf(\"wei\", :ph, false, t) for t in t_grid_wei], \n       label=\"Theoretical\", linestyle=:dash, linewidth=2, color=:red)\naxislegend(ax1, position=:rb)\n\n# With covariate PH\nmodel_wei_cov, _ = build_test_model(\"wei\", :ph, true)\ndurations_wei_cov = simulate_event_times(model_wei_cov, SIM_SAMPLES)\n\nax2 = Axis(fig[1, 2], xlabel=\"Time\", ylabel=\"CDF\", title=\"Weibull PH with Covariate\")\necdf_wei_cov = ecdf(durations_wei_cov)\nlines!(ax2, t_grid_wei, [ecdf_wei_cov(t) for t in t_grid_wei], label=\"Empirical\", linewidth=2)\nlines!(ax2, t_grid_wei, [expected_cdf(\"wei\", :ph, true, t) for t in t_grid_wei], \n       label=\"Theoretical\", linestyle=:dash, linewidth=2, color=:red)\naxislegend(ax2, position=:rb)\n\n# AFT baseline\nmodel_wei_aft, _ = build_test_model(\"wei\", :aft, false)\ndurations_wei_aft = simulate_event_times(model_wei_aft, SIM_SAMPLES)\n\nax3 = Axis(fig[2, 1], xlabel=\"Time\", ylabel=\"CDF\", title=\"Weibull AFT Baseline\")\necdf_wei_aft = ecdf(durations_wei_aft)\nlines!(ax3, t_grid_wei, [ecdf_wei_aft(t) for t in t_grid_wei], label=\"Empirical\", linewidth=2)\nlines!(ax3, t_grid_wei, [expected_cdf(\"wei\", :aft, false, t) for t in t_grid_wei], \n       label=\"Theoretical\", linestyle=:dash, linewidth=2, color=:red)\naxislegend(ax3, position=:rb)\n\n# AFT with covariate\nmodel_wei_aft_cov, _ = build_test_model(\"wei\", :aft, true)\ndurations_wei_aft_cov = simulate_event_times(model_wei_aft_cov, SIM_SAMPLES)\n\nax4 = Axis(fig[2, 2], xlabel=\"Time\", ylabel=\"CDF\", title=\"Weibull AFT with Covariate\")\necdf_wei_aft_cov = ecdf(durations_wei_aft_cov)\nlines!(ax4, t_grid_wei, [ecdf_wei_aft_cov(t) for t in t_grid_wei], label=\"Empirical\", linewidth=2)\nlines!(ax4, t_grid_wei, [expected_cdf(\"wei\", :aft, true, t) for t in t_grid_wei], \n       label=\"Theoretical\", linestyle=:dash, linewidth=2, color=:red)\naxislegend(ax4, position=:rb)\n\nfig\n\n\n\n\n\n\n\n\nFigure 2: Weibull Hazard Diagnostics\n\n\n\n\n\n\n\nGompertz Distribution\n\n\nShow code\nfig = Figure(size=(900, 700))\n\nRandom.seed!(33333)\ncfg_gom = FAMILY_CONFIG[\"gom\"]\nt_grid_gom = range(0, cfg_gom.horizon, length=DIST_GRID_POINTS)\n\n# Baseline PH\nmodel_gom_base, _ = build_test_model(\"gom\", :ph, false)\ndurations_gom_base = simulate_event_times(model_gom_base, SIM_SAMPLES)\n\nax1 = Axis(fig[1, 1], xlabel=\"Time\", ylabel=\"CDF\", title=\"Gompertz PH Baseline\")\necdf_gom = ecdf(durations_gom_base)\nlines!(ax1, t_grid_gom, [ecdf_gom(t) for t in t_grid_gom], label=\"Empirical\", linewidth=2)\nlines!(ax1, t_grid_gom, [expected_cdf(\"gom\", :ph, false, t) for t in t_grid_gom], \n       label=\"Theoretical\", linestyle=:dash, linewidth=2, color=:red)\naxislegend(ax1, position=:rb)\n\n# With covariate PH\nmodel_gom_cov, _ = build_test_model(\"gom\", :ph, true)\ndurations_gom_cov = simulate_event_times(model_gom_cov, SIM_SAMPLES)\n\nax2 = Axis(fig[1, 2], xlabel=\"Time\", ylabel=\"CDF\", title=\"Gompertz PH with Covariate\")\necdf_gom_cov = ecdf(durations_gom_cov)\nlines!(ax2, t_grid_gom, [ecdf_gom_cov(t) for t in t_grid_gom], label=\"Empirical\", linewidth=2)\nlines!(ax2, t_grid_gom, [expected_cdf(\"gom\", :ph, true, t) for t in t_grid_gom], \n       label=\"Theoretical\", linestyle=:dash, linewidth=2, color=:red)\naxislegend(ax2, position=:rb)\n\n# AFT baseline\nmodel_gom_aft, _ = build_test_model(\"gom\", :aft, false)\ndurations_gom_aft = simulate_event_times(model_gom_aft, SIM_SAMPLES)\n\nax3 = Axis(fig[2, 1], xlabel=\"Time\", ylabel=\"CDF\", title=\"Gompertz AFT Baseline\")\necdf_gom_aft = ecdf(durations_gom_aft)\nlines!(ax3, t_grid_gom, [ecdf_gom_aft(t) for t in t_grid_gom], label=\"Empirical\", linewidth=2)\nlines!(ax3, t_grid_gom, [expected_cdf(\"gom\", :aft, false, t) for t in t_grid_gom], \n       label=\"Theoretical\", linestyle=:dash, linewidth=2, color=:red)\naxislegend(ax3, position=:rb)\n\n# AFT with covariate\nmodel_gom_aft_cov, _ = build_test_model(\"gom\", :aft, true)\ndurations_gom_aft_cov = simulate_event_times(model_gom_aft_cov, SIM_SAMPLES)\n\nax4 = Axis(fig[2, 2], xlabel=\"Time\", ylabel=\"CDF\", title=\"Gompertz AFT with Covariate\")\necdf_gom_aft_cov = ecdf(durations_gom_aft_cov)\nlines!(ax4, t_grid_gom, [ecdf_gom_aft_cov(t) for t in t_grid_gom], label=\"Empirical\", linewidth=2)\nlines!(ax4, t_grid_gom, [expected_cdf(\"gom\", :aft, true, t) for t in t_grid_gom], \n       label=\"Theoretical\", linestyle=:dash, linewidth=2, color=:red)\naxislegend(ax4, position=:rb)\n\nfig\n\n\n\n\n\n\n\n\nFigure 3: Gompertz Hazard Diagnostics"
  },
  {
    "objectID": "simulation_diagnostics.html#hazard-function-verification",
    "href": "simulation_diagnostics.html#hazard-function-verification",
    "title": "Simulation Diagnostics",
    "section": "Hazard Function Verification",
    "text": "Hazard Function Verification\nThe CDF plots above implicitly verify hazard function correctness - if the hazard functions were wrong, the simulated CDFs would not match the theoretical CDFs.\nFor explicit verification, the hazard functions use the following formulas:\n\n\n\nFamily\nHazard \\(h(t)\\)\nImplementation\n\n\n\n\nExponential\n\\(\\lambda\\)\nrate\n\n\nWeibull\n\\(a \\cdot b \\cdot t^{a-1}\\)\nshape * scale * t^(shape-1)\n\n\nGompertz\n\\(b \\cdot e^{at}\\)\nrate * exp(shape * t)\n\n\n\nWhere shape and scale (or rate) are the distribution parameters. The Gompertz uses the flexsurv parameterization."
  },
  {
    "objectID": "simulation_diagnostics.html#summary",
    "href": "simulation_diagnostics.html#summary",
    "title": "Simulation Diagnostics",
    "section": "Summary",
    "text": "Summary\nAll simulation diagnostics pass:\n\nExponential: PH and AFT baseline and with covariates ✅\nWeibull: PH and AFT baseline and with covariates ✅\nGompertz: PH and AFT baseline and with covariates ✅\n\nThe maximum CDF differences are all essentially zero (within Monte Carlo error), confirming that:\n\nEvent time simulation is statistically correct\nHazard functions are implemented correctly\nCovariate effects (PH and AFT) work as expected\nThe flexsurv Gompertz parameterization is correctly implemented"
  },
  {
    "objectID": "simulation_diagnostics.html#technical-notes",
    "href": "simulation_diagnostics.html#technical-notes",
    "title": "Simulation Diagnostics",
    "section": "Technical Notes",
    "text": "Technical Notes\n\nGompertz Parameterization\nMultistateModels.jl uses the flexsurv Gompertz parameterization: - shape (\\(a\\)): Rate of hazard increase (can be negative for decreasing hazard) - rate (\\(b\\)): Initial hazard at \\(t=0\\)\nThis differs from some other parameterizations. The hazard is: \\[h(t) = b \\cdot e^{at}\\]\n\n\nSimulation Strategy\nThe diagnostics use CachedTransformStrategy() which caches inverse CDF computations for efficiency. The DirectTransformStrategy() computes inversions fresh each time. Both should produce identical results.\n\n\nMonte Carlo Error\nWith 40,000 samples, the expected maximum CDF error from Monte Carlo is approximately: \\[\\sqrt{\\frac{\\log(n)}{2n}} \\approx 0.007\\]\nSo maximum differences &lt; 0.02 are consistent with simulation being correct."
  },
  {
    "objectID": "01_architecture.html",
    "href": "01_architecture.html",
    "title": "Package Architecture & Workflow",
    "section": "",
    "text": "NoteStatus: Not Started\n\n\n\nThis report is a placeholder. Content will be added as the package documentation is developed."
  },
  {
    "objectID": "01_architecture.html#introduction",
    "href": "01_architecture.html#introduction",
    "title": "Package Architecture & Workflow",
    "section": "1. Introduction",
    "text": "1. Introduction\n\nDesign Philosophy\nMultistateModels.jl is designed to provide flexible tools for analyzing multistate survival data. The package supports:\n\nMultiple hazard families (Exponential, Weibull, Gompertz, B-splines)\nBoth proportional hazards (PH) and accelerated failure time (AFT) covariate effects\nExactly observed and panel (interval-censored) data\nTime-varying covariates\nSemi-Markov models with duration dependence\n\n\n\nPackage Overview\n\n\nShow code\n# Core workflow\nusing MultistateModels\n\n# 1. Define hazards\nhazards = (\n    h12 = Hazard(@formula(0 ~ x), \"wei\", 1, 2),\n    h23 = Hazard(@formula(0 ~ 1), \"exp\", 2, 3)\n)\n\n# 2. Build model\nmodel = multistatemodel(hazards; data = df)\n\n# 3. Fit model\nfit!(model)\n\n# 4. Simulate from fitted model\npaths = simulate(model; nsim = 1000)"
  },
  {
    "objectID": "01_architecture.html#model-construction",
    "href": "01_architecture.html#model-construction",
    "title": "Package Architecture & Workflow",
    "section": "2. Model Construction",
    "text": "2. Model Construction\n\n2.1 The MultistateProcess Struct\nTo be documented\n\n\n2.2 Hazard Specification\nTo be documented\n\n\n2.3 Parameterization Conventions\nAll hazard families follow flexsurv conventions:\n\n\n\n\n\n\n\n\nFamily\nHazard Function\nParameters\n\n\n\n\nExponential\n\\(h(t) = \\text{rate}\\)\nrate &gt; 0\n\n\nWeibull\n\\(h(t) = \\text{shape} \\times \\text{scale} \\times t^{\\text{shape}-1}\\)\nshape &gt; 0, scale &gt; 0\n\n\nGompertz\n\\(h(t) = \\text{rate} \\times \\exp(\\text{shape} \\times t)\\)\nshape ∈ ℝ, rate &gt; 0\n\n\nB-Spline\n\\(h(t) = \\exp(\\mathbf{B}(t)' \\boldsymbol{\\theta})\\)\nθ ∈ ℝ^k\n\n\n\n\n\n2.4 Covariate Effects\nTo be documented\n\n\n2.5 Time-Varying Covariates\nTo be documented\n\n\n2.6 The multistatemodel() Constructor\nTo be documented\n\n\n2.7 Data Requirements\nTo be documented"
  },
  {
    "objectID": "01_architecture.html#simulation-engine",
    "href": "01_architecture.html#simulation-engine",
    "title": "Package Architecture & Workflow",
    "section": "3. Simulation Engine",
    "text": "3. Simulation Engine\n\n3.1 simulate() vs simulate_path()\nTo be documented\n\n\n3.2 Transform Strategies\nTo be documented\n\n\n3.3 Jump Solvers\nTo be documented\n\n\n3.4 Phase-Type Expansion\nTo be documented"
  },
  {
    "objectID": "01_architecture.html#inference",
    "href": "01_architecture.html#inference",
    "title": "Package Architecture & Workflow",
    "section": "4. Inference",
    "text": "4. Inference\n\n4.1 Likelihood Calculations\nTo be documented\n\n\n4.2 MCEM Algorithm\nTo be documented\n\n\n4.3 Optimization Wrappers\nTo be documented\n\n\n4.4 Parameter Constraints\nTo be documented"
  },
  {
    "objectID": "01_architecture.html#key-internal-functions",
    "href": "01_architecture.html#key-internal-functions",
    "title": "Package Architecture & Workflow",
    "section": "5. Key Internal Functions",
    "text": "5. Key Internal Functions\n\n5.1 Hazard Evaluation\nTo be documented\n\n\n5.2 Survival Probability\nTo be documented\n\n\n5.3 Parameter Handling\nTo be documented\n\n\n5.4 Time Transforms\nTo be documented"
  },
  {
    "objectID": "01_architecture.html#option-reference",
    "href": "01_architecture.html#option-reference",
    "title": "Package Architecture & Workflow",
    "section": "6. Option Reference",
    "text": "6. Option Reference\nTo be documented"
  },
  {
    "objectID": "benchmarks.html",
    "href": "benchmarks.html",
    "title": "Performance Benchmarks",
    "section": "",
    "text": "Note: These results are generated from MultistateModelsTests/benchmarks/run_benchmarks.jl. Last run: December 2025.\n\n\n0×2 DataFrame\n\n\n\nRow\nThreads\nRuntime\n\n\n\nUnion{}\nUnion{}"
  },
  {
    "objectID": "benchmarks.html#benchmark-results",
    "href": "benchmarks.html#benchmark-results",
    "title": "Performance Benchmarks",
    "section": "",
    "text": "Note: These results are generated from MultistateModelsTests/benchmarks/run_benchmarks.jl. Last run: December 2025.\n\n\n0×2 DataFrame\n\n\n\nRow\nThreads\nRuntime\n\n\n\nUnion{}\nUnion{}"
  },
  {
    "objectID": "benchmarks.html#scalability-analysis",
    "href": "benchmarks.html#scalability-analysis",
    "title": "Performance Benchmarks",
    "section": "Scalability Analysis",
    "text": "Scalability Analysis\n\nSample Size Scaling\n\n\nShow code\nif !isempty(scalability_df)\n    fig = Figure(size=(700, 400))\n    \n    ax = Axis(fig[1, 1],\n        xlabel=\"Sample Size (n)\",\n        ylabel=\"Runtime (seconds)\",\n        title=\"Runtime Scaling\",\n        xscale=log10,\n        yscale=log10,\n        xticks=(scalability_df.N, string.(scalability_df.N)))\n    \n    scatter!(ax, scalability_df.N, scalability_df.Runtime, label=\"Panel (MCEM)\", \n             markersize=12, color=:orange)\n    lines!(ax, scalability_df.N, scalability_df.Runtime, color=:orange, linewidth=2)\n    \n    axislegend(ax, position=:lt)\n    fig\nelse\n    println(\"No scalability data available.\")\nend\n\n\n\n\n\n\n\n\nFigure 1: Runtime Scaling with Sample Size"
  },
  {
    "objectID": "benchmarks.html#squarem-acceleration",
    "href": "benchmarks.html#squarem-acceleration",
    "title": "Performance Benchmarks",
    "section": "SQUAREM Acceleration",
    "text": "SQUAREM Acceleration\n\n\nSQUAREM Runtime (N=200): 0.0108 seconds"
  },
  {
    "objectID": "benchmarks.html#threading-performance",
    "href": "benchmarks.html#threading-performance",
    "title": "Performance Benchmarks",
    "section": "Threading Performance",
    "text": "Threading Performance\n\n\nNo threading data available.\n\n\n\nComplexity Analysis\n\n\n\nOperation\nComplexity\nNotes\n\n\n\n\nExact likelihood\nO(n)\nPer-subject TPM computation\n\n\nPanel likelihood\nO(n × k)\nk = paths per subject\n\n\nGradient computation\nO(n × p)\np = number of parameters\n\n\nMCEM per iteration\nO(n × k × m)\nm = MCEM paths\n\n\n\n\n\nThreading Recommendations\n\n\n4×3 DataFrame\n\n\n\nRow\nScenario\nRecommendedThreads\nNotes\n\n\n\nString\nString\nString\n\n\n\n\n1\nSmall dataset (n &lt; 500)\n1-2\nThread overhead dominates\n\n\n2\nMedium dataset (n ~ 1000)\n4\nGood balance\n\n\n3\nLarge dataset (n &gt; 2000)\n8-16\nNear-linear scaling\n\n\n4\nMCEM with many paths\nMatch physical cores\nMemory bandwidth limit"
  },
  {
    "objectID": "benchmarks.html#phase-type-proposal-performance",
    "href": "benchmarks.html#phase-type-proposal-performance",
    "title": "Performance Benchmarks",
    "section": "Phase-Type Proposal Performance",
    "text": "Phase-Type Proposal Performance\nBenchmark pending implementation."
  },
  {
    "objectID": "benchmarks.html#running-benchmarks",
    "href": "benchmarks.html#running-benchmarks",
    "title": "Performance Benchmarks",
    "section": "Running Benchmarks",
    "text": "Running Benchmarks\n# Full benchmark suite\njulia --project=MultistateModelsTests MultistateModelsTests/benchmarks/run_benchmarks.jl\n\nBenchmark Environment\n\n\nShow code\n# System information for reproducibility\nprintln(\"Julia version: \", VERSION)\nprintln(\"Threads available: \", Threads.nthreads())\n# println(\"Physical cores: \", MultistateModels.get_physical_cores())\n\n\nJulia version: 1.12.2\nThreads available: 1"
  },
  {
    "objectID": "benchmarks.html#summary",
    "href": "benchmarks.html#summary",
    "title": "Performance Benchmarks",
    "section": "Summary",
    "text": "Summary\n\nPerformance Highlights\n\nExact data fitting: Scales linearly with sample size\nPanel data (MCEM): Slower than exact, but handles interval censoring\nSQUAREM: Accelerated EM convergence (enabled by default)\nThreading: Parallel likelihood computation\nPhase-type proposals: Critical for non-exponential hazards in MCEM\n\n\n\nOptimization Tips\n\nUse exact observations when available - much faster than panel\nEnable SQUAREM - default in fit(), significantly faster\nMatch threads to physical cores - avoid hyperthreading overhead\nUse phase-type proposals for semi-Markov - automatic selection in fit()\nProfile before optimizing - identify actual bottlenecks\n\n\n\nMemory Management\n\nPre-allocate path storage for MCEM\nUse CachedTransformStrategy() for repeated simulations\nConsider batched processing for very large datasets"
  },
  {
    "objectID": "03_long_tests.html",
    "href": "03_long_tests.html",
    "title": "Long Tests Status",
    "section": "",
    "text": "**Summary**: 23 / 28 tests passed (5 failed)\n\n\n\n\n\nTable 1: Long Test Results Summary\n\n\n\n28×7 DataFrame3 rows omitted\n\n\n\nRow\nTestName\nFamily\nDataType\nCovariates\nNSubjects\nStatus\nTimestamp\n\n\n\nString\nString\nString\nString\nInt64\nString\nString\n\n\n\n\n1\nexp_exact_fixed\nexp\nexact\nfixed\n1000\n✅ Pass\n2026-01-01T16:30:59.909\n\n\n2\nexp_exact_nocov\nexp\nexact\nnocov\n1000\n✅ Pass\n2026-01-01T16:30:56.638\n\n\n3\nexp_exact_tvc\nexp\nexact\ntvc\n1000\n✅ Pass\n2026-01-01T16:31:00.825\n\n\n4\nexp_panel_fixed\nexp\npanel\nfixed\n986\n✅ Pass\n2026-01-01T16:33:12.818\n\n\n5\nexp_panel_nocov\nexp\npanel\nnocov\n990\n✅ Pass\n2026-01-01T16:33:02.121\n\n\n6\nexp_panel_tvc\nexp\npanel\ntvc\n990\n✅ Pass\n2026-01-01T16:33:23.251\n\n\n7\ngom_exact_fixed\ngom\nexact\nfixed\n1000\n✅ Pass\n2026-01-01T16:32:31.437\n\n\n8\ngom_exact_nocov\ngom\nexact\nnocov\n1000\n✅ Pass\n2026-01-01T16:32:13.335\n\n\n9\ngom_exact_tvc\ngom\nexact\ntvc\n1000\n✅ Pass\n2026-01-01T16:32:51.437\n\n\n10\ngom_mcem_fixed\ngom\nmcem\nfixed\n984\n✅ Pass\n2026-01-01T16:37:58.797\n\n\n11\ngom_mcem_nocov\ngom\nmcem\nnocov\n992\n✅ Pass\n2026-01-01T16:37:05.896\n\n\n12\ngom_mcem_tvc\ngom\nmcem\ntvc\n993\n❌ Fail\n2026-01-01T16:38:53.898\n\n\n13\npt_mixed_simple\nphasetype\nmixed\nnone\n1000\n✅ Pass\n2026-01-01T16:50:16.242\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n17\npt_panel_simple\nphasetype\npanel\nnone\n1000\n✅ Pass\n2026-01-01T16:49:53.801\n\n\n18\npt_panel_tvc\nphasetype\npanel\ntvc\n1000\n❌ Fail\n2026-01-01T16:50:57.991\n\n\n19\npt_exact_fixed\npt\nexact\nfixed\n1000\n✅ Pass\n2026-01-01T16:49:44.907\n\n\n20\npt_exact_nocov\npt\nexact\nnocov\n1000\n✅ Pass\n2026-01-01T16:49:39.984\n\n\n21\npt_exact_tvc\npt\nexact\ntvc\n1000\n✅ Pass\n2026-01-01T16:49:45.453\n\n\n22\nsp_mcem_fixed\nsp\npanel\nfixed\n1000\n❌ Fail\n2026-01-01T17:08:41.835\n\n\n23\nwei_exact_fixed\nwei\nexact\nfixed\n1000\n✅ Pass\n2026-01-01T16:31:38.432\n\n\n24\nwei_exact_nocov\nwei\nexact\nnocov\n1000\n✅ Pass\n2026-01-01T16:31:17.325\n\n\n25\nwei_exact_tvc\nwei\nexact\ntvc\n1000\n✅ Pass\n2026-01-01T16:31:58.169\n\n\n26\nwei_mcem_fixed\nwei\nmcem\nfixed\n989\n✅ Pass\n2026-01-01T16:35:28.655\n\n\n27\nwei_mcem_nocov\nwei\nmcem\nnocov\n991\n✅ Pass\n2026-01-01T16:34:12.161\n\n\n28\nwei_mcem_tvc\nwei\nmcem\ntvc\n995\n❌ Fail\n2026-01-01T16:36:30.196"
  },
  {
    "objectID": "03_long_tests.html#test-inventory",
    "href": "03_long_tests.html#test-inventory",
    "title": "Long Tests Status",
    "section": "",
    "text": "**Summary**: 23 / 28 tests passed (5 failed)\n\n\n\n\n\nTable 1: Long Test Results Summary\n\n\n\n28×7 DataFrame3 rows omitted\n\n\n\nRow\nTestName\nFamily\nDataType\nCovariates\nNSubjects\nStatus\nTimestamp\n\n\n\nString\nString\nString\nString\nInt64\nString\nString\n\n\n\n\n1\nexp_exact_fixed\nexp\nexact\nfixed\n1000\n✅ Pass\n2026-01-01T16:30:59.909\n\n\n2\nexp_exact_nocov\nexp\nexact\nnocov\n1000\n✅ Pass\n2026-01-01T16:30:56.638\n\n\n3\nexp_exact_tvc\nexp\nexact\ntvc\n1000\n✅ Pass\n2026-01-01T16:31:00.825\n\n\n4\nexp_panel_fixed\nexp\npanel\nfixed\n986\n✅ Pass\n2026-01-01T16:33:12.818\n\n\n5\nexp_panel_nocov\nexp\npanel\nnocov\n990\n✅ Pass\n2026-01-01T16:33:02.121\n\n\n6\nexp_panel_tvc\nexp\npanel\ntvc\n990\n✅ Pass\n2026-01-01T16:33:23.251\n\n\n7\ngom_exact_fixed\ngom\nexact\nfixed\n1000\n✅ Pass\n2026-01-01T16:32:31.437\n\n\n8\ngom_exact_nocov\ngom\nexact\nnocov\n1000\n✅ Pass\n2026-01-01T16:32:13.335\n\n\n9\ngom_exact_tvc\ngom\nexact\ntvc\n1000\n✅ Pass\n2026-01-01T16:32:51.437\n\n\n10\ngom_mcem_fixed\ngom\nmcem\nfixed\n984\n✅ Pass\n2026-01-01T16:37:58.797\n\n\n11\ngom_mcem_nocov\ngom\nmcem\nnocov\n992\n✅ Pass\n2026-01-01T16:37:05.896\n\n\n12\ngom_mcem_tvc\ngom\nmcem\ntvc\n993\n❌ Fail\n2026-01-01T16:38:53.898\n\n\n13\npt_mixed_simple\nphasetype\nmixed\nnone\n1000\n✅ Pass\n2026-01-01T16:50:16.242\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n17\npt_panel_simple\nphasetype\npanel\nnone\n1000\n✅ Pass\n2026-01-01T16:49:53.801\n\n\n18\npt_panel_tvc\nphasetype\npanel\ntvc\n1000\n❌ Fail\n2026-01-01T16:50:57.991\n\n\n19\npt_exact_fixed\npt\nexact\nfixed\n1000\n✅ Pass\n2026-01-01T16:49:44.907\n\n\n20\npt_exact_nocov\npt\nexact\nnocov\n1000\n✅ Pass\n2026-01-01T16:49:39.984\n\n\n21\npt_exact_tvc\npt\nexact\ntvc\n1000\n✅ Pass\n2026-01-01T16:49:45.453\n\n\n22\nsp_mcem_fixed\nsp\npanel\nfixed\n1000\n❌ Fail\n2026-01-01T17:08:41.835\n\n\n23\nwei_exact_fixed\nwei\nexact\nfixed\n1000\n✅ Pass\n2026-01-01T16:31:38.432\n\n\n24\nwei_exact_nocov\nwei\nexact\nnocov\n1000\n✅ Pass\n2026-01-01T16:31:17.325\n\n\n25\nwei_exact_tvc\nwei\nexact\ntvc\n1000\n✅ Pass\n2026-01-01T16:31:58.169\n\n\n26\nwei_mcem_fixed\nwei\nmcem\nfixed\n989\n✅ Pass\n2026-01-01T16:35:28.655\n\n\n27\nwei_mcem_nocov\nwei\nmcem\nnocov\n991\n✅ Pass\n2026-01-01T16:34:12.161\n\n\n28\nwei_mcem_tvc\nwei\nmcem\ntvc\n995\n❌ Fail\n2026-01-01T16:36:30.196"
  },
  {
    "objectID": "03_long_tests.html#parametric-models",
    "href": "03_long_tests.html#parametric-models",
    "title": "Long Tests Status",
    "section": "2. Parametric Models",
    "text": "2. Parametric Models\n\n2.1 Exponential Hazard\n\n\n\n\n#### exp_exact_nocov\n- **Status**: ✅ Pass\n- **N subjects**: 1000\n\n| Parameter | True | Estimated |\n|-----------|------|-----------|\n| h12_log_rate | -1.8971 | -1.8465 |\n| h23_log_rate | -2.1203 | -2.0904 |\n\n#### exp_exact_fixed\n- **Status**: ✅ Pass\n- **N subjects**: 1000\n\n| Parameter | True | Estimated |\n|-----------|------|-----------|\n| h12_beta | 0.5 | 0.5267 |\n| h23_beta | 0.5 | 0.4791 |\n| h12_log_rate | -1.8971 | -1.8898 |\n| h23_log_rate | -2.1203 | -2.067 |\n\n#### exp_exact_tvc\n- **Status**: ✅ Pass\n- **N subjects**: 1000\n\n| Parameter | True | Estimated |\n|-----------|------|-----------|\n| h12_beta | 0.5 | 0.4118 |\n| h23_beta | 0.5 | 0.3392 |\n| h12_log_rate | -1.8971 | -1.8465 |\n| h23_log_rate | -2.1203 | -1.9534 |\n\n\n\n\nFigure 1\n\n\n\n\n\n2.2 Weibull Hazard\n\n\n#### wei_exact_nocov\n- **Status**: ✅ Pass\n- **N subjects**: 1000\n\n#### wei_exact_fixed\n- **Status**: ✅ Pass\n- **N subjects**: 1000\n\n#### wei_exact_tvc\n- **Status**: ✅ Pass\n- **N subjects**: 1000\n\n#### wei_mcem_nocov\n- **Status**: ✅ Pass\n- **N subjects**: 991\n\n#### wei_mcem_fixed\n- **Status**: ✅ Pass\n- **N subjects**: 989\n\n#### wei_mcem_tvc\n- **Status**: ❌ Fail\n- **N subjects**: 995\n\n\n\n\n\n2.3 Gompertz Hazard\n\n\n#### gom_exact_nocov\n- **Status**: ✅ Pass\n- **N subjects**: 1000\n\n#### gom_exact_fixed\n- **Status**: ✅ Pass\n- **N subjects**: 1000\n\n#### gom_exact_tvc\n- **Status**: ✅ Pass\n- **N subjects**: 1000\n\n#### gom_mcem_nocov\n- **Status**: ✅ Pass\n- **N subjects**: 992\n\n#### gom_mcem_fixed\n- **Status**: ✅ Pass\n- **N subjects**: 984\n\n#### gom_mcem_tvc\n- **Status**: ❌ Fail\n- **N subjects**: 993"
  },
  {
    "objectID": "03_long_tests.html#panel-data-exponential-markov",
    "href": "03_long_tests.html#panel-data-exponential-markov",
    "title": "Long Tests Status",
    "section": "3. Panel Data (Exponential / Markov)",
    "text": "3. Panel Data (Exponential / Markov)\n\n\n#### exp_panel_nocov\n- **Status**: ✅ Pass\n- **N subjects**: 990\n\n#### exp_panel_fixed\n- **Status**: ✅ Pass\n- **N subjects**: 986\n\n#### exp_panel_tvc\n- **Status**: ✅ Pass\n- **N subjects**: 990"
  },
  {
    "objectID": "03_long_tests.html#notes",
    "href": "03_long_tests.html#notes",
    "title": "Long Tests Status",
    "section": "4. Notes",
    "text": "4. Notes\n\nTests use a 3-state progressive model: State 1 → State 2 → State 3\nParameter recovery tolerance: 35% relative error for main parameters\nTVC (time-varying covariate) tests verify covariate effects change at t=5\nExact data uses obstype=1 (continuous observation)\nPanel data uses discrete observation times with MCEM for semi-Markov families"
  },
  {
    "objectID": "05_benchmarks.html",
    "href": "05_benchmarks.html",
    "title": "Benchmarks",
    "section": "",
    "text": "NoteStatus: Not Started\n\n\n\nThis report is a placeholder. Content will be added as the benchmark infrastructure is developed."
  },
  {
    "objectID": "05_benchmarks.html#sampling-methods-comparison",
    "href": "05_benchmarks.html#sampling-methods-comparison",
    "title": "Benchmarks",
    "section": "1. Sampling Methods Comparison",
    "text": "1. Sampling Methods Comparison\n\nOverview\nThis section compares the performance of different sampling methods used in the MCEM algorithm:\n\nSIR: Sampling Importance Resampling\nLHS: Latin Hypercube Sampling\nIS: Importance Sampling\n\n\n\nBenchmark Setup\n\n\nShow code\n# TODO: Add benchmark setup code\nusing BenchmarkTools\n\n# Model configuration\n# ...\n\n\n\n\nResults\n\n\n\nMethod\nESS\nRuntime (s)\nESS/second\n\n\n\n\nSIR\n-\n-\n-\n\n\nLHS\n-\n-\n-\n\n\nIS\n-\n-\n-\n\n\n\n\n\nEffective Sample Size Comparison\nPlot to be generated: ESS vs computation time for each method"
  },
  {
    "objectID": "05_benchmarks.html#mcem-acceleration",
    "href": "05_benchmarks.html#mcem-acceleration",
    "title": "Benchmarks",
    "section": "2. MCEM Acceleration",
    "text": "2. MCEM Acceleration\n\nOverview\nThis section compares standard EM with SQUAREM acceleration.\n\n\nBenchmark Setup\n\n\nShow code\n# TODO: Add SQUAREM benchmark code\n\n\n\n\nConvergence Comparison\n\n\n\nMethod\nIterations to Convergence\nTotal Runtime (s)\n\n\n\n\nStandard EM\n-\n-\n\n\nSQUAREM\n-\n-\n\n\n\n\n\nConvergence Plots\nPlots to be generated: Log-likelihood vs iteration for each method"
  },
  {
    "objectID": "05_benchmarks.html#scalability",
    "href": "05_benchmarks.html#scalability",
    "title": "Benchmarks",
    "section": "3. Scalability",
    "text": "3. Scalability\n\n3.1 Runtime vs Number of Subjects\nPlot to be generated\n\n\n3.2 Runtime vs Number of States\nPlot to be generated\n\n\n3.3 Runtime vs Number of Transitions\nPlot to be generated"
  },
  {
    "objectID": "05_benchmarks.html#memory-usage",
    "href": "05_benchmarks.html#memory-usage",
    "title": "Benchmarks",
    "section": "4. Memory Usage",
    "text": "4. Memory Usage\n\nPeak Memory by Problem Size\n\n\n\nSubjects\nStates\nTransitions\nPeak Memory (GB)\n\n\n\n\n100\n3\n2\n-\n\n\n500\n3\n2\n-\n\n\n1000\n3\n2\n-\n\n\n1000\n5\n6\n-\n\n\n\nAdditional memory profiling to be added"
  },
  {
    "objectID": "04_simulation_diagnostics.html",
    "href": "04_simulation_diagnostics.html",
    "title": "Simulation Diagnostics",
    "section": "",
    "text": "This report validates that the MultistateModels.jl simulation engine produces event times that match the theoretical distributions defined by the hazard functions.\n\n\nFor each scenario, we:\n\nDefine a hazard model with known parameters\nSimulate many event times using simulate_path()\nCompare the empirical CDF (ECDF) to the theoretical CDF\nVerify time-transform parity - ensure that both the cached time-transform strategy and the direct fallback produce identical results\n\n\n\n\n\nECDF vs CDF: Visual comparison of simulated vs theoretical distributions\nKS statistic: Kolmogorov-Smirnov statistic \\(D_n = \\sup_t |F_n(t) - F(t)|\\), which should decrease as \\(\\sim 1/\\sqrt{n}\\)\nTime-transform parity: \\(\\Delta F(t) = F_{tt}(t) - F_{fb}(t)\\) should be zero\n\n\n\nConfiguration constants\nconst COVARIATE_VALUE = 1.5\nconst DELTA_U = sqrt(eps())\nconst DELTA_T = sqrt(eps())\nconst SIM_SAMPLES = 40_000\nconst DIST_GRID_POINTS = 400\n\nconst FAMILY_CONFIG = Dict(\n    \"exp\" =&gt; (; rate = 0.35, beta = 0.6, horizon = 5.0, hazard_start = 0.0),\n    \"wei\" =&gt; (; shape = 1.35, scale = 0.4, beta = -0.35, horizon = 5.0, hazard_start = 0.02),\n    \"gom\" =&gt; (; shape = 0.6, rate = 0.4, beta = 0.5, horizon = 5.0, hazard_start = 0.0),\n)\n\nconst TVC_CONFIG = Dict(\n    \"exp\" =&gt; (; rate = 0.35, beta = 0.6, horizon = 5.0, hazard_start = 0.0, \n               t_changes = [1.5, 3.0], x_values = [0.5, 1.5, 2.5]),\n    \"wei\" =&gt; (; rate = 0.0, shape = 1.35, scale = 0.4, beta = -0.35, horizon = 5.0, \n               hazard_start = 0.02, t_changes = [1.5, 3.0], x_values = [0.5, 1.5, 2.5]),\n    \"gom\" =&gt; (; rate = 0.4, shape = 0.6, beta = 0.5, horizon = 5.0, hazard_start = 0.0, \n               t_changes = [1.5, 3.0], x_values = [0.5, 1.5, 2.5]),\n)\n\n\nDict{String, NamedTuple} with 3 entries:\n  \"exp\" =&gt; (rate = 0.35, beta = 0.6, horizon = 5.0, hazard_start = 0.0, t_chang…\n  \"wei\" =&gt; (rate = 0.0, shape = 1.35, scale = 0.4, beta = -0.35, horizon = 5.0,…\n  \"gom\" =&gt; (rate = 0.4, shape = 0.6, beta = 0.5, horizon = 5.0, hazard_start = …\n\n\n\n\nHelper functions for scenario setup\nstruct Scenario\n    family::String\n    effect::Symbol\n    covariate_mode::Symbol\n    label::String\n    slug::String\n    config::NamedTuple\nend\n\nfunction Scenario(family::String, effect::Symbol, cov_mode::Symbol)\n    if cov_mode == :tvc\n        config = TVC_CONFIG[family]\n        label = string(uppercasefirst(lowercase(family)), \" \", uppercase(String(effect)), \n                      \" time-varying covariate\")\n    else\n        config = FAMILY_CONFIG[family]\n        label = string(uppercasefirst(lowercase(family)), \" \", uppercase(String(effect)), \n                      \" \", cov_mode == :covariate ? \"with covariate\" : \"baseline-only\")\n    end\n    slug = string(family, \"_\", effect, \"_\", cov_mode)\n    return Scenario(family, effect, cov_mode, label, slug, config)\nend\n\nfunction scenario_subject_df(scenario::Scenario)\n    horizon = scenario.config.horizon\n    if scenario.covariate_mode == :tvc\n        t_changes = scenario.config.t_changes\n        x_values = scenario.config.x_values\n        tstart_grid = vcat(0.0, t_changes)\n        tstop_grid = vcat(t_changes, horizon)\n        n_intervals = length(tstart_grid)\n        df = DataFrame(\n            id = fill(1, n_intervals),\n            tstart = tstart_grid,\n            tstop = tstop_grid,\n            statefrom = fill(1, n_intervals),\n            stateto = fill(2, n_intervals),\n            obstype = fill(1, n_intervals),\n            x = x_values,\n        )\n    else\n        df = DataFrame(\n            id = [1], tstart = [0.0], tstop = [horizon],\n            statefrom = [1], stateto = [2], obstype = [1],\n        )\n        if scenario.covariate_mode == :covariate\n            df.x = [COVARIATE_VALUE]\n        end\n    end\n    return df\nend\n\nfunction hazard_formula(scenario::Scenario)\n    (scenario.covariate_mode == :covariate || scenario.covariate_mode == :tvc) ? \n        @formula(0 ~ x) : @formula(0 ~ 1)\nend\n\nfunction scenario_parameter_vector(scenario::Scenario)\n    cfg = scenario.config\n    if scenario.family == \"exp\"\n        base = [log(cfg.rate)]\n    elseif scenario.family == \"wei\"\n        base = [log(cfg.shape), log(cfg.scale)]\n    elseif scenario.family == \"gom\"\n        base = [cfg.shape, log(cfg.rate)]\n    else\n        error(\"Unsupported family $(scenario.family)\")\n    end\n    return (scenario.covariate_mode == :covariate || scenario.covariate_mode == :tvc) ? \n        vcat(base, [cfg.beta]) : base\nend\n\nfunction build_model(scenario::Scenario)\n    data = scenario_subject_df(scenario)\n    hazard = Hazard(\n        hazard_formula(scenario),\n        scenario.family, 1, 2;\n        linpred_effect = scenario.effect,\n        time_transform = true,\n    )\n    model = multistatemodel(hazard; data = data)\n    pars = scenario_parameter_vector(scenario)\n    hazname = model.hazards[1].hazname\n    set_parameters!(model, NamedTuple{(hazname,)}((pars,)))\n    return model, data\nend\n\ncovariate_value(scenario::Scenario) = scenario.covariate_mode == :covariate ? COVARIATE_VALUE : 0.0\n\n\ncovariate_value (generic function with 1 method)\n\n\n\n\nTheoretical distribution functions\n# Piecewise cumulative hazard helpers for TVC\nfunction piecewise_exp_ph_cumhaz(t, rate, beta, t_changes, x_values)\n    cumhaz = 0.0\n    prev_t = 0.0\n    for (i, tc) in enumerate(t_changes)\n        if t &lt;= tc\n            cumhaz += rate * exp(beta * x_values[i]) * (t - prev_t)\n            return cumhaz\n        else\n            cumhaz += rate * exp(beta * x_values[i]) * (tc - prev_t)\n            prev_t = tc\n        end\n    end\n    cumhaz += rate * exp(beta * x_values[end]) * (t - prev_t)\n    return cumhaz\nend\n\nfunction piecewise_wei_ph_cumhaz(t, shape, scale, beta, t_changes, x_values)\n    cumhaz = 0.0\n    prev_t = 0.0\n    for (i, tc) in enumerate(t_changes)\n        if t &lt;= tc\n            cumhaz += scale * exp(beta * x_values[i]) * (t^shape - prev_t^shape)\n            return cumhaz\n        else\n            cumhaz += scale * exp(beta * x_values[i]) * (tc^shape - prev_t^shape)\n            prev_t = tc\n        end\n    end\n    cumhaz += scale * exp(beta * x_values[end]) * (t^shape - prev_t^shape)\n    return cumhaz\nend\n\nfunction distribution_functions(scenario::Scenario)\n    cfg = scenario.config\n    \n    if scenario.covariate_mode == :tvc\n        t_changes = cfg.t_changes\n        x_values = cfg.x_values\n        beta = cfg.beta\n        \n        if scenario.family == \"exp\"\n            rate = cfg.rate\n            cumhaz = t -&gt; piecewise_exp_ph_cumhaz(t, rate, beta, t_changes, x_values)\n            hazard = t -&gt; begin\n                for (i, tc) in enumerate(t_changes)\n                    if t &lt; tc\n                        return rate * exp(beta * x_values[i])\n                    end\n                end\n                return rate * exp(beta * x_values[end])\n            end\n        elseif scenario.family == \"wei\"\n            shape = cfg.shape\n            scale = cfg.scale\n            cumhaz = t -&gt; piecewise_wei_ph_cumhaz(t, shape, scale, beta, t_changes, x_values)\n            hazard = t -&gt; begin\n                for (i, tc) in enumerate(t_changes)\n                    if t &lt; tc\n                        return shape * scale * exp(beta * x_values[i]) * (t^(shape - 1))\n                    end\n                end\n                return shape * scale * exp(beta * x_values[end]) * (t^(shape - 1))\n            end\n        else\n            error(\"TVC not implemented for family $(scenario.family)\")\n        end\n    else\n        xval = covariate_value(scenario)\n        beta = scenario.covariate_mode == :covariate ? cfg.beta : 0.0\n        \n        if scenario.family == \"exp\"\n            base_rate = cfg.rate\n            rate = scenario.effect == :ph ? base_rate * exp(beta * xval) : base_rate * exp(-beta * xval)\n            cumhaz = t -&gt; rate * t\n            hazard = _ -&gt; rate\n        elseif scenario.family == \"wei\"\n            shape = cfg.shape\n            scale = cfg.scale\n            multiplier = scenario.effect == :ph ? exp(beta * xval) : exp(-shape * beta * xval)\n            cumhaz = t -&gt; scale * multiplier * (t^shape)\n            hazard = t -&gt; shape * scale * multiplier * (t^(shape - 1))\n        elseif scenario.family == \"gom\"\n            shape = cfg.shape\n            rate = cfg.rate\n            linpred = beta * xval\n            if scenario.effect == :ph\n                cumhaz = t -&gt; (rate / shape) * exp(linpred) * (exp(shape * t) - 1)\n                hazard = t -&gt; rate * exp(shape * t + linpred)\n            else\n                time_scale = exp(-linpred)\n                scaled_shape = shape * time_scale\n                scaled_rate = rate * time_scale\n                cumhaz = t -&gt; (scaled_rate / scaled_shape) * (exp(scaled_shape * t) - 1)\n                hazard = t -&gt; scaled_rate * exp(scaled_shape * t)\n            end\n        else\n            error(\"Unsupported family $(scenario.family)\")\n        end\n    end\n    cdf = t -&gt; t &lt;= 0 ? 0.0 : 1 - exp(-cumhaz(t))\n    pdf = t -&gt; t &lt;= 0 ? 0.0 : hazard(t) * exp(-cumhaz(t))\n    return cdf, pdf\nend\n\n\ndistribution_functions (generic function with 1 method)\n\n\n\n\nSimulation and plotting functions\nfunction collect_event_durations(model, nsamples; use_cached_strategy::Bool, rng::AbstractRNG)\n    durations = Vector{Float64}(undef, nsamples)\n    collected = 0\n    attempts = 0\n    max_attempts = nsamples * 200\n    strategy = use_cached_strategy ? CachedTransformStrategy() : DirectTransformStrategy()\n    while collected &lt; nsamples\n        path = simulate_path(model, 1; strategy = strategy, rng = rng)\n        attempts += 1\n        attempts &gt; max_attempts && error(\"Exceeded maximum attempts\")\n        if path.states[end] != path.states[1]\n            collected += 1\n            durations[collected] = path.times[end] - path.times[1]\n        end\n    end\n    return durations\nend\n\nfunction run_scenario_diagnostics(scenario::Scenario)\n    model, data = build_model(scenario)\n    \n    seed = hash(scenario.slug)\n    rng_tt = Random.MersenneTwister(seed)\n    rng_fb = Random.MersenneTwister(seed)\n    \n    durations_tt = collect_event_durations(model, SIM_SAMPLES; use_cached_strategy=true, rng=rng_tt)\n    durations_fb = collect_event_durations(model, SIM_SAMPLES; use_cached_strategy=false, rng=rng_fb)\n    \n    ecdf_tt = ecdf(durations_tt)\n    ecdf_fb = ecdf(durations_fb)\n    horizon = scenario.config.horizon\n    ts = collect(range(0.0, horizon; length = DIST_GRID_POINTS))\n    \n    cdf_base, pdf_base = distribution_functions(scenario)\n    cdf_fn, pdf_fn = truncate_distribution(cdf_base, pdf_base; lower = 0.0, upper = horizon)\n    \n    expected = cdf_fn.(ts)\n    empirical = ecdf_fb.(ts)\n    diff_curve = ecdf_tt.(ts) .- ecdf_fb.(ts)\n    max_abs_diff = maximum(abs.(diff_curve))\n    \n    # KS statistic at different sample sizes\n    sorted_durations = sort(durations_fb)\n    n_samples = length(sorted_durations)\n    expected_cdf_at_samples = cdf_fn.(sorted_durations)\n    eval_ns = filter(n -&gt; n &lt;= n_samples, [100, 200, 500, 1000, 2000, 5000, 10000, 20000, n_samples])\n    ks_at_n = zeros(length(eval_ns))\n    \n    for (idx, n) in enumerate(eval_ns)\n        max_diff = 0.0\n        for i in 1:n\n            cdf_i = expected_cdf_at_samples[i]\n            diff_upper = abs(i / n - cdf_i)\n            diff_lower = abs((i - 1) / n - cdf_i)\n            max_diff = max(max_diff, diff_upper, diff_lower)\n        end\n        ks_at_n[idx] = max_diff\n    end\n    \n    # Create figure\n    fig = Figure(size = (1400, 500))\n    \n    ax1 = Axis(fig[1, 1], title = \"ECDF vs Expected CDF\", xlabel = \"Duration\", ylabel = \"F(t)\")\n    lines!(ax1, ts, expected, color = :black, linewidth = 3, label = \"Theoretical\")\n    lines!(ax1, ts, empirical, color = :dodgerblue, linewidth = 2, label = \"Simulated\")\n    axislegend(ax1, position = :rb)\n    \n    ax2 = Axis(fig[1, 2], title = \"KS Statistic vs Sample Size\", \n               xlabel = \"n\", ylabel = \"Dₙ\", xscale = log10)\n    scatterlines!(ax2, eval_ns, ks_at_n, color = :crimson, linewidth = 2, markersize = 8)\n    \n    ylim_span = max(max_abs_diff, 1e-6)\n    ax3 = Axis(fig[1, 3], title = \"Time-Transform Parity: max|ΔF| = $(round(max_abs_diff; digits=4))\", \n               xlabel = \"Duration\", ylabel = \"ΔF(t)\")\n    lines!(ax3, ts, diff_curve, color = :seagreen, linewidth = 2)\n    hlines!(ax3, [0.0], color = :black, linestyle = :dash)\n    ylims!(ax3, (-1.1 * ylim_span, 1.1 * ylim_span))\n    \n    return fig, max_abs_diff\nend\n\n\nrun_scenario_diagnostics (generic function with 1 method)"
  },
  {
    "objectID": "04_simulation_diagnostics.html#methodology",
    "href": "04_simulation_diagnostics.html#methodology",
    "title": "Simulation Diagnostics",
    "section": "",
    "text": "This report validates that the MultistateModels.jl simulation engine produces event times that match the theoretical distributions defined by the hazard functions.\n\n\nFor each scenario, we:\n\nDefine a hazard model with known parameters\nSimulate many event times using simulate_path()\nCompare the empirical CDF (ECDF) to the theoretical CDF\nVerify time-transform parity - ensure that both the cached time-transform strategy and the direct fallback produce identical results\n\n\n\n\n\nECDF vs CDF: Visual comparison of simulated vs theoretical distributions\nKS statistic: Kolmogorov-Smirnov statistic \\(D_n = \\sup_t |F_n(t) - F(t)|\\), which should decrease as \\(\\sim 1/\\sqrt{n}\\)\nTime-transform parity: \\(\\Delta F(t) = F_{tt}(t) - F_{fb}(t)\\) should be zero\n\n\n\nConfiguration constants\nconst COVARIATE_VALUE = 1.5\nconst DELTA_U = sqrt(eps())\nconst DELTA_T = sqrt(eps())\nconst SIM_SAMPLES = 40_000\nconst DIST_GRID_POINTS = 400\n\nconst FAMILY_CONFIG = Dict(\n    \"exp\" =&gt; (; rate = 0.35, beta = 0.6, horizon = 5.0, hazard_start = 0.0),\n    \"wei\" =&gt; (; shape = 1.35, scale = 0.4, beta = -0.35, horizon = 5.0, hazard_start = 0.02),\n    \"gom\" =&gt; (; shape = 0.6, rate = 0.4, beta = 0.5, horizon = 5.0, hazard_start = 0.0),\n)\n\nconst TVC_CONFIG = Dict(\n    \"exp\" =&gt; (; rate = 0.35, beta = 0.6, horizon = 5.0, hazard_start = 0.0, \n               t_changes = [1.5, 3.0], x_values = [0.5, 1.5, 2.5]),\n    \"wei\" =&gt; (; rate = 0.0, shape = 1.35, scale = 0.4, beta = -0.35, horizon = 5.0, \n               hazard_start = 0.02, t_changes = [1.5, 3.0], x_values = [0.5, 1.5, 2.5]),\n    \"gom\" =&gt; (; rate = 0.4, shape = 0.6, beta = 0.5, horizon = 5.0, hazard_start = 0.0, \n               t_changes = [1.5, 3.0], x_values = [0.5, 1.5, 2.5]),\n)\n\n\nDict{String, NamedTuple} with 3 entries:\n  \"exp\" =&gt; (rate = 0.35, beta = 0.6, horizon = 5.0, hazard_start = 0.0, t_chang…\n  \"wei\" =&gt; (rate = 0.0, shape = 1.35, scale = 0.4, beta = -0.35, horizon = 5.0,…\n  \"gom\" =&gt; (rate = 0.4, shape = 0.6, beta = 0.5, horizon = 5.0, hazard_start = …\n\n\n\n\nHelper functions for scenario setup\nstruct Scenario\n    family::String\n    effect::Symbol\n    covariate_mode::Symbol\n    label::String\n    slug::String\n    config::NamedTuple\nend\n\nfunction Scenario(family::String, effect::Symbol, cov_mode::Symbol)\n    if cov_mode == :tvc\n        config = TVC_CONFIG[family]\n        label = string(uppercasefirst(lowercase(family)), \" \", uppercase(String(effect)), \n                      \" time-varying covariate\")\n    else\n        config = FAMILY_CONFIG[family]\n        label = string(uppercasefirst(lowercase(family)), \" \", uppercase(String(effect)), \n                      \" \", cov_mode == :covariate ? \"with covariate\" : \"baseline-only\")\n    end\n    slug = string(family, \"_\", effect, \"_\", cov_mode)\n    return Scenario(family, effect, cov_mode, label, slug, config)\nend\n\nfunction scenario_subject_df(scenario::Scenario)\n    horizon = scenario.config.horizon\n    if scenario.covariate_mode == :tvc\n        t_changes = scenario.config.t_changes\n        x_values = scenario.config.x_values\n        tstart_grid = vcat(0.0, t_changes)\n        tstop_grid = vcat(t_changes, horizon)\n        n_intervals = length(tstart_grid)\n        df = DataFrame(\n            id = fill(1, n_intervals),\n            tstart = tstart_grid,\n            tstop = tstop_grid,\n            statefrom = fill(1, n_intervals),\n            stateto = fill(2, n_intervals),\n            obstype = fill(1, n_intervals),\n            x = x_values,\n        )\n    else\n        df = DataFrame(\n            id = [1], tstart = [0.0], tstop = [horizon],\n            statefrom = [1], stateto = [2], obstype = [1],\n        )\n        if scenario.covariate_mode == :covariate\n            df.x = [COVARIATE_VALUE]\n        end\n    end\n    return df\nend\n\nfunction hazard_formula(scenario::Scenario)\n    (scenario.covariate_mode == :covariate || scenario.covariate_mode == :tvc) ? \n        @formula(0 ~ x) : @formula(0 ~ 1)\nend\n\nfunction scenario_parameter_vector(scenario::Scenario)\n    cfg = scenario.config\n    if scenario.family == \"exp\"\n        base = [log(cfg.rate)]\n    elseif scenario.family == \"wei\"\n        base = [log(cfg.shape), log(cfg.scale)]\n    elseif scenario.family == \"gom\"\n        base = [cfg.shape, log(cfg.rate)]\n    else\n        error(\"Unsupported family $(scenario.family)\")\n    end\n    return (scenario.covariate_mode == :covariate || scenario.covariate_mode == :tvc) ? \n        vcat(base, [cfg.beta]) : base\nend\n\nfunction build_model(scenario::Scenario)\n    data = scenario_subject_df(scenario)\n    hazard = Hazard(\n        hazard_formula(scenario),\n        scenario.family, 1, 2;\n        linpred_effect = scenario.effect,\n        time_transform = true,\n    )\n    model = multistatemodel(hazard; data = data)\n    pars = scenario_parameter_vector(scenario)\n    hazname = model.hazards[1].hazname\n    set_parameters!(model, NamedTuple{(hazname,)}((pars,)))\n    return model, data\nend\n\ncovariate_value(scenario::Scenario) = scenario.covariate_mode == :covariate ? COVARIATE_VALUE : 0.0\n\n\ncovariate_value (generic function with 1 method)\n\n\n\n\nTheoretical distribution functions\n# Piecewise cumulative hazard helpers for TVC\nfunction piecewise_exp_ph_cumhaz(t, rate, beta, t_changes, x_values)\n    cumhaz = 0.0\n    prev_t = 0.0\n    for (i, tc) in enumerate(t_changes)\n        if t &lt;= tc\n            cumhaz += rate * exp(beta * x_values[i]) * (t - prev_t)\n            return cumhaz\n        else\n            cumhaz += rate * exp(beta * x_values[i]) * (tc - prev_t)\n            prev_t = tc\n        end\n    end\n    cumhaz += rate * exp(beta * x_values[end]) * (t - prev_t)\n    return cumhaz\nend\n\nfunction piecewise_wei_ph_cumhaz(t, shape, scale, beta, t_changes, x_values)\n    cumhaz = 0.0\n    prev_t = 0.0\n    for (i, tc) in enumerate(t_changes)\n        if t &lt;= tc\n            cumhaz += scale * exp(beta * x_values[i]) * (t^shape - prev_t^shape)\n            return cumhaz\n        else\n            cumhaz += scale * exp(beta * x_values[i]) * (tc^shape - prev_t^shape)\n            prev_t = tc\n        end\n    end\n    cumhaz += scale * exp(beta * x_values[end]) * (t^shape - prev_t^shape)\n    return cumhaz\nend\n\nfunction distribution_functions(scenario::Scenario)\n    cfg = scenario.config\n    \n    if scenario.covariate_mode == :tvc\n        t_changes = cfg.t_changes\n        x_values = cfg.x_values\n        beta = cfg.beta\n        \n        if scenario.family == \"exp\"\n            rate = cfg.rate\n            cumhaz = t -&gt; piecewise_exp_ph_cumhaz(t, rate, beta, t_changes, x_values)\n            hazard = t -&gt; begin\n                for (i, tc) in enumerate(t_changes)\n                    if t &lt; tc\n                        return rate * exp(beta * x_values[i])\n                    end\n                end\n                return rate * exp(beta * x_values[end])\n            end\n        elseif scenario.family == \"wei\"\n            shape = cfg.shape\n            scale = cfg.scale\n            cumhaz = t -&gt; piecewise_wei_ph_cumhaz(t, shape, scale, beta, t_changes, x_values)\n            hazard = t -&gt; begin\n                for (i, tc) in enumerate(t_changes)\n                    if t &lt; tc\n                        return shape * scale * exp(beta * x_values[i]) * (t^(shape - 1))\n                    end\n                end\n                return shape * scale * exp(beta * x_values[end]) * (t^(shape - 1))\n            end\n        else\n            error(\"TVC not implemented for family $(scenario.family)\")\n        end\n    else\n        xval = covariate_value(scenario)\n        beta = scenario.covariate_mode == :covariate ? cfg.beta : 0.0\n        \n        if scenario.family == \"exp\"\n            base_rate = cfg.rate\n            rate = scenario.effect == :ph ? base_rate * exp(beta * xval) : base_rate * exp(-beta * xval)\n            cumhaz = t -&gt; rate * t\n            hazard = _ -&gt; rate\n        elseif scenario.family == \"wei\"\n            shape = cfg.shape\n            scale = cfg.scale\n            multiplier = scenario.effect == :ph ? exp(beta * xval) : exp(-shape * beta * xval)\n            cumhaz = t -&gt; scale * multiplier * (t^shape)\n            hazard = t -&gt; shape * scale * multiplier * (t^(shape - 1))\n        elseif scenario.family == \"gom\"\n            shape = cfg.shape\n            rate = cfg.rate\n            linpred = beta * xval\n            if scenario.effect == :ph\n                cumhaz = t -&gt; (rate / shape) * exp(linpred) * (exp(shape * t) - 1)\n                hazard = t -&gt; rate * exp(shape * t + linpred)\n            else\n                time_scale = exp(-linpred)\n                scaled_shape = shape * time_scale\n                scaled_rate = rate * time_scale\n                cumhaz = t -&gt; (scaled_rate / scaled_shape) * (exp(scaled_shape * t) - 1)\n                hazard = t -&gt; scaled_rate * exp(scaled_shape * t)\n            end\n        else\n            error(\"Unsupported family $(scenario.family)\")\n        end\n    end\n    cdf = t -&gt; t &lt;= 0 ? 0.0 : 1 - exp(-cumhaz(t))\n    pdf = t -&gt; t &lt;= 0 ? 0.0 : hazard(t) * exp(-cumhaz(t))\n    return cdf, pdf\nend\n\n\ndistribution_functions (generic function with 1 method)\n\n\n\n\nSimulation and plotting functions\nfunction collect_event_durations(model, nsamples; use_cached_strategy::Bool, rng::AbstractRNG)\n    durations = Vector{Float64}(undef, nsamples)\n    collected = 0\n    attempts = 0\n    max_attempts = nsamples * 200\n    strategy = use_cached_strategy ? CachedTransformStrategy() : DirectTransformStrategy()\n    while collected &lt; nsamples\n        path = simulate_path(model, 1; strategy = strategy, rng = rng)\n        attempts += 1\n        attempts &gt; max_attempts && error(\"Exceeded maximum attempts\")\n        if path.states[end] != path.states[1]\n            collected += 1\n            durations[collected] = path.times[end] - path.times[1]\n        end\n    end\n    return durations\nend\n\nfunction run_scenario_diagnostics(scenario::Scenario)\n    model, data = build_model(scenario)\n    \n    seed = hash(scenario.slug)\n    rng_tt = Random.MersenneTwister(seed)\n    rng_fb = Random.MersenneTwister(seed)\n    \n    durations_tt = collect_event_durations(model, SIM_SAMPLES; use_cached_strategy=true, rng=rng_tt)\n    durations_fb = collect_event_durations(model, SIM_SAMPLES; use_cached_strategy=false, rng=rng_fb)\n    \n    ecdf_tt = ecdf(durations_tt)\n    ecdf_fb = ecdf(durations_fb)\n    horizon = scenario.config.horizon\n    ts = collect(range(0.0, horizon; length = DIST_GRID_POINTS))\n    \n    cdf_base, pdf_base = distribution_functions(scenario)\n    cdf_fn, pdf_fn = truncate_distribution(cdf_base, pdf_base; lower = 0.0, upper = horizon)\n    \n    expected = cdf_fn.(ts)\n    empirical = ecdf_fb.(ts)\n    diff_curve = ecdf_tt.(ts) .- ecdf_fb.(ts)\n    max_abs_diff = maximum(abs.(diff_curve))\n    \n    # KS statistic at different sample sizes\n    sorted_durations = sort(durations_fb)\n    n_samples = length(sorted_durations)\n    expected_cdf_at_samples = cdf_fn.(sorted_durations)\n    eval_ns = filter(n -&gt; n &lt;= n_samples, [100, 200, 500, 1000, 2000, 5000, 10000, 20000, n_samples])\n    ks_at_n = zeros(length(eval_ns))\n    \n    for (idx, n) in enumerate(eval_ns)\n        max_diff = 0.0\n        for i in 1:n\n            cdf_i = expected_cdf_at_samples[i]\n            diff_upper = abs(i / n - cdf_i)\n            diff_lower = abs((i - 1) / n - cdf_i)\n            max_diff = max(max_diff, diff_upper, diff_lower)\n        end\n        ks_at_n[idx] = max_diff\n    end\n    \n    # Create figure\n    fig = Figure(size = (1400, 500))\n    \n    ax1 = Axis(fig[1, 1], title = \"ECDF vs Expected CDF\", xlabel = \"Duration\", ylabel = \"F(t)\")\n    lines!(ax1, ts, expected, color = :black, linewidth = 3, label = \"Theoretical\")\n    lines!(ax1, ts, empirical, color = :dodgerblue, linewidth = 2, label = \"Simulated\")\n    axislegend(ax1, position = :rb)\n    \n    ax2 = Axis(fig[1, 2], title = \"KS Statistic vs Sample Size\", \n               xlabel = \"n\", ylabel = \"Dₙ\", xscale = log10)\n    scatterlines!(ax2, eval_ns, ks_at_n, color = :crimson, linewidth = 2, markersize = 8)\n    \n    ylim_span = max(max_abs_diff, 1e-6)\n    ax3 = Axis(fig[1, 3], title = \"Time-Transform Parity: max|ΔF| = $(round(max_abs_diff; digits=4))\", \n               xlabel = \"Duration\", ylabel = \"ΔF(t)\")\n    lines!(ax3, ts, diff_curve, color = :seagreen, linewidth = 2)\n    hlines!(ax3, [0.0], color = :black, linestyle = :dash)\n    ylims!(ax3, (-1.1 * ylim_span, 1.1 * ylim_span))\n    \n    return fig, max_abs_diff\nend\n\n\nrun_scenario_diagnostics (generic function with 1 method)"
  },
  {
    "objectID": "04_simulation_diagnostics.html#parametric-families",
    "href": "04_simulation_diagnostics.html#parametric-families",
    "title": "Simulation Diagnostics",
    "section": "2. Parametric Families",
    "text": "2. Parametric Families\n\n2.1 Exponential\nThe exponential hazard: \\(h(t) = \\text{rate}\\)\nParameterization:\n\n\n\n\n\n\n\n\nEffect\nHazard\nCumulative Hazard\n\n\n\n\nPH\n\\(h(t\\|x) = \\text{rate} \\cdot e^{\\beta x}\\)\n\\(H(t\\|x) = \\text{rate} \\cdot e^{\\beta x} \\cdot t\\)\n\n\nAFT\n\\(h(t\\|x) = \\text{rate} \\cdot e^{-\\beta x}\\)\n\\(H(t\\|x) = \\text{rate} \\cdot e^{-\\beta x} \\cdot t\\)\n\n\n\n\nPH Baseline-Only\n\n\nShow code\nscenario = Scenario(\"exp\", :ph, :baseline)\nfig, max_diff = run_scenario_diagnostics(scenario)\nfig\n\n\n\n┌ Warning: Found `resolution` in the theme when creating a `Scene`. The `resolution` keyword for `Scene`s and `Figure`s has been deprecated. Use `Figure(; size = ...` or `Scene(; size = ...)` instead, which better reflects that this is a unitless size and not a pixel resolution. The key could also come from `set_theme!` calls or related theming functions.\n\n└ @ Makie ~/.julia/packages/Makie/TOy8O/src/scenes.jl:264\n\n\n\n\n\n\n\n\n\nPH with Covariate\n\n\nShow code\nscenario = Scenario(\"exp\", :ph, :covariate)\nfig, max_diff = run_scenario_diagnostics(scenario)\nfig\n\n\n\n┌ Warning: Found `resolution` in the theme when creating a `Scene`. The `resolution` keyword for `Scene`s and `Figure`s has been deprecated. Use `Figure(; size = ...` or `Scene(; size = ...)` instead, which better reflects that this is a unitless size and not a pixel resolution. The key could also come from `set_theme!` calls or related theming functions.\n\n└ @ Makie ~/.julia/packages/Makie/TOy8O/src/scenes.jl:264\n\n\n\n\n\n\n\n\n\nAFT Baseline-Only\n\n\nShow code\nscenario = Scenario(\"exp\", :aft, :baseline)\nfig, max_diff = run_scenario_diagnostics(scenario)\nfig\n\n\n\n┌ Warning: Found `resolution` in the theme when creating a `Scene`. The `resolution` keyword for `Scene`s and `Figure`s has been deprecated. Use `Figure(; size = ...` or `Scene(; size = ...)` instead, which better reflects that this is a unitless size and not a pixel resolution. The key could also come from `set_theme!` calls or related theming functions.\n\n└ @ Makie ~/.julia/packages/Makie/TOy8O/src/scenes.jl:264\n\n\n\n\n\n\n\n\n\nAFT with Covariate\n\n\nShow code\nscenario = Scenario(\"exp\", :aft, :covariate)\nfig, max_diff = run_scenario_diagnostics(scenario)\nfig\n\n\n\n┌ Warning: Found `resolution` in the theme when creating a `Scene`. The `resolution` keyword for `Scene`s and `Figure`s has been deprecated. Use `Figure(; size = ...` or `Scene(; size = ...)` instead, which better reflects that this is a unitless size and not a pixel resolution. The key could also come from `set_theme!` calls or related theming functions.\n\n└ @ Makie ~/.julia/packages/Makie/TOy8O/src/scenes.jl:264\n\n\n\n\n\n\n\n\n\n\n\n2.2 Weibull\nThe Weibull hazard: \\(h(t) = \\text{shape} \\cdot \\text{scale} \\cdot t^{\\text{shape}-1}\\)\nParameterization:\n\n\n\n\n\n\n\n\nEffect\nHazard\nCumulative Hazard\n\n\n\n\nPH\n\\(h(t\\|x) = k \\cdot \\lambda \\cdot t^{k-1} \\cdot e^{\\beta x}\\)\n\\(H(t\\|x) = \\lambda \\cdot e^{\\beta x} \\cdot t^k\\)\n\n\nAFT\n\\(h(t\\|x) = k \\cdot \\lambda \\cdot t^{k-1} \\cdot e^{-k\\beta x}\\)\n\\(H(t\\|x) = \\lambda \\cdot e^{-k\\beta x} \\cdot t^k\\)\n\n\n\n\nPH Baseline-Only\n\n\nShow code\nscenario = Scenario(\"wei\", :ph, :baseline)\nfig, max_diff = run_scenario_diagnostics(scenario)\nfig\n\n\n\n******************************************************************************\nThis program contains Ipopt, a library for large-scale nonlinear optimization.\n Ipopt is released as open source code under the Eclipse Public License (EPL).\n         For more information visit https://github.com/coin-or/Ipopt\n******************************************************************************\n\n\n\n\n┌ Warning: Found `resolution` in the theme when creating a `Scene`. The `resolution` keyword for `Scene`s and `Figure`s has been deprecated. Use `Figure(; size = ...` or `Scene(; size = ...)` instead, which better reflects that this is a unitless size and not a pixel resolution. The key could also come from `set_theme!` calls or related theming functions.\n\n└ @ Makie ~/.julia/packages/Makie/TOy8O/src/scenes.jl:264\n\n\n\n\n\n\n\n\n\nPH with Covariate\n\n\nShow code\nscenario = Scenario(\"wei\", :ph, :covariate)\nfig, max_diff = run_scenario_diagnostics(scenario)\nfig\n\n\n\n┌ Warning: Found `resolution` in the theme when creating a `Scene`. The `resolution` keyword for `Scene`s and `Figure`s has been deprecated. Use `Figure(; size = ...` or `Scene(; size = ...)` instead, which better reflects that this is a unitless size and not a pixel resolution. The key could also come from `set_theme!` calls or related theming functions.\n\n└ @ Makie ~/.julia/packages/Makie/TOy8O/src/scenes.jl:264\n\n\n\n\n\n\n\n\n\nAFT Baseline-Only\n\n\nShow code\nscenario = Scenario(\"wei\", :aft, :baseline)\nfig, max_diff = run_scenario_diagnostics(scenario)\nfig\n\n\n\n┌ Warning: Found `resolution` in the theme when creating a `Scene`. The `resolution` keyword for `Scene`s and `Figure`s has been deprecated. Use `Figure(; size = ...` or `Scene(; size = ...)` instead, which better reflects that this is a unitless size and not a pixel resolution. The key could also come from `set_theme!` calls or related theming functions.\n\n└ @ Makie ~/.julia/packages/Makie/TOy8O/src/scenes.jl:264\n\n\n\n\n\n\n\n\n\nAFT with Covariate\n\n\nShow code\nscenario = Scenario(\"wei\", :aft, :covariate)\nfig, max_diff = run_scenario_diagnostics(scenario)\nfig\n\n\n\n┌ Warning: Found `resolution` in the theme when creating a `Scene`. The `resolution` keyword for `Scene`s and `Figure`s has been deprecated. Use `Figure(; size = ...` or `Scene(; size = ...)` instead, which better reflects that this is a unitless size and not a pixel resolution. The key could also come from `set_theme!` calls or related theming functions.\n\n└ @ Makie ~/.julia/packages/Makie/TOy8O/src/scenes.jl:264\n\n\n\n\n\n\n\n\n\n\n\n2.3 Gompertz\nThe Gompertz hazard (flexsurv parameterization): \\(h(t) = \\text{rate} \\cdot e^{\\text{shape} \\cdot t}\\)\nParameterization:\n\n\n\n\n\n\n\n\nEffect\nHazard\nCumulative Hazard\n\n\n\n\nPH\n\\(h(t\\|x) = r \\cdot e^{at + \\beta x}\\)\n\\(H(t\\|x) = \\frac{r}{a} e^{\\beta x} (e^{at} - 1)\\)\n\n\nAFT\n\\(h(t\\|x) = r' \\cdot e^{a' t}\\) where \\(r' = r e^{-\\beta x}\\), \\(a' = a e^{-\\beta x}\\)\n\\(H(t\\|x) = \\frac{r'}{a'} (e^{a't} - 1)\\)\n\n\n\n\nPH Baseline-Only\n\n\nShow code\nscenario = Scenario(\"gom\", :ph, :baseline)\nfig, max_diff = run_scenario_diagnostics(scenario)\nfig\n\n\n\n┌ Warning: Found `resolution` in the theme when creating a `Scene`. The `resolution` keyword for `Scene`s and `Figure`s has been deprecated. Use `Figure(; size = ...` or `Scene(; size = ...)` instead, which better reflects that this is a unitless size and not a pixel resolution. The key could also come from `set_theme!` calls or related theming functions.\n\n└ @ Makie ~/.julia/packages/Makie/TOy8O/src/scenes.jl:264\n\n\n\n\n\n\n\n\n\nPH with Covariate\n\n\nShow code\nscenario = Scenario(\"gom\", :ph, :covariate)\nfig, max_diff = run_scenario_diagnostics(scenario)\nfig\n\n\n\n┌ Warning: Found `resolution` in the theme when creating a `Scene`. The `resolution` keyword for `Scene`s and `Figure`s has been deprecated. Use `Figure(; size = ...` or `Scene(; size = ...)` instead, which better reflects that this is a unitless size and not a pixel resolution. The key could also come from `set_theme!` calls or related theming functions.\n\n└ @ Makie ~/.julia/packages/Makie/TOy8O/src/scenes.jl:264\n\n\n\n\n\n\n\n\n\nAFT Baseline-Only\n\n\nShow code\nscenario = Scenario(\"gom\", :aft, :baseline)\nfig, max_diff = run_scenario_diagnostics(scenario)\nfig\n\n\n\n┌ Warning: Found `resolution` in the theme when creating a `Scene`. The `resolution` keyword for `Scene`s and `Figure`s has been deprecated. Use `Figure(; size = ...` or `Scene(; size = ...)` instead, which better reflects that this is a unitless size and not a pixel resolution. The key could also come from `set_theme!` calls or related theming functions.\n\n└ @ Makie ~/.julia/packages/Makie/TOy8O/src/scenes.jl:264\n\n\n\n\n\n\n\n\n\nAFT with Covariate\n\n\nShow code\nscenario = Scenario(\"gom\", :aft, :covariate)\nfig, max_diff = run_scenario_diagnostics(scenario)\nfig\n\n\n\n┌ Warning: Found `resolution` in the theme when creating a `Scene`. The `resolution` keyword for `Scene`s and `Figure`s has been deprecated. Use `Figure(; size = ...` or `Scene(; size = ...)` instead, which better reflects that this is a unitless size and not a pixel resolution. The key could also come from `set_theme!` calls or related theming functions.\n\n└ @ Makie ~/.julia/packages/Makie/TOy8O/src/scenes.jl:264"
  },
  {
    "objectID": "04_simulation_diagnostics.html#b-splines",
    "href": "04_simulation_diagnostics.html#b-splines",
    "title": "Simulation Diagnostics",
    "section": "3. B-Splines",
    "text": "3. B-Splines\n\n\n\n\n\n\nWarningStatus: Not Yet Implemented\n\n\n\nB-spline scenarios will be added once the spline infrastructure is integrated into this report.\n\n\n\n3.1 Cubic Splines (4 Interior Knots)\nTo be implemented\n\n\n3.2 Quadratic Splines (3 Interior Knots)\nTo be implemented\n\n\n3.3 Natural Splines\nTo be implemented\n\n\n3.4 Splines with Covariates (PH)\nTo be implemented"
  },
  {
    "objectID": "04_simulation_diagnostics.html#time-varying-covariates",
    "href": "04_simulation_diagnostics.html#time-varying-covariates",
    "title": "Simulation Diagnostics",
    "section": "4. Time-Varying Covariates",
    "text": "4. Time-Varying Covariates\n\n4.1 Exponential PH with Step-Function TVC\n\n\nShow code\nscenario = Scenario(\"exp\", :ph, :tvc)\nfig, max_diff = run_scenario_diagnostics(scenario)\nfig\n\n\n\n┌ Warning: Found `resolution` in the theme when creating a `Scene`. The `resolution` keyword for `Scene`s and `Figure`s has been deprecated. Use `Figure(; size = ...` or `Scene(; size = ...)` instead, which better reflects that this is a unitless size and not a pixel resolution. The key could also come from `set_theme!` calls or related theming functions.\n\n└ @ Makie ~/.julia/packages/Makie/TOy8O/src/scenes.jl:264\n\n\n\n\n\n\n\n\n\n4.2 Weibull PH with Step-Function TVC\n\n\nShow code\nscenario = Scenario(\"wei\", :ph, :tvc)\nfig, max_diff = run_scenario_diagnostics(scenario)\nfig\n\n\n\n┌ Warning: Found `resolution` in the theme when creating a `Scene`. The `resolution` keyword for `Scene`s and `Figure`s has been deprecated. Use `Figure(; size = ...` or `Scene(; size = ...)` instead, which better reflects that this is a unitless size and not a pixel resolution. The key could also come from `set_theme!` calls or related theming functions.\n\n└ @ Makie ~/.julia/packages/Makie/TOy8O/src/scenes.jl:264"
  },
  {
    "objectID": "04_simulation_diagnostics.html#guarantees-validated",
    "href": "04_simulation_diagnostics.html#guarantees-validated",
    "title": "Simulation Diagnostics",
    "section": "5. Guarantees Validated",
    "text": "5. Guarantees Validated\nThis report validates the following guarantees:\n\nCall-stack accuracy: The eval_hazard, eval_cumhaz, and survprob functions produce values that match the closed-form analytical expressions.\nDistributional fidelity: The ECDF of simulated event times matches the theoretical CDF, with KS statistics consistent with the expected \\(O(1/\\sqrt{n})\\) convergence rate.\nTime-transform parity: Simulations using CachedTransformStrategy (time transforms enabled) produce identical results to DirectTransformStrategy (fallback), confirming that the caching optimization does not introduce bias.\nFamily coverage: All parametric families (Exponential, Weibull, Gompertz) with both PH and AFT covariate effects are validated."
  },
  {
    "objectID": "long_tests.html",
    "href": "long_tests.html",
    "title": "Long Test Status",
    "section": "",
    "text": "Long tests validate parameter recovery across all supported model configurations. Each test:\n\nSimulates data from a model with known true parameters (N=1000 subjects)\nFits the model to the simulated data\n\nCompares estimated parameters to true values\nVerifies distributional properties via prevalence and cumulative incidence plots\n\n\n\n23/28 tests passing | Last updated: 2026-01-01 18:28\n\n\n\n\n\n\nTest Name\nFamily\nData Type\nCovariates\nN\nStatus\n\n\n\n\nexp_exact_fixed\nexp\nexact\nfixed\n1000\n✅ Pass\n\n\nexp_exact_nocov\nexp\nexact\nnocov\n1000\n✅ Pass\n\n\nexp_exact_tvc\nexp\nexact\ntvc\n1000\n✅ Pass\n\n\nexp_panel_fixed\nexp\npanel\nfixed\n986\n✅ Pass\n\n\nexp_panel_nocov\nexp\npanel\nnocov\n990\n✅ Pass\n\n\nexp_panel_tvc\nexp\npanel\ntvc\n990\n✅ Pass\n\n\ngom_exact_fixed\ngom\nexact\nfixed\n1000\n✅ Pass\n\n\ngom_exact_nocov\ngom\nexact\nnocov\n1000\n✅ Pass\n\n\ngom_exact_tvc\ngom\nexact\ntvc\n1000\n✅ Pass\n\n\ngom_mcem_fixed\ngom\nmcem\nfixed\n984\n✅ Pass\n\n\ngom_mcem_nocov\ngom\nmcem\nnocov\n992\n✅ Pass\n\n\ngom_mcem_tvc\ngom\nmcem\ntvc\n993\n❌ Fail\n\n\npt_mixed_simple\nphasetype\nmixed\nnone\n1000\n✅ Pass\n\n\npt_mixed_structured\nphasetype\nmixed\nnone\n1000\n✅ Pass\n\n\npt_panel_fixed\nphasetype\npanel\nfixed\n1000\n❌ Fail\n\n\npt_panel_id\nphasetype\npanel\nnone\n1000\n✅ Pass\n\n\npt_panel_simple\nphasetype\npanel\nnone\n1000\n✅ Pass\n\n\npt_panel_tvc\nphasetype\npanel\ntvc\n1000\n❌ Fail\n\n\npt_exact_fixed\npt\nexact\nfixed\n1000\n✅ Pass\n\n\npt_exact_nocov\npt\nexact\nnocov\n1000\n✅ Pass\n\n\npt_exact_tvc\npt\nexact\ntvc\n1000\n✅ Pass\n\n\nsp_mcem_fixed\nsp\npanel\nfixed\n1000\n❌ Fail\n\n\nwei_exact_fixed\nwei\nexact\nfixed\n1000\n✅ Pass\n\n\nwei_exact_nocov\nwei\nexact\nnocov\n1000\n✅ Pass\n\n\nwei_exact_tvc\nwei\nexact\ntvc\n1000\n✅ Pass\n\n\nwei_mcem_fixed\nwei\nmcem\nfixed\n989\n✅ Pass\n\n\nwei_mcem_nocov\nwei\nmcem\nnocov\n991\n✅ Pass\n\n\nwei_mcem_tvc\nwei\nmcem\ntvc\n995\n❌ Fail"
  },
  {
    "objectID": "long_tests.html#test-inventory",
    "href": "long_tests.html#test-inventory",
    "title": "Long Test Status",
    "section": "",
    "text": "Long tests validate parameter recovery across all supported model configurations. Each test:\n\nSimulates data from a model with known true parameters (N=1000 subjects)\nFits the model to the simulated data\n\nCompares estimated parameters to true values\nVerifies distributional properties via prevalence and cumulative incidence plots\n\n\n\n23/28 tests passing | Last updated: 2026-01-01 18:28\n\n\n\n\n\n\nTest Name\nFamily\nData Type\nCovariates\nN\nStatus\n\n\n\n\nexp_exact_fixed\nexp\nexact\nfixed\n1000\n✅ Pass\n\n\nexp_exact_nocov\nexp\nexact\nnocov\n1000\n✅ Pass\n\n\nexp_exact_tvc\nexp\nexact\ntvc\n1000\n✅ Pass\n\n\nexp_panel_fixed\nexp\npanel\nfixed\n986\n✅ Pass\n\n\nexp_panel_nocov\nexp\npanel\nnocov\n990\n✅ Pass\n\n\nexp_panel_tvc\nexp\npanel\ntvc\n990\n✅ Pass\n\n\ngom_exact_fixed\ngom\nexact\nfixed\n1000\n✅ Pass\n\n\ngom_exact_nocov\ngom\nexact\nnocov\n1000\n✅ Pass\n\n\ngom_exact_tvc\ngom\nexact\ntvc\n1000\n✅ Pass\n\n\ngom_mcem_fixed\ngom\nmcem\nfixed\n984\n✅ Pass\n\n\ngom_mcem_nocov\ngom\nmcem\nnocov\n992\n✅ Pass\n\n\ngom_mcem_tvc\ngom\nmcem\ntvc\n993\n❌ Fail\n\n\npt_mixed_simple\nphasetype\nmixed\nnone\n1000\n✅ Pass\n\n\npt_mixed_structured\nphasetype\nmixed\nnone\n1000\n✅ Pass\n\n\npt_panel_fixed\nphasetype\npanel\nfixed\n1000\n❌ Fail\n\n\npt_panel_id\nphasetype\npanel\nnone\n1000\n✅ Pass\n\n\npt_panel_simple\nphasetype\npanel\nnone\n1000\n✅ Pass\n\n\npt_panel_tvc\nphasetype\npanel\ntvc\n1000\n❌ Fail\n\n\npt_exact_fixed\npt\nexact\nfixed\n1000\n✅ Pass\n\n\npt_exact_nocov\npt\nexact\nnocov\n1000\n✅ Pass\n\n\npt_exact_tvc\npt\nexact\ntvc\n1000\n✅ Pass\n\n\nsp_mcem_fixed\nsp\npanel\nfixed\n1000\n❌ Fail\n\n\nwei_exact_fixed\nwei\nexact\nfixed\n1000\n✅ Pass\n\n\nwei_exact_nocov\nwei\nexact\nnocov\n1000\n✅ Pass\n\n\nwei_exact_tvc\nwei\nexact\ntvc\n1000\n✅ Pass\n\n\nwei_mcem_fixed\nwei\nmcem\nfixed\n989\n✅ Pass\n\n\nwei_mcem_nocov\nwei\nmcem\nnocov\n991\n✅ Pass\n\n\nwei_mcem_tvc\nwei\nmcem\ntvc\n995\n❌ Fail"
  },
  {
    "objectID": "long_tests.html#test-results-by-family",
    "href": "long_tests.html#test-results-by-family",
    "title": "Long Test Status",
    "section": "Test Results by Family",
    "text": "Test Results by Family\n\nExponential\n\nExponential - Exact Data - Fixed Covariates\nTest: exp_exact_fixed | N: 1000 | Run: 2026-01-01T16:30:59.909 on penalized_splines (6b59be0)\n\n\nExponential - Exact Data - No Covariates\nTest: exp_exact_nocov | N: 1000 | Run: 2026-01-01T16:30:56.638 on penalized_splines (6b59be0)\n\n\nExponential - Exact Data - Time-Varying Covariates\nTest: exp_exact_tvc | N: 1000 | Run: 2026-01-01T16:31:00.825 on penalized_splines (6b59be0)\n\n\nExponential - Panel Data (Markov) - Fixed Covariates\nTest: exp_panel_fixed | N: 986 | Run: 2026-01-01T16:33:12.818 on penalized_splines (6b59be0)\n\n\nExponential - Panel Data (Markov) - No Covariates\nTest: exp_panel_nocov | N: 990 | Run: 2026-01-01T16:33:02.121 on penalized_splines (6b59be0)\n\n\nExponential - Panel Data (Markov) - Time-Varying Covariates\nTest: exp_panel_tvc | N: 990 | Run: 2026-01-01T16:33:23.251 on penalized_splines (6b59be0)\n\n\n\nWeibull\n\nWeibull - Exact Data - Fixed Covariates\nTest: wei_exact_fixed | N: 1000 | Run: 2026-01-01T16:31:38.432 on penalized_splines (6b59be0)\n\n\nWeibull - Exact Data - No Covariates\nTest: wei_exact_nocov | N: 1000 | Run: 2026-01-01T16:31:17.325 on penalized_splines (6b59be0)\n\n\nWeibull - Exact Data - Time-Varying Covariates\nTest: wei_exact_tvc | N: 1000 | Run: 2026-01-01T16:31:58.169 on penalized_splines (6b59be0)\n\n\nWeibull - Panel Data (MCEM) - Fixed Covariates\nTest: wei_mcem_fixed | N: 989 | Run: 2026-01-01T16:35:28.655 on penalized_splines (6b59be0)\n\n\nWeibull - Panel Data (MCEM) - No Covariates\nTest: wei_mcem_nocov | N: 991 | Run: 2026-01-01T16:34:12.161 on penalized_splines (6b59be0)\n\n\nWeibull - Panel Data (MCEM) - Time-Varying Covariates\nTest: wei_mcem_tvc | N: 995 | Run: 2026-01-01T16:36:30.196 on penalized_splines (6b59be0)\n\n\n\nGompertz\n\nGompertz - Exact Data - Fixed Covariates\nTest: gom_exact_fixed | N: 1000 | Run: 2026-01-01T16:32:31.437 on penalized_splines (6b59be0)\n\n\nGompertz - Exact Data - No Covariates\nTest: gom_exact_nocov | N: 1000 | Run: 2026-01-01T16:32:13.335 on penalized_splines (6b59be0)\n\n\nGompertz - Exact Data - Time-Varying Covariates\nTest: gom_exact_tvc | N: 1000 | Run: 2026-01-01T16:32:51.437 on penalized_splines (6b59be0)\n\n\nGompertz - Panel Data (MCEM) - Fixed Covariates\nTest: gom_mcem_fixed | N: 984 | Run: 2026-01-01T16:37:58.797 on penalized_splines (6b59be0)\n\n\nGompertz - Panel Data (MCEM) - No Covariates\nTest: gom_mcem_nocov | N: 992 | Run: 2026-01-01T16:37:05.896 on penalized_splines (6b59be0)\n\n\nGompertz - Panel Data (MCEM) - Time-Varying Covariates\nTest: gom_mcem_tvc | N: 993 | Run: 2026-01-01T16:38:53.898 on penalized_splines (6b59be0)\n\n\n\nPhase-Type\n\nPhase-Type - Exact Data - Fixed Covariates\nTest: pt_exact_fixed | N: 1000 | Run: 2026-01-01T16:49:44.907 on penalized_splines (6b59be0)\n\n\nPhase-Type - Exact Data - No Covariates\nTest: pt_exact_nocov | N: 1000 | Run: 2026-01-01T16:49:39.984 on penalized_splines (6b59be0)\n\n\nPhase-Type - Exact Data - Time-Varying Covariates\nTest: pt_exact_tvc | N: 1000 | Run: 2026-01-01T16:49:45.453 on penalized_splines (6b59be0)\n\n\n\nSpline\n\nSpline - Panel Data (Markov) - Fixed Covariates\nTest: sp_mcem_fixed | N: 1000 | Run: 2026-01-01T17:08:41.835 on penalized_splines (6b59be0)\n\n\n\n---\n\n### Exponential - Exact Data - Fixed Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n4×8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nh12_beta\n0.5\n0.526746\n0.065457\n0.39845\n0.655041\n5.34913\n✓\n\n\n2\nh12_log_rate\n-1.89712\n-1.88978\n0.0457869\n-1.97952\n-1.80004\n0.386995\n✓\n\n\n3\nh23_beta\n0.5\n0.479096\n0.0753465\n0.331417\n0.626775\n4.18081\n✓\n\n\n4\nh23_log_rate\n-2.12026\n-2.06702\n0.0555556\n-2.1759\n-1.95813\n2.51137\n✓\n\n\n\n\n\n\n\n---\n\n### Exponential - Exact Data - No Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n2×8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nh12_log_rate\n-1.89712\n-1.84645\n0.0332045\n-1.91154\n-1.78137\n2.67065\n✓\n\n\n2\nh23_log_rate\n-2.12026\n-2.09038\n0.0403567\n-2.16948\n-2.01128\n1.40959\n✓\n\n\n\n\n\n\n\n---\n\n### Exponential - Exact Data - Time-Varying Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n4×8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nh12_beta\n0.5\n0.411826\n0.065087\n0.284256\n0.539397\n17.6348\n✓\n\n\n2\nh12_log_rate\n-1.89712\n-1.84652\n0.0428746\n-1.93056\n-1.76249\n2.66705\n✓\n\n\n3\nh23_beta\n0.5\n0.339203\n0.0864828\n0.169696\n0.508709\n32.1595\n✓\n\n\n4\nh23_log_rate\n-2.12026\n-1.95338\n0.0764719\n-2.10327\n-1.8035\n7.87084\n✗\n\n\n\n\n\n\n\n---\n\n### Exponential - Panel Data (Markov) - Fixed Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n4×8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nh12_beta\n0.5\n0.532568\n0.0771887\n0.381278\n0.683858\n6.51366\n✓\n\n\n2\nh12_log_rate\n-1.89712\n-1.85012\n0.0546095\n-1.95716\n-1.74309\n2.47726\n✓\n\n\n3\nh23_beta\n0.5\n0.45703\n0.0898408\n0.280942\n0.633118\n8.59399\n✓\n\n\n4\nh23_log_rate\n-2.12026\n-2.0921\n0.0696143\n-2.22855\n-1.95566\n1.32826\n✓\n\n\n\n\n\n\n\n---\n\n### Exponential - Panel Data (Markov) - No Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n2×8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nh12_log_rate\n-1.89712\n-1.87335\n0.0394745\n-1.95072\n-1.79598\n1.25309\n✓\n\n\n2\nh23_log_rate\n-2.12026\n-2.09382\n0.0503324\n-2.19247\n-1.99517\n1.24721\n✓\n\n\n\n\n\n\n\n---\n\n### Exponential - Panel Data (Markov) - Time-Varying Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n4×8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nh12_beta\n0.5\n0.473535\n0.073794\n0.328899\n0.618171\n5.293\n✓\n\n\n2\nh12_log_rate\n-1.89712\n-1.8745\n0.0499861\n-1.97247\n-1.77653\n1.19237\n✓\n\n\n3\nh23_beta\n0.5\n0.484892\n0.0985236\n0.291786\n0.677998\n3.02159\n✓\n\n\n4\nh23_log_rate\n-2.12026\n-2.07011\n0.0844214\n-2.23558\n-1.90465\n2.36528\n✓\n\n\n\n\n\n\n\n---\n\n### Gompertz - Exact Data - Fixed Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n6×8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nh12_beta\n0.5\n0.412447\n0.0648108\n0.285418\n0.539476\n17.5106\n✓\n\n\n2\nh12_log_rate\n-1.89712\n-1.77672\n0.0638228\n-1.90181\n-1.65163\n6.34647\n✓\n\n\n3\nh12_shape\n0.05\n0.0371486\n0.00986178\n0.0178195\n0.0564777\n25.7028\n✓\n\n\n4\nh23_beta\n0.5\n0.53814\n0.0711483\n0.398689\n0.677591\n7.628\n✓\n\n\n5\nh23_log_rate\n-2.12026\n-2.14863\n0.0727701\n-2.29126\n-2.006\n1.3377\n✓\n\n\n6\nh23_shape\n0.03\n0.0384585\n0.0109827\n0.0169325\n0.0599845\n28.1951\n✓\n\n\n\n\n\n\n\n---\n\n### Gompertz - Exact Data - No Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n4×8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nh12_log_rate\n-1.89712\n-1.87834\n0.0530357\n-1.98229\n-1.77439\n0.989759\n✓\n\n\n2\nh12_shape\n0.05\n0.04426\n0.00878205\n0.0270472\n0.0614728\n11.48\n✓\n\n\n3\nh23_log_rate\n-2.12026\n-2.09246\n0.0628666\n-2.21568\n-1.96924\n1.31137\n✓\n\n\n4\nh23_shape\n0.03\n0.0345311\n0.0117755\n0.0114512\n0.057611\n15.1037\n✓\n\n\n\n\n\n\n\n---\n\n### Gompertz - Exact Data - Time-Varying Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n6×8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nh12_beta\n0.5\n0.384156\n0.116553\n0.155711\n0.612601\n23.1688\n✓\n\n\n2\nh12_log_rate\n-1.89712\n-1.87818\n0.0577317\n-1.99134\n-1.76503\n0.998275\n✓\n\n\n3\nh12_shape\n0.05\n0.0545131\n0.0177867\n0.0196513\n0.089375\n9.02628\n✓\n\n\n4\nh23_beta\n0.5\n0.480954\n0.0926818\n0.299298\n0.66261\n3.80921\n✓\n\n\n5\nh23_log_rate\n-2.12026\n-2.05207\n0.079264\n-2.20743\n-1.89672\n3.21609\n✓\n\n\n6\nh23_shape\n0.03\n0.0198651\n0.0125821\n-0.00479584\n0.044526\n33.7831\n✓\n\n\n\n\n\n\n\n---\n\n### Gompertz - Panel Data (MCEM) - Fixed Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n6×8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nh12_beta\n0.5\n0.284498\n0.0755857\n0.13635\n0.432646\n43.1005\n✗\n\n\n2\nh12_log_rate\n-1.89712\n-1.73651\n0.0791911\n-1.89172\n-1.58129\n8.46606\n✗\n\n\n3\nh12_shape\n0.05\n0.168865\n0.0178191\n0.13394\n0.20379\n237.73\n✗\n\n\n4\nh23_beta\n0.5\n0.119758\n0.0867347\n-0.0502423\n0.289758\n76.0485\n✗\n\n\n5\nh23_log_rate\n-2.12026\n-1.69718\n0.0946568\n-1.8827\n-1.51165\n19.9545\n✗\n\n\n6\nh23_shape\n0.03\n0.191964\n0.0210166\n0.150771\n0.233156\n539.878\n✗\n\n\n\n\n\n\n\n---\n\n### Gompertz - Panel Data (MCEM) - No Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n4×8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nh12_log_rate\n-1.89712\n-1.84424\n0.0694454\n-1.98035\n-1.70812\n2.78757\n✓\n\n\n2\nh12_shape\n0.05\n0.190753\n0.0166652\n0.158089\n0.223416\n281.505\n✗\n\n\n3\nh23_log_rate\n-2.12026\n-1.55959\n0.0871115\n-1.73033\n-1.38885\n26.4435\n✗\n\n\n4\nh23_shape\n0.03\n0.199919\n0.0250899\n0.150742\n0.249095\n566.395\n✗\n\n\n\n\n\n\n\n---\n\n### Gompertz - Panel Data (MCEM) - Time-Varying Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n6×8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nh12_beta\n0.5\n0.229463\n0.132961\n-0.03114\n0.490066\n54.1074\n✗\n\n\n2\nh12_log_rate\n-1.89712\n-2.1207\n0.0792563\n-2.27604\n-1.96536\n11.7853\n✗\n\n\n3\nh12_shape\n0.05\n0.225953\n0.0307129\n0.165756\n0.286151\n351.907\n✗\n\n\n4\nh23_beta\n0.5\n1.09197\n0.0965364\n0.902756\n1.28118\n118.393\n✗\n\n\n5\nh23_log_rate\n-2.12026\n-1.97517\n0.0811326\n-2.13419\n-1.81615\n6.84318\n✓\n\n\n6\nh23_shape\n0.03\n0.077206\n0.0226209\n0.032869\n0.121543\n157.353\n✗\n\n\n\n\n\n\n\n---\n\n### Phase-Type - Exact Data - Fixed Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n6×8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nbeta_1\n0.0\n0.0204126\n0.0847214\n-0.145641\n0.186466\n2.04126\n✓\n\n\n2\nbeta_2\n0.4\n0.43372\n0.0964374\n0.244703\n0.622737\n8.42994\n✓\n\n\n3\nbeta_3\n0.3\n0.324105\n0.0849959\n0.157513\n0.490697\n8.03504\n✓\n\n\n4\nlog_rate_1\n-0.693147\n-0.702404\n0.0582223\n-0.81652\n-0.588289\n1.33552\n✓\n\n\n5\nlog_rate_2\n-1.20397\n-1.15827\n0.0731272\n-1.3016\n-1.01494\n3.79592\n✓\n\n\n6\nlog_rate_3\n-0.510826\n-0.513388\n0.058621\n-0.628285\n-0.398491\n0.501624\n✓\n\n\n\n\n\n\n\n---\n\n### Phase-Type - Exact Data - No Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n8×8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nlog_rate_1\n-0.693147\n-0.779814\n0.0513665\n-0.880492\n-0.679135\n12.5033\n✓\n\n\n2\nlog_rate_2\n-1.20397\n-1.07544\n0.0595491\n-1.19216\n-0.958727\n10.6755\n✗\n\n\n3\nlog_rate_3\n-0.916291\n-0.89135\n0.0543125\n-0.997802\n-0.784897\n2.72194\n✓\n\n\n4\nlog_rate_4\n-1.60944\n-1.55932\n0.0751646\n-1.70664\n-1.41199\n3.11418\n✓\n\n\n5\nlog_rate_5\n-1.38629\n-1.44216\n0.0708881\n-1.5811\n-1.30322\n4.03001\n✓\n\n\n6\nlog_rate_6\n-1.04982\n-1.0177\n0.0631194\n-1.14141\n-0.893983\n3.06004\n✓\n\n\n7\nlog_rate_7\n-1.20397\n-1.22994\n0.0701862\n-1.36751\n-1.09238\n2.15713\n✓\n\n\n8\nlog_rate_8\n-1.89712\n-1.75227\n0.0776151\n-1.9044\n-1.60015\n7.63512\n✓\n\n\n\n\n\n\n\n---\n\n### Phase-Type - Exact Data - Time-Varying Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n6×8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nbeta_1\n0.0\n-0.0184989\n0.174056\n-0.359649\n0.322651\n1.84989\n✓\n\n\n2\nbeta_2\n0.5\n0.454755\n0.179613\n0.102714\n0.806797\n9.04891\n✓\n\n\n3\nbeta_3\n0.4\n0.319135\n0.0986186\n0.125843\n0.512428\n20.2162\n✓\n\n\n4\nlog_rate_1\n-0.916291\n-0.875647\n0.0415227\n-0.957031\n-0.794262\n4.43572\n✓\n\n\n5\nlog_rate_2\n-1.38629\n-1.37789\n0.0533761\n-1.48251\n-1.27327\n0.60635\n✓\n\n\n6\nlog_rate_3\n-0.693147\n-0.584399\n0.0457389\n-0.674047\n-0.49475\n15.6891\n✗\n\n\n\n\n\n\n\n---\n\n### phasetype - mixed - none - Details\n\n\n**Parameter Recovery:**\n\n\n\n3×8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\np1\n-1.04982\n-1.03833\n0.0460167\n-1.12852\n-0.948132\n1.09514\n✓\n\n\n2\np2\n-1.38629\n-1.40182\n0.0554219\n-1.51045\n-1.2932\n1.12018\n✓\n\n\n3\np3\n-0.798508\n-0.79215\n0.044898\n-0.88015\n-0.70415\n0.796161\n✓\n\n\n\n\n\n\n\n---\n\n### phasetype - mixed - none - Details\n\n\n**Parameter Recovery:**\n\n\n\n3×8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\np1\n-0.916291\n-0.951913\n0.0471724\n-1.04437\n-0.859455\n3.88761\n✓\n\n\n2\np2\n-1.38629\n-1.38502\n0.0593844\n-1.50141\n-1.26862\n0.0922677\n✓\n\n\n3\np3\n-0.693147\n-0.726022\n0.0453045\n-0.814819\n-0.637225\n4.74285\n✓\n\n\n\n\n\n\n\n---\n\n### Unknown - Panel Data (Markov) - Fixed Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n6×8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\np1\n-0.916291\n-0.909705\n0.0463105\n-1.00047\n-0.818937\n0.718703\n✓\n\n\n2\np2\n0.0\n0.193466\n0.0667954\n0.0625473\n0.324385\n19.3466\n✗\n\n\n3\np3\n-1.38629\n-25.8976\n0.0\n-25.8976\n-25.8976\n1768.11\n✗\n\n\n4\np4\n0.4\n0.00570717\n0.0\n0.00570717\n0.00570717\n98.5732\n✗\n\n\n5\np5\n-0.693147\n-26.4437\n0.0\n-26.4437\n-26.4437\n3715.01\n✗\n\n\n6\np6\n0.3\n-0.000830122\n0.0\n-0.000830122\n-0.000830122\n100.277\n✗\n\n\n\n\n\n\n\n---\n\n### Unknown - Panel Data (Markov) - Unknown - Details\n\n\n**Parameter Recovery:**\n\n\n\n8×8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\np1\n-0.693147\n-0.625669\n0.100717\n-0.823075\n-0.428263\n9.735\n✓\n\n\n2\np2\n-1.20397\n-1.22398\n0.148987\n-1.51599\n-0.931963\n1.66147\n✓\n\n\n3\np3\n-1.04982\n-1.03216\n0.103216\n-1.23446\n-0.829854\n1.68263\n✓\n\n\n4\np4\n-0.916291\n-0.952688\n0.121489\n-1.19081\n-0.714569\n3.97219\n✓\n\n\n5\np5\n-1.38629\n-1.26281\n0.142515\n-1.54214\n-0.983485\n8.9072\n✓\n\n\n6\np6\n-1.60944\n-1.56844\n0.0910699\n-1.74694\n-1.38994\n2.54744\n✓\n\n\n7\np7\n-1.20397\n-1.23632\n0.0935042\n-1.41959\n-1.05305\n2.68647\n✓\n\n\n8\np8\n-1.04982\n-1.03998\n0.0922861\n-1.22086\n-0.859095\n0.937887\n✓\n\n\n\n\n\n\n\n---\n\n### Unknown - Panel Data (Markov) - Unknown - Details\n\n\n**Parameter Recovery:**\n\n\n\n3×8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\np1\n-0.916291\n-0.840454\n0.075397\n-0.988232\n-0.692676\n8.27653\n✓\n\n\n2\np2\n-1.60944\n-1.52736\n0.12783\n-1.7779\n-1.27681\n5.10005\n✓\n\n\n3\np3\n-0.693147\n-0.653854\n0.0619913\n-0.775357\n-0.532351\n5.66882\n✓\n\n\n\n\n\n\n\n---\n\n### Unknown - Panel Data (Markov) - Time-Varying Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n6×8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\np1\n-0.916291\n-23.5454\n0.0\n-23.5454\n-23.5454\n2469.64\n✗\n\n\n2\np2\n0.0\n-0.962064\n0.0\n-0.962064\n-0.962064\n96.2064\n✗\n\n\n3\np3\n-1.38629\n-0.255928\n0.021944\n-0.298938\n-0.212918\n81.5387\n✗\n\n\n4\np4\n0.5\n0.651666\n0.0466929\n0.560148\n0.743184\n30.3332\n✗\n\n\n5\np5\n-0.693147\n3.22238\n0.0\n3.22238\n3.22238\n564.891\n✗\n\n\n6\np6\n0.4\n0.0462193\n0.0\n0.0462193\n0.0462193\n88.4452\n✗\n\n\n\n\n\n\n\n---\n\n### Spline - Panel Data (Markov) - Fixed Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n1×8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nbeta\n0.5\n-1.25739\nNaN\nNaN\nNaN\n351.478\n?\n\n\n\n\n\n\n\n---\n\n### Weibull - Exact Data - Fixed Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n6×8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nh12_beta\n0.5\n0.561068\n0.0647565\n0.434145\n0.687991\n12.2136\n✓\n\n\n2\nh12_log_scale\n-1.89712\n-1.89595\n0.0720161\n-2.0371\n-1.7548\n0.0616512\n✓\n\n\n3\nh12_log_shape\n0.182322\n0.167014\n0.0250907\n0.117836\n0.216192\n8.39594\n✓\n\n\n4\nh23_beta\n0.5\n0.488059\n0.0695899\n0.351662\n0.624455\n2.38828\n✓\n\n\n5\nh23_log_scale\n-2.12026\n-2.00192\n0.0771521\n-2.15314\n-1.8507\n5.58149\n✓\n\n\n6\nh23_log_shape\n0.0953102\n0.0382591\n0.0285863\n-0.01777\n0.0942882\n59.8583\n✗\n\n\n\n\n\n\n\n---\n\n### Weibull - Exact Data - No Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n4×8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nh12_log_scale\n-1.89712\n-1.90817\n0.0664495\n-2.03842\n-1.77793\n0.582702\n✓\n\n\n2\nh12_log_shape\n0.182322\n0.172548\n0.0255417\n0.122486\n0.22261\n5.36051\n✓\n\n\n3\nh23_log_scale\n-2.12026\n-1.92772\n0.0705533\n-2.066\n-1.78943\n9.08117\n✗\n\n\n4\nh23_log_shape\n0.0953102\n0.0359114\n0.0305228\n-0.0239132\n0.0957361\n62.3215\n✓\n\n\n\n\n\n\n\n---\n\n### Weibull - Exact Data - Time-Varying Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n6×8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nh12_beta\n0.5\n0.304335\n0.0887852\n0.130316\n0.478354\n39.133\n✗\n\n\n2\nh12_log_scale\n-1.89712\n-1.83579\n0.0681643\n-1.96939\n-1.70219\n3.23288\n✓\n\n\n3\nh12_log_shape\n0.182322\n0.182518\n0.0339722\n0.115933\n0.249104\n0.107935\n✓\n\n\n4\nh23_beta\n0.5\n0.583029\n0.0904944\n0.40566\n0.760398\n16.6057\n✓\n\n\n5\nh23_log_scale\n-2.12026\n-2.10673\n0.0807577\n-2.26502\n-1.94845\n0.638274\n✓\n\n\n6\nh23_log_shape\n0.0953102\n0.0621098\n0.0314562\n0.000455684\n0.123764\n34.834\n✓\n\n\n\n\n\n\n\n---\n\n### Weibull - Panel Data (MCEM) - Fixed Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n6×8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nh12_beta\n0.5\n0.236104\n0.0734473\n0.0921474\n0.380061\n52.7792\n✗\n\n\n2\nh12_log_scale\n-1.89712\n-1.52076\n0.080301\n-1.67815\n-1.36337\n19.8387\n✗\n\n\n3\nh12_log_shape\n0.182322\n0.227693\n0.0327314\n0.16354\n0.291847\n24.8855\n✓\n\n\n4\nh23_beta\n0.5\n0.239506\n0.0835806\n0.0756882\n0.403324\n52.0988\n✗\n\n\n5\nh23_log_scale\n-2.12026\n-1.70131\n0.0994666\n-1.89626\n-1.50635\n19.7597\n✗\n\n\n6\nh23_log_shape\n0.0953102\n0.322336\n0.0369632\n0.249888\n0.394784\n238.197\n✗\n\n\n\n\n\n\n\n---\n\n### Weibull - Panel Data (MCEM) - No Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n4×8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nh12_log_scale\n-1.89712\n-1.76173\n0.0799154\n-1.91836\n-1.6051\n7.13664\n✓\n\n\n2\nh12_log_shape\n0.182322\n0.320764\n0.0327404\n0.256593\n0.384935\n75.933\n✗\n\n\n3\nh23_log_scale\n-2.12026\n-1.85253\n0.100663\n-2.04983\n-1.65523\n12.6273\n✗\n\n\n4\nh23_log_shape\n0.0953102\n0.395194\n0.0397398\n0.317304\n0.473084\n314.64\n✗\n\n\n\n\n\n\n\n---\n\n### Weibull - Panel Data (MCEM) - Time-Varying Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n6×8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nh12_beta\n0.5\n0.806506\n0.0984655\n0.613513\n0.999498\n61.3011\n✗\n\n\n2\nh12_log_scale\n-1.89712\n-1.57963\n0.0729307\n-1.72257\n-1.43669\n16.7354\n✗\n\n\n3\nh12_log_shape\n0.182322\n0.102176\n0.0444122\n0.0151275\n0.189224\n43.9586\n✓\n\n\n4\nh23_beta\n0.5\n0.975225\n0.0895833\n0.799642\n1.15081\n95.0451\n✗\n\n\n5\nh23_log_scale\n-2.12026\n-1.99836\n0.08273\n-2.16051\n-1.83621\n5.74932\n✓\n\n\n6\nh23_log_shape\n0.0953102\n0.163469\n0.0398453\n0.0853725\n0.241566\n71.5129\n✓\n\n\n\n\n\n\n\n\n\n**State Prevalence: Exponential - Exact Data - Fixed Covariates**\n\nRed = true model, Blue = fitted model\n\n\n\n\n\n\n\n\n\n\n\n**State Prevalence: Exponential - Exact Data - No Covariates**\n\nRed = true model, Blue = fitted model\n\n\n\n\n\n\n\n\n\n\n\n**State Prevalence: Exponential - Exact Data - Time-Varying Covariates**\n\nRed = true model, Blue = fitted model\n\n\n\n\n\n\n\n\n\n\n\n**State Prevalence: Exponential - Panel Data (Markov) - Fixed Covariates**\n\nRed = true model, Blue = fitted model\n\n\n\n\n\n\n\n\n\n\n\n**State Prevalence: Exponential - Panel Data (Markov) - No Covariates**\n\nRed = true model, Blue = fitted model\n\n\n\n\n\n\n\n\n\n\n\n**State Prevalence: Exponential - Panel Data (Markov) - Time-Varying Covariates**\n\nRed = true model, Blue = fitted model\n\n\n\n\n\n\n\n\n\n\n\n**State Prevalence: Gompertz - Exact Data - Fixed Covariates**\n\nRed = true model, Blue = fitted model\n\n\n\n\n\n\n\n\n\n\n\n**State Prevalence: Gompertz - Exact Data - No Covariates**\n\nRed = true model, Blue = fitted model\n\n\n\n\n\n\n\n\n\n\n\n**State Prevalence: Gompertz - Exact Data - Time-Varying Covariates**\n\nRed = true model, Blue = fitted model\n\n\n\n\n\n\n\n\n\n\n\n**State Prevalence: Gompertz - Panel Data (MCEM) - Fixed Covariates**\n\nRed = true model, Blue = fitted model\n\n\n\n\n\n\n\n\n\n\n\n**State Prevalence: Gompertz - Panel Data (MCEM) - No Covariates**\n\nRed = true model, Blue = fitted model\n\n\n\n\n\n\n\n\n\n\n\n**State Prevalence: Gompertz - Panel Data (MCEM) - Time-Varying Covariates**\n\nRed = true model, Blue = fitted model\n\n\n\n\n\n\n\n\n\n\n\n**State Prevalence: Phase-Type - Exact Data - Fixed Covariates**\n\nRed = true model, Blue = fitted model\n\n*(Prevalence plots not available for this test)*\n\n**State Prevalence: Phase-Type - Exact Data - No Covariates**\n\nRed = true model, Blue = fitted model\n\n*(Prevalence plots not available for this test)*\n\n**State Prevalence: Phase-Type - Exact Data - Time-Varying Covariates**\n\nRed = true model, Blue = fitted model\n\n*(Prevalence plots not available for this test)*\n\n**State Prevalence: phasetype - mixed - none**\n\nRed = true model, Blue = fitted model\n\n*(Prevalence plots not available for this test)*\n\n**State Prevalence: phasetype - mixed - none**\n\nRed = true model, Blue = fitted model\n\n*(Prevalence plots not available for this test)*\n\n**State Prevalence: Unknown - Panel Data (Markov) - Fixed Covariates**\n\nRed = true model, Blue = fitted model\n\n*(Prevalence plots not available for this test)*\n\n**State Prevalence: Unknown - Panel Data (Markov) - Unknown**\n\nRed = true model, Blue = fitted model\n\n*(Prevalence plots not available for this test)*\n\n**State Prevalence: Unknown - Panel Data (Markov) - Unknown**\n\nRed = true model, Blue = fitted model\n\n*(Prevalence plots not available for this test)*\n\n**State Prevalence: Unknown - Panel Data (Markov) - Time-Varying Covariates**\n\nRed = true model, Blue = fitted model\n\n*(Prevalence plots not available for this test)*\n\n**State Prevalence: Spline - Panel Data (Markov) - Fixed Covariates**\n\nRed = true model, Blue = fitted model\n\n*(Prevalence plots not available for this test)*\n\n**State Prevalence: Weibull - Exact Data - Fixed Covariates**\n\nRed = true model, Blue = fitted model\n\n\n\n\n\n\n\n\n\n\n\n**State Prevalence: Weibull - Exact Data - No Covariates**\n\nRed = true model, Blue = fitted model\n\n\n\n\n\n\n\n\n\n\n\n**State Prevalence: Weibull - Exact Data - Time-Varying Covariates**\n\nRed = true model, Blue = fitted model\n\n\n\n\n\n\n\n\n\n\n\n**State Prevalence: Weibull - Panel Data (MCEM) - Fixed Covariates**\n\nRed = true model, Blue = fitted model\n\n\n\n\n\n\n\n\n\n\n\n**State Prevalence: Weibull - Panel Data (MCEM) - No Covariates**\n\nRed = true model, Blue = fitted model\n\n\n\n\n\n\n\n\n\n\n\n**State Prevalence: Weibull - Panel Data (MCEM) - Time-Varying Covariates**\n\nRed = true model, Blue = fitted model\n\n\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Exponential - Exact Data - Fixed Covariates**\n\nTransitions 1→2 and 2→3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Exponential - Exact Data - No Covariates**\n\nTransitions 1→2 and 2→3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Exponential - Exact Data - Time-Varying Covariates**\n\nTransitions 1→2 and 2→3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Exponential - Panel Data (Markov) - Fixed Covariates**\n\nTransitions 1→2 and 2→3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Exponential - Panel Data (Markov) - No Covariates**\n\nTransitions 1→2 and 2→3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Exponential - Panel Data (Markov) - Time-Varying Covariates**\n\nTransitions 1→2 and 2→3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Gompertz - Exact Data - Fixed Covariates**\n\nTransitions 1→2 and 2→3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Gompertz - Exact Data - No Covariates**\n\nTransitions 1→2 and 2→3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Gompertz - Exact Data - Time-Varying Covariates**\n\nTransitions 1→2 and 2→3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Gompertz - Panel Data (MCEM) - Fixed Covariates**\n\nTransitions 1→2 and 2→3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Gompertz - Panel Data (MCEM) - No Covariates**\n\nTransitions 1→2 and 2→3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Gompertz - Panel Data (MCEM) - Time-Varying Covariates**\n\nTransitions 1→2 and 2→3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Phase-Type - Exact Data - Fixed Covariates**\n\nTransitions 1→2 and 2→3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Phase-Type - Exact Data - No Covariates**\n\nTransitions 1→2 and 2→3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Phase-Type - Exact Data - Time-Varying Covariates**\n\nTransitions 1→2 and 2→3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: phasetype - mixed - none**\n\nTransitions 1→2 and 2→3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: phasetype - mixed - none**\n\nTransitions 1→2 and 2→3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Unknown - Panel Data (Markov) - Fixed Covariates**\n\nTransitions 1→2 and 2→3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Unknown - Panel Data (Markov) - Unknown**\n\nTransitions 1→2 and 2→3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Unknown - Panel Data (Markov) - Unknown**\n\nTransitions 1→2 and 2→3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Unknown - Panel Data (Markov) - Time-Varying Covariates**\n\nTransitions 1→2 and 2→3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Spline - Panel Data (Markov) - Fixed Covariates**\n\nTransitions 1→2 and 2→3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Weibull - Exact Data - Fixed Covariates**\n\nTransitions 1→2 and 2→3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Weibull - Exact Data - No Covariates**\n\nTransitions 1→2 and 2→3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Weibull - Exact Data - Time-Varying Covariates**\n\nTransitions 1→2 and 2→3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Weibull - Panel Data (MCEM) - Fixed Covariates**\n\nTransitions 1→2 and 2→3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Weibull - Panel Data (MCEM) - No Covariates**\n\nTransitions 1→2 and 2→3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Weibull - Panel Data (MCEM) - Time-Varying Covariates**\n\nTransitions 1→2 and 2→3 only (progressive model)"
  },
  {
    "objectID": "long_tests.html#running-long-tests",
    "href": "long_tests.html#running-long-tests",
    "title": "Long Test Status",
    "section": "Running Long Tests",
    "text": "Running Long Tests\n\nFull Suite\ncd MultistateModelsTests\n\n# Via the test package API\nMSM_TEST_LEVEL=full julia --project=. -e 'using MultistateModelsTests; MultistateModelsTests.runtests()'\n\n# Or via the dedicated script\njulia --project=. scripts/run_longtests.jl\n\n\nIndividual Test Suite\n# Run only a specific suite (by key name)\nMSM_TEST_LEVEL=full MSM_LONGTEST_ONLY=parametric_suite julia --project=. -e 'using MultistateModelsTests; MultistateModelsTests.runtests()'\n\n\nAvailable Test Suites\n\n\n\n\n\n\n\nKey\nDescription\n\n\n\n\nparametric_suite\nParametric families (exp/wei/gom) × data types × covariates\n\n\nexact_data\nExact observation direct MLE\n\n\nmcem_parametric\nPanel data with parametric hazards\n\n\nmcem_splines\nPanel data with spline hazards\n\n\nphasetype\nPhase-type hazard models\n\n\nvariance_validation\nVariance estimation validation\n\n\n\n\n\nEnvironment Variables\n\n\n\n\n\n\n\n\nVariable\nValues\nDescription\n\n\n\n\nMSM_TEST_LEVEL\nquick (default), full\nControls whether long tests run\n\n\nMSM_LONGTEST_ONLY\ntest key\nRun only one specific long test suite\n\n\nMSM_SUPPRESS_WARNINGS\ntrue (default), false\nSuppress expected warnings"
  },
  {
    "objectID": "long_tests.html#troubleshooting",
    "href": "long_tests.html#troubleshooting",
    "title": "Long Test Status",
    "section": "Troubleshooting",
    "text": "Troubleshooting\n\nParameter Recovery Failures\nSymptoms: Estimated parameters far from true values\nPotential Causes: 1. Insufficient sample size: Tests use N=1000, may need more for some models 2. Poor initialization: Check initialize_parameters! settings 3. MCEM convergence: Increase iterations or tighten tolerance\n\n\nVariance Estimation Issues\nSymptoms: Coverage rates significantly below 95%\nPotential Causes: 1. Small sample bias: Need larger n 2. Boundary parameters: Transform scale may help 3. Model misspecification: Verify DGP matches fitted model"
  },
  {
    "objectID": "long_tests.html#summary-1",
    "href": "long_tests.html#summary-1",
    "title": "Long Test Status",
    "section": "Summary",
    "text": "Summary\nLong tests provide rigorous validation that MultistateModels.jl:\n\nRecovers parameters within expected tolerance (20% relative error)\nProduces valid uncertainty through variance estimation\nSimulates correctly from fitted models\nHandles all supported hazard families and observation types\n\nThe test matrix covers: - Families: Exponential, Weibull, Gompertz, Phase-Type, Spline - Data types: Exact (direct MLE), Panel (Markov/MCEM) - Covariates: None, Time-fixed, Time-varying"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MultistateModels.jl",
    "section": "",
    "text": "Branch: penalized_splines   Commit: b1144da"
  },
  {
    "objectID": "index.html#overview",
    "href": "index.html#overview",
    "title": "MultistateModels.jl",
    "section": "Overview",
    "text": "Overview\nComprehensive validation and documentation for MultistateModels.jl — a Julia package for continuous-time multistate modeling.\n\n\n📐 Architecture\nType hierarchy, hazard families, inference engine, and simulation strategies.\n\n\n✅ Unit Tests\nFunction-level tests for hazards, simulation, MCEM, and model construction.\n\n\n📊 Long Tests\nStatistical recovery of parameters across hazard families and data types.\n\n\n🎯 Simulation\nVisual verification of event time distributions (CDF diagnostic plots).\n\n\n⚡ Benchmarks\nPerformance comparison of sampling methods and optimization strategies.\n\n\n📦 Main Package\nSource code and documentation for MultistateModels.jl."
  },
  {
    "objectID": "index.html#test-results-summary",
    "href": "index.html#test-results-summary",
    "title": "MultistateModels.jl",
    "section": "Test Results Summary",
    "text": "Test Results Summary\n\n\n\nMetric\nValue\n\n\n\n\nPassed\n1192\n\n\nFailed\n0\n\n\nErrors\n0\n\n\nPass Rate\n100.0%\n\n\nCategories\n12\n\n\nLast Updated\n2025-12-31T17:24:57.676"
  },
  {
    "objectID": "index.html#quick-start",
    "href": "index.html#quick-start",
    "title": "MultistateModels.jl",
    "section": "Quick Start",
    "text": "Quick Start\n\nBuilding Reports Locally\ncd MultistateModelsTests/reports\nquarto render\n\n\nRunning Tests and Recording Results\n# Run full test suite with automatic cache recording\njulia --project=. -e 'using MultistateModelsTests; MultistateModelsTests.runtests()'\n\n# Or run with the dedicated script\njulia --project=. scripts/run_all_tests.jl\nTest results are automatically cached when running via runtests().\n\n\nChecking Cache Status\njulia --project=. scripts/refresh_cache.jl"
  },
  {
    "objectID": "architecture.html",
    "href": "architecture.html",
    "title": "MultistateModels.jl Architecture",
    "section": "",
    "text": "MultistateModels.jl is a Julia package for fitting and simulating continuous-time multistate models. This document provides a comprehensive architectural overview, covering the package structure, type hierarchy, and key implementation patterns."
  },
  {
    "objectID": "architecture.html#overview",
    "href": "architecture.html#overview",
    "title": "MultistateModels.jl Architecture",
    "section": "",
    "text": "MultistateModels.jl is a Julia package for fitting and simulating continuous-time multistate models. This document provides a comprehensive architectural overview, covering the package structure, type hierarchy, and key implementation patterns."
  },
  {
    "objectID": "architecture.html#package-structure",
    "href": "architecture.html#package-structure",
    "title": "MultistateModels.jl Architecture",
    "section": "Package Structure",
    "text": "Package Structure\nThe package is organized into the following directories:\nsrc/\n├── MultistateModels.jl      # Main module, exports, includes\n├── construction/            # Model construction (multistatemodel function)\n├── hazard/                  # Hazard functions and evaluation\n├── inference/               # MCEM, SIR, fitting algorithms\n├── likelihood/              # Log-likelihood computation\n├── output/                  # Model accessors and variance estimation\n├── phasetype/               # Phase-type distributions and FFBS\n├── simulation/              # Path simulation\n├── surrogate/               # Markov surrogates\n├── types/                   # Type definitions\n└── utilities/               # Parameter handling, validation, misc"
  },
  {
    "objectID": "architecture.html#type-hierarchy",
    "href": "architecture.html#type-hierarchy",
    "title": "MultistateModels.jl Architecture",
    "section": "Type Hierarchy",
    "text": "Type Hierarchy\n\nInternal Hazard Types\nThe package uses an internal type hierarchy for hazard functions that distinguishes between Markov (time-homogeneous) and semi-Markov (sojourn-time-dependent) hazards:\n\n\n\n\n\n\n\n\n\nKey insight: PhaseTypeCoxianHazard inherits from _MarkovHazard because the stochastic process on the expanded state space (with latent phases) is Markovian—each phase transition is exponential. The non-exponential sojourn time arises from the mixture over paths through phases, not from any single transition.\n\n\nModel Types\n\n\n\n\n\n\n\n\n\n\n\nUser-Facing Hazard Specifications\nUsers specify hazards via HazardFunction subtypes, which are converted to internal types during model construction:\n\n\n\n\n\n\n\n\nUser Specification\nInternal Type\nDescription\n\n\n\n\nParametricHazard (:exp)\nMarkovHazard\nExponential (constant hazard)\n\n\nParametricHazard (:wei, :gom)\nSemiMarkovHazard\nWeibull, Gompertz\n\n\nSplineHazard (:sp)\nRuntimeSplineHazard\nB-spline hazard\n\n\nPhaseTypeHazard (:pt)\nPhaseTypeCoxianHazard\nPhase-type (Coxian)\n\n\n\n\n\nTrait-Based Dispatch\nRather than using the type hierarchy directly, model behavior is determined by trait functions:\nis_markov(model)              # All hazards are _MarkovHazard?\nis_panel_data(model)          # Any obstype ≥ 2?\nhas_phasetype_expansion(model) # Model has phase-type hazards?\nThese traits determine which fitting algorithm is used: - is_panel_data=false → Direct MLE (exact data) - is_panel_data=true && is_markov=true → Matrix exponential MLE - is_panel_data=true && is_markov=false → MCEM"
  },
  {
    "objectID": "architecture.html#data-handling",
    "href": "architecture.html#data-handling",
    "title": "MultistateModels.jl Architecture",
    "section": "Data Handling",
    "text": "Data Handling\n\nRequired Data Format\nData must be a DataFrame with the following columns:\n\n\n\nColumn\nType\nDescription\n\n\n\n\nid\nInt/String\nSubject identifier\n\n\ntstart\nFloat64\nInterval start time\n\n\ntstop\nFloat64\nInterval end time\n\n\nstatefrom\nInt\nState at tstart\n\n\nstateto\nInt\nState at tstop\n\n\nobstype\nInt\nObservation type code\n\n\ncovariates\nAny\nModel-specific covariates\n\n\n\n\n\nObservation Types (obstype)\nThe obstype column controls how each observation contributes to the likelihood:\n\n\n\n\n\n\n\n\n\nCode\nName\nDescription\nLikelihood Contribution\n\n\n\n\n1\nExact\nTransition time and state observed exactly\nTransition density\n\n\n2\nPanel\nState known at tstop, transition time unknown\nTPM entry\n\n\n0\nFully censored\nState unknown at tstop\nSum over all states\n\n\n≥3\nPartially censored\nState partially known (see CensoringPatterns)\nWeighted sum\n\n\n\n\n\nCensoringPatterns\nFor obstype ≥ 3, you must provide a CensoringPatterns matrix specifying which states are compatible with each censoring code:\n# 3-state model with two censoring patterns\n# obstype=3: states 1 or 2 possible (not 3)\n# obstype=4: states 2 or 3 possible (not 1)\nCensoringPatterns = [\n    # code  state1  state2  state3\n    3       1.0     1.0     0.0;\n    4       0.0     1.0     1.0\n]\n\nmodel = multistatemodel(h12, h23; data=dat, CensoringPatterns=CensoringPatterns)\n\n\nEmissionMatrix\nFor maximum flexibility, you can provide an observation-specific EmissionMatrix directly. This is an \\((n_{\\text{obs}} \\times n_{\\text{states}})\\) matrix where entry \\((i, s)\\) gives \\(P(\\text{observation } i \\mid \\text{state } s)\\)."
  },
  {
    "objectID": "architecture.html#hazard-families",
    "href": "architecture.html#hazard-families",
    "title": "MultistateModels.jl Architecture",
    "section": "Hazard Families",
    "text": "Hazard Families\n\nParametric Distributions\n\n\n\n\n\n\n\n\n\n\nFamily\nSymbol\nParameters\nHazard \\(h(t)\\)\nMarkov?\n\n\n\n\nExponential\n:exp\nrate \\((\\lambda)\\)\n\\(\\lambda\\)\n✓\n\n\nWeibull\n:wei\nshape \\((a)\\), scale \\((b)\\)\n\\(\\displaystyle\\frac{a}{b}\\left(\\frac{t}{b}\\right)^{a-1}\\)\n✗\n\n\nGompertz\n:gom\nshape \\((a)\\), rate \\((b)\\)\n\\(b \\cdot e^{at}\\)\n✗\n\n\nB-Spline\n:sp\ncoefs \\((\\beta_1,\\ldots,\\beta_K)\\)\n\\(\\exp\\left(\\sum_{k=1}^K B_k(t)\\beta_k\\right)\\)\n✗ (degree&gt;0)\n\n\nPhase-Type\n:pt\n\\(\\lambda_1,\\ldots,\\lambda_{n-1}\\), \\(\\mu_1,\\ldots,\\mu_n\\)\nCoxian absorption\n✓ (expanded)\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nGompertz Parameterization: MultistateModels.jl uses the flexsurv parameterization where shape (\\(a\\)) is the rate of hazard increase and rate (\\(b\\)) is the initial hazard at \\(t=0\\).\n\n\n\n\nPhase-Type Structure\nPhase-type hazards (:pt) use a Coxian structure with latent phases:\n\n\n\n\n\n\n\n\n\nKey properties:\n\nApproximate any non-negative distribution arbitrarily well\nThe process on the expanded state space is Markovian — hence PhaseTypeCoxianHazard &lt;: _MarkovHazard\nNon-exponential sojourn times arise from the mixture over phase paths\nParameters: \\(\\lambda_1, \\ldots, \\lambda_{n-1}\\) (progression), \\(\\mu_1, \\ldots, \\mu_n\\) (exit)\n\n\n\nCovariate Effects\nTwo covariate effect types are supported:\nProportional Hazards (PH): \\[h(t|\\mathbf{x}) = h_0(t) \\exp(\\mathbf{x}'\\boldsymbol{\\beta})\\]\nAccelerated Failure Time (AFT): \\[h(t|\\mathbf{x}) = h_0(t \\cdot e^{\\mathbf{x}'\\boldsymbol{\\beta}}) \\cdot e^{\\mathbf{x}'\\boldsymbol{\\beta}}\\]\n# Specify effect type when creating hazards\nh12_ph = Hazard(@formula(0 ~ 1 + age), \"wei\", 1, 2; linpred_effect=:ph)\nh12_aft = Hazard(@formula(0 ~ 1 + age), \"wei\", 1, 2; linpred_effect=:aft)\n\n\n\n\n\n\nWarning\n\n\n\nThe covariate effect types (:ph and :aft) are built into the package. Adding custom effect types requires modifying the hazard generation code—this is not user-extensible."
  },
  {
    "objectID": "architecture.html#parameter-handling",
    "href": "architecture.html#parameter-handling",
    "title": "MultistateModels.jl Architecture",
    "section": "Parameter Handling",
    "text": "Parameter Handling\n\nParameter Structure\nParameters are stored as NamedTuples with multiple representations:\nmodel.parameters = (\n    flat = [...],           # Flat vector on estimation (log) scale\n    nested = (...),         # Nested NamedTuple by hazard\n    natural = (...),        # Natural scale values by hazard\n    reconstructor = ...     # Function to unflatten\n)\nEach hazard’s parameters include: - Baseline parameters (shape, scale, rate, coefs, etc.) - Regression coefficients (if covariates specified)\n\n\nScale Transformations\nParameters are estimated on transformed scales for numerical stability:\n\n\n\n\n\n\n\n\n\nParameter Type\nNatural Scale\nEstimation Scale\nTransformation\n\n\n\n\nRates, shapes, scales\n\\((0, \\infty)\\)\n\\((-\\infty, \\infty)\\)\n\\(\\log\\)\n\n\nSpline coefficients\n\\((-\\infty, \\infty)\\)\n\\((-\\infty, \\infty)\\)\nIdentity\n\n\nRegression \\(\\beta\\)\n\\((-\\infty, \\infty)\\)\n\\((-\\infty, \\infty)\\)\nIdentity\n\n\n\nTransformation by family:\n\n\n\n\n\n\n\n\n\n\nFamily\nParameter\nNatural\nEstimation\nTransform\n\n\n\n\nExponential\nrate\n\\(\\lambda &gt; 0\\)\n\\(\\theta \\in \\mathbb{R}\\)\n\\(\\lambda = e^\\theta\\)\n\n\nWeibull\nshape\n\\(a &gt; 0\\)\n\\(\\theta_a \\in \\mathbb{R}\\)\n\\(a = e^{\\theta_a}\\)\n\n\nWeibull\nscale\n\\(b &gt; 0\\)\n\\(\\theta_b \\in \\mathbb{R}\\)\n\\(b = e^{\\theta_b}\\)\n\n\nGompertz\nshape\n\\(a \\in \\mathbb{R}\\)\n\\(a\\)\nIdentity\n\n\nGompertz\nrate\n\\(b &gt; 0\\)\n\\(\\theta_b \\in \\mathbb{R}\\)\n\\(b = e^{\\theta_b}\\)\n\n\nSpline\ncoefs\n\\(\\boldsymbol{\\beta}\\)\n\\(\\boldsymbol{\\beta}\\)\nIdentity\n\n\n\n# Access parameters in different scales\np_natural = model.parameters.natural   # Interpretable values\np_flat = model.parameters.flat         # For optimization (log scale)"
  },
  {
    "objectID": "architecture.html#inference-methods",
    "href": "architecture.html#inference-methods",
    "title": "MultistateModels.jl Architecture",
    "section": "Inference Methods",
    "text": "Inference Methods\n\nFitting Strategy Selection\nThe fit() function automatically selects the appropriate method based on data and hazard types:\n\n\n\n\n\n\n\n\n\n\n\nDirect MLE (Exact Data)\nFor exactly observed data (obstype=1), the likelihood factorizes into transition densities:\n\\[\\mathcal{L}(\\boldsymbol{\\theta}) = \\prod_{i} \\prod_{j} h_{s_j \\to s_{j+1}}(t_j) \\cdot S_{s_j}(t_j - t_{j-1})\\]\nwhere \\(S_s(t) = \\exp(-H_s(t))\\) is the survival probability in state \\(s\\).\n\n\nMatrix Exponential MLE (Markov Panel)\nFor panel data with Markov hazards (exponential or phase-type), the likelihood uses transition probability matrices:\n\\[P(t_0, t_1) = \\exp(\\mathbf{Q} \\cdot (t_1 - t_0))\\]\nwhere \\(\\mathbf{Q}\\) is the generator matrix.\n\n\nMonte Carlo EM (Semi-Markov Panel)\nFor panel data with semi-Markov hazards (Weibull, Gompertz, degree&gt;0 splines), MCEM is used:\nE-step: Sample latent paths via importance sampling using a Markov surrogate\nM-step: Maximize expected complete-data log-likelihood with importance weights\nFeatures: - SQUAREM acceleration - Adaptive ESS targeting - Latin Hypercube Sampling (LHS) for variance-reduced resampling\n\n\nForward-Filtering Backward-Sampling (FFBS)\nFFBS samples latent state sequences given observations. For phase-type models, FFBS operates on the expanded Markov state space, then collapses sampled phases back to observed states.\nSee the Phase-Type FFBS documentation for details."
  },
  {
    "objectID": "architecture.html#variance-estimation",
    "href": "architecture.html#variance-estimation",
    "title": "MultistateModels.jl Architecture",
    "section": "Variance Estimation",
    "text": "Variance Estimation\nThree variance estimation approaches are available:\n\n\n\n\n\n\n\n\n\nMethod\nDescription\nPros\nCons\n\n\n\n\nModel-based\nInverse Hessian at MLE\nFast, standard\nAssumes correct model\n\n\nSandwich (IJ)\nInfinitesimal jackknife\nRobust to misspecification\nRequires more computation\n\n\nJackknife\nLeave-one-out refitting\nNonparametric\nComputationally expensive\n\n\n\nfitted = fit(model; \n    compute_vcov=true,      # Model-based (default)\n    compute_ij_vcov=true,   # Sandwich estimator\n    compute_jk_vcov=false   # Jackknife (slow)\n)"
  },
  {
    "objectID": "architecture.html#custom-constraints",
    "href": "architecture.html#custom-constraints",
    "title": "MultistateModels.jl Architecture",
    "section": "Custom Constraints",
    "text": "Custom Constraints\nUsers can specify parameter constraints using expressions that reference parameter names:\n# Constraint: shape parameter must be ≥ 1\n# Constraint: two hazards share the same rate\nconstraints = make_constraints(\n    cons = [\n        :(h1_2_shape - 1),           # shape ≥ 1 → (shape - 1) ≥ 0\n        :(h1_2_rate - h2_3_rate)     # Equal rates → difference = 0\n    ],\n    lcons = [0.0, 0.0],   # Lower bounds\n    ucons = [Inf, 0.0]    # Upper bounds\n)\n\nfitted = fit(model; constraints=constraints)\nParameter naming: h{from}_{to}_{param} (e.g., h1_2_shape, h2_3_rate)\n\n\n\n\n\n\nWarning\n\n\n\nVariance-covariance matrices are not computed when constraints are active, as the constrained MLE may lie on the boundary of the parameter space."
  },
  {
    "objectID": "architecture.html#simulation-engine",
    "href": "architecture.html#simulation-engine",
    "title": "MultistateModels.jl Architecture",
    "section": "Simulation Engine",
    "text": "Simulation Engine\nThe simulation engine samples complete state trajectories:\n\nInitialize at starting state and time\nCompute total hazard from current state\nSample waiting time via inverse CDF\nSample destination state proportional to hazard rates\nUpdate state and time\nRepeat until absorbing state or end time\n\npaths = simulate(model; nsim=1000, tmax=10.0)"
  },
  {
    "objectID": "architecture.html#summary",
    "href": "architecture.html#summary",
    "title": "MultistateModels.jl Architecture",
    "section": "Summary",
    "text": "Summary\nMultistateModels.jl provides a flexible framework for multistate modeling:\n\nType hierarchy: _MarkovHazard vs _SemiMarkovHazard governs fitting method selection\nPhase-type hazards are Markovian on the expanded space (not semi-Markov!)\nTrait-based dispatch via is_markov(), is_panel_data(), has_phasetype_expansion()\nParameters as NamedTuples with flat/nested/natural representations\nFlexible observation handling via obstype, CensoringPatterns, EmissionMatrix\nThree fitting algorithms: Direct MLE, Matrix Exp MLE, MCEM (auto-selected)\nLHS resampling for variance-reduced importance sampling in MCEM"
  },
  {
    "objectID": "unit_tests.html",
    "href": "unit_tests.html",
    "title": "Unit Test Coverage",
    "section": "",
    "text": "This document provides a comprehensive summary of unit test coverage for MultistateModels.jl. Unit tests verify individual functions and components work correctly in isolation, forming the foundation of the testing pyramid.\n\n\n🟢 Cache current (b1144da, updated 2025-12-31T17:24:57.676)\n\n\n**Branch:** `penalized_splines` | **Commit:** `b1144da`\n\n⚠️ Uncommitted changes in: Project.toml, docs/build/.documenter-siteinfo.json, docs/build/assets/documenter.js...\n\n\n\n\n\n\n\n| Metric | Value |\n|--------|-------|\n| Total Passed | 1192 |\n| Total Failed | 0 |\n| Total Errors | 0 |\n| Categories Tested | 12 |\n\n\n\n\n\n\n\n12×6 DataFrame\n\n\n\nRow\nCategory\nPassed\nFailed\nErrors\nTimestamp\nStatus\n\n\n\nSymbol\nInt64\nInt64\nInt64\nString\nString\n\n\n\n\n1\nsurrogates\n58\n0\n0\n2025-12-31T17:24:55.579\n✅ Pass\n\n\n2\nsimulation\n39\n0\n0\n2025-12-31T17:24:55.937\n✅ Pass\n\n\n3\nmcem\n23\n0\n0\n2025-12-31T17:24:56.097\n✅ Pass\n\n\n4\nsplines\n152\n0\n0\n2025-12-31T17:24:56.279\n✅ Pass\n\n\n5\nmodelgeneration\n5\n0\n0\n2025-12-31T17:24:56.461\n✅ Pass\n\n\n6\nhelpers\n53\n0\n0\n2025-12-31T17:24:56.640\n✅ Pass\n\n\n7\nreconstructor\n79\n0\n0\n2025-12-31T17:24:56.808\n✅ Pass\n\n\n8\ninitialization\n59\n0\n0\n2025-12-31T17:24:56.983\n✅ Pass\n\n\n9\nhazards\n163\n0\n0\n2025-12-31T17:24:57.152\n✅ Pass\n\n\n10\nsir\n38\n0\n0\n2025-12-31T17:24:57.323\n✅ Pass\n\n\n11\nphasetype\n505\n0\n0\n2025-12-31T17:24:57.491\n✅ Pass\n\n\n12\nvariance\n18\n0\n0\n2025-12-31T17:24:57.662\n✅ Pass"
  },
  {
    "objectID": "unit_tests.html#overview",
    "href": "unit_tests.html#overview",
    "title": "Unit Test Coverage",
    "section": "",
    "text": "This document provides a comprehensive summary of unit test coverage for MultistateModels.jl. Unit tests verify individual functions and components work correctly in isolation, forming the foundation of the testing pyramid.\n\n\n🟢 Cache current (b1144da, updated 2025-12-31T17:24:57.676)\n\n\n**Branch:** `penalized_splines` | **Commit:** `b1144da`\n\n⚠️ Uncommitted changes in: Project.toml, docs/build/.documenter-siteinfo.json, docs/build/assets/documenter.js...\n\n\n\n\n\n\n\n| Metric | Value |\n|--------|-------|\n| Total Passed | 1192 |\n| Total Failed | 0 |\n| Total Errors | 0 |\n| Categories Tested | 12 |\n\n\n\n\n\n\n\n12×6 DataFrame\n\n\n\nRow\nCategory\nPassed\nFailed\nErrors\nTimestamp\nStatus\n\n\n\nSymbol\nInt64\nInt64\nInt64\nString\nString\n\n\n\n\n1\nsurrogates\n58\n0\n0\n2025-12-31T17:24:55.579\n✅ Pass\n\n\n2\nsimulation\n39\n0\n0\n2025-12-31T17:24:55.937\n✅ Pass\n\n\n3\nmcem\n23\n0\n0\n2025-12-31T17:24:56.097\n✅ Pass\n\n\n4\nsplines\n152\n0\n0\n2025-12-31T17:24:56.279\n✅ Pass\n\n\n5\nmodelgeneration\n5\n0\n0\n2025-12-31T17:24:56.461\n✅ Pass\n\n\n6\nhelpers\n53\n0\n0\n2025-12-31T17:24:56.640\n✅ Pass\n\n\n7\nreconstructor\n79\n0\n0\n2025-12-31T17:24:56.808\n✅ Pass\n\n\n8\ninitialization\n59\n0\n0\n2025-12-31T17:24:56.983\n✅ Pass\n\n\n9\nhazards\n163\n0\n0\n2025-12-31T17:24:57.152\n✅ Pass\n\n\n10\nsir\n38\n0\n0\n2025-12-31T17:24:57.323\n✅ Pass\n\n\n11\nphasetype\n505\n0\n0\n2025-12-31T17:24:57.491\n✅ Pass\n\n\n12\nvariance\n18\n0\n0\n2025-12-31T17:24:57.662\n✅ Pass"
  },
  {
    "objectID": "unit_tests.html#test-organization",
    "href": "unit_tests.html#test-organization",
    "title": "Unit Test Coverage",
    "section": "Test Organization",
    "text": "Test Organization\nUnit tests are located in MultistateModelsTests/unit/ and organized by functional area:\nMultistateModelsTests/unit/\n├── test_hazards.jl                    # Hazard function evaluation\n├── test_splines.jl                    # B-spline hazard implementation\n├── test_simulation.jl                 # Path simulation engine\n├── test_mcem.jl                       # MCEM algorithm components\n├── test_phasetype.jl                  # Phase-type distributions\n├── test_phasetype_emission_expansion.jl\n├── test_phasetype_panel_expansion.jl\n├── test_sir.jl                        # Sampling importance resampling\n├── test_variance.jl                   # Variance estimation\n├── test_pijcv.jl                      # PIJ cross-validation\n├── test_initialization.jl             # Parameter initialization\n├── test_modelgeneration.jl            # Model construction\n├── test_helpers.jl                    # Utility functions\n├── test_reconstructor.jl              # Parameter flattening\n├── test_mll_consistency.jl            # Likelihood consistency\n├── test_observation_weights_emat.jl   # Weighted observations\n├── test_per_transition_obstype.jl     # Per-transition observation types\n├── test_reversible_tvc_loglik.jl      # Time-varying covariates\n├── test_subject_weights.jl            # Subject weighting\n└── test_surrogates.jl                 # Surrogate models"
  },
  {
    "objectID": "unit_tests.html#coverage-by-module",
    "href": "unit_tests.html#coverage-by-module",
    "title": "Unit Test Coverage",
    "section": "Coverage by Module",
    "text": "Coverage by Module\n\nHazard Functions (test_hazards.jl)\nPurpose: Validate that all hazard functions return correct values against analytical formulas.\n\n\n9×3 DataFrame\n\n\n\nRow\nTestSet\nCoverage\nStatus\n\n\n\nString\nString\nString\n\n\n\n\n1\nsurvprob\nSurvival probability S(t₁,t₂) = exp(-H(t₁,t₂))\n✅\n\n\n2\ntest_hazards_exp\nExponential: h(t) = λ, PH covariates\n✅\n\n\n3\ntest_hazards_weibull\nWeibull: h(t) = λκt^{κ-1}, PH covariates\n✅\n\n\n4\ntest_hazards_weibull_aft\nWeibull AFT: h(t|x) = h₀(t·e^{-β'x})·e^{-β'x}\n✅\n\n\n5\ntest_hazards_gompertz\nGompertz: h(t) = b·e^{at}, PH covariates\n✅\n\n\n6\ntest_hazards_gompertz_aft\nGompertz AFT covariate effects\n✅\n\n\n7\ntest_cumhaz_consistency\nH(a,c) = H(a,b) + H(b,c) additivity\n✅\n\n\n8\ntotal_cumulhaz\nTotal hazard from competing transitions\n✅\n\n\n9\ntpm_computation\nTransition probability matrix computation\n✅\n\n\n\n\n\n\nKey Formulas Verified:\n\n\n\nDistribution\nHazard \\(h(t)\\)\nCumulative Hazard \\(H(t)\\)\n\n\n\n\nExponential\n\\(\\lambda\\)\n\\(\\lambda t\\)\n\n\nWeibull\n\\(\\lambda \\kappa t^{\\kappa-1}\\)\n\\(\\lambda t^\\kappa\\)\n\n\nGompertz\n\\(b \\exp(at)\\)\n\\(\\frac{b}{a}(\\exp(at) - 1)\\)\n\n\n\n\n\nSpline Hazards (test_splines.jl)\nPurpose: Verify B-spline hazard implementation against numerical integration.\n\n\n7×3 DataFrame\n\n\n\nRow\nTestSet\nCoverage\nStatus\n\n\n\nString\nString\nString\n\n\n\n\n1\nCumhaz vs QuadGK\nH(a,b) = ∫ₐᵇ h(t)dt numerical verification\n✅\n\n\n2\nPH covariate effect\nh(t|x) = h₀(t)exp(β'x) multiplicative effect\n✅\n\n\n3\nSurvival probability\nS(a,b) = exp(-H(a,b)) survival function\n✅\n\n\n4\nCumhaz additivity\nH(a,c) = H(a,b) + H(b,c) partition property\n✅\n\n\n5\nKnot placement\nAuto knot placement from data quantiles\n✅\n\n\n6\nCoefficient transforms\nLog-coefficient ↔︎ natural scale transforms\n✅\n\n\n7\nBoundary conditions\nBoundary knot handling for extrapolation\n✅\n\n\n\n\n\n\nNumerical Verification Strategy:\n# Tests verify cumulative hazard matches numerical integration\nH_analytical = eval_cumhaz(hazard, lb, ub, params, covars)\nH_numerical = quadgk(t -&gt; eval_hazard(hazard, t, params, covars), lb, ub)[1]\n@test H_analytical ≈ H_numerical rtol=1e-6\n\n\nSimulation Engine (test_simulation.jl)\nPurpose: Validate path simulation produces statistically correct distributions.\n\n\n7×3 DataFrame\n\n\n\nRow\nTestSet\nCoverage\nStatus\n\n\n\nString\nString\nString\n\n\n\n\n1\nExponential waiting times\nWaiting times ~ Exp(total_hazard)\n✅\n\n\n2\nCompeting risks allocation\nTransition to state j ~ h_j/Σh_k\n✅\n\n\n3\nAbsorbing state termination\nSimulation stops at absorbing states\n✅\n\n\n4\nSojourn time distributions\nNon-Markov sojourns match theory\n✅\n\n\n5\nSolver strategy parity\nOptimJumpSolver vs ExponentialJumpSolver\n✅\n\n\n6\nCovariate propagation\nCovariates correctly passed through path\n✅\n\n\n7\nRight-censoring handling\nPaths correctly censored at max_time\n✅\n\n\n\n\n\n\n\n\nMCEM Algorithm (test_mcem.jl)\nPurpose: Verify Monte Carlo EM components for panel data likelihood.\n\n\n6×3 DataFrame\n\n\n\nRow\nTestSet\nCoverage\nStatus\n\n\n\nString\nString\nString\n\n\n\n\n1\nE-step sampling\nConditional path sampling given observations\n✅\n\n\n2\nM-step optimization\nExpected complete-data LL maximization\n✅\n\n\n3\nSQUAREM acceleration\nAccelerated EM convergence (SQUAREM)\n✅\n\n\n4\nConvergence detection\nAscent-based stopping criterion\n✅\n\n\n5\nPath weighting\nCorrect weighting of sampled paths\n✅\n\n\n6\nImportance weights\nImportance sampling weight computation\n✅\n\n\n\n\n\n\n\n\nPhase-Type Distributions (test_phasetype.jl)\nPurpose: Validate phase-type approximations for semi-Markov processes.\n\n\n6×3 DataFrame\n\n\n\nRow\nTestSet\nCoverage\nStatus\n\n\n\nString\nString\nString\n\n\n\n\n1\nCoxian construction\nCoxian phase-type matrix construction\n✅\n\n\n2\nMoment matching\nFirst two moments match target distribution\n✅\n\n\n3\nHazard approximation\nPhase-type hazard approximates semi-Markov\n✅\n\n\n4\nEmission expansion\nState space expansion for exact obs\n✅\n\n\n5\nPanel expansion\nState space expansion for panel obs\n✅\n\n\n6\nForward-backward algorithm\nForward-backward sampling algorithm\n✅\n\n\n\n\n\n\n\n\nVariance Estimation (test_variance.jl)\nPurpose: Verify variance estimation methods.\n\n\n5×3 DataFrame\n\n\n\nRow\nTestSet\nCoverage\nStatus\n\n\n\nString\nString\nString\n\n\n\n\n1\nObserved information\nHessian-based variance at MLE\n✅\n\n\n2\nIJ covariance\nJackknife sandwich covariance (IJ)\n✅\n\n\n3\nJK covariance\nInfinitesimal jackknife (JK)\n✅\n\n\n4\nPseudovalues\nPseudovalue computation for robust SE\n✅\n\n\n5\nSubject gradients\nPer-subject gradient extraction\n✅\n\n\n\n\n\n\n\n\nModel Construction (test_modelgeneration.jl)\nPurpose: Verify model construction and validation.\n\n\n6×3 DataFrame\n\n\n\nRow\nTestSet\nCoverage\nStatus\n\n\n\nString\nString\nString\n\n\n\n\n1\nHazard parsing\n@hazard macro parses correctly\n✅\n\n\n2\nData validation\nRequired columns, state consistency\n✅\n\n\n3\nParameter construction\nComponentArray structure built correctly\n✅\n\n\n4\nState enumeration\nTransition matrix state mapping\n✅\n\n\n5\nCovariate extraction\nCovariate columns extracted properly\n✅\n\n\n6\nFormula handling\n@formula integration with StatsModels\n✅\n\n\n\n\n\n\n\n\nSampling Importance Resampling (test_sir.jl)\nPurpose: Validate SIR for posterior sampling.\n\n\n4×3 DataFrame\n\n\n\nRow\nTestSet\nCoverage\nStatus\n\n\n\nString\nString\nString\n\n\n\n\n1\nWeight computation\nLog importance weights from proposal/target\n✅\n\n\n2\nResampling\nMultinomial/systematic resampling\n✅\n\n\n3\nPSIS diagnostics\nPareto-smoothed IS integration\n✅\n\n\n4\nESS calculation\nEffective sample size monitoring\n✅"
  },
  {
    "objectID": "unit_tests.html#test-matrix-by-feature",
    "href": "unit_tests.html#test-matrix-by-feature",
    "title": "Unit Test Coverage",
    "section": "Test Matrix by Feature",
    "text": "Test Matrix by Feature\nThe following matrix shows which test files cover which package features:"
  },
  {
    "objectID": "unit_tests.html#running-unit-tests",
    "href": "unit_tests.html#running-unit-tests",
    "title": "Unit Test Coverage",
    "section": "Running Unit Tests",
    "text": "Running Unit Tests\n\nRun All Unit Tests\ncd MultistateModelsTests\njulia --project=. -e 'using Pkg; Pkg.test()'\n\n\nRun Specific Test File\njulia --project=. unit/test_hazards.jl\n\n\nRun with Coverage\njulia --project=. -e '\n    using Pkg\n    Pkg.test(coverage=true)\n'"
  },
  {
    "objectID": "unit_tests.html#test-data-fixtures",
    "href": "unit_tests.html#test-data-fixtures",
    "title": "Unit Test Coverage",
    "section": "Test Data Fixtures",
    "text": "Test Data Fixtures\nUnit tests use standardized fixtures from fixtures/TestFixtures.jl:\n\n\n5×3 DataFrame\n\n\n\nRow\nFixture\nDescription\nObsTypes\n\n\n\nString\nString\nString\n\n\n\n\n1\ntoy_expwei_model()\n2-state with exponential + Weibull hazards\nExact (obstype=1)\n\n\n2\ntoy_gompertz_model()\n2-state with Gompertz hazard\nExact (obstype=1)\n\n\n3\ntoy_spline_model()\n2-state with B-spline hazard\nMixed\n\n\n4\npanel_3state_model()\n3-state progressive model (1→2→3)\nPanel (obstype=2)\n\n\n5\nreversible_model()\n2-state bidirectional (1⇌2)\nBoth"
  },
  {
    "objectID": "unit_tests.html#quality-metrics",
    "href": "unit_tests.html#quality-metrics",
    "title": "Unit Test Coverage",
    "section": "Quality Metrics",
    "text": "Quality Metrics\n\nTest Count Summary\n\n\n10×3 DataFrame\n\n\n\nRow\nFile\nTestSets\nAssertions\n\n\n\nString\nInt64\nInt64\n\n\n\n\n1\ntest_hazards.jl\n25\n180\n\n\n2\ntest_splines.jl\n18\n95\n\n\n3\ntest_simulation.jl\n12\n75\n\n\n4\ntest_mcem.jl\n8\n45\n\n\n5\ntest_phasetype.jl\n15\n85\n\n\n6\ntest_variance.jl\n10\n55\n\n\n7\ntest_sir.jl\n6\n35\n\n\n8\ntest_modelgeneration.jl\n8\n50\n\n\n9\nOther files\n35\n180\n\n\n10\nTOTAL\n137\n800\n\n\n\n\n\n\n\n\nCoverage Goals\n\n\n\nCategory\nTarget\nCurrent\n\n\n\n\nLine Coverage\n&gt;80%\n~85%\n\n\nBranch Coverage\n&gt;70%\n~75%\n\n\nFunction Coverage\n&gt;90%\n~92%"
  },
  {
    "objectID": "unit_tests.html#continuous-integration",
    "href": "unit_tests.html#continuous-integration",
    "title": "Unit Test Coverage",
    "section": "Continuous Integration",
    "text": "Continuous Integration\nUnit tests run on every PR via GitHub Actions:\n\nJulia versions: 1.10, 1.11\nPlatforms: Linux, macOS\nTimeout: 30 minutes\n\n# .github/workflows/test.yml (excerpt)\ntest:\n  runs-on: ubuntu-latest\n  steps:\n    - uses: julia-actions/julia-runtest@v1\n      with:\n        project: MultistateModelsTests"
  },
  {
    "objectID": "unit_tests.html#adding-new-tests",
    "href": "unit_tests.html#adding-new-tests",
    "title": "Unit Test Coverage",
    "section": "Adding New Tests",
    "text": "Adding New Tests\nWhen adding new functionality, follow this checklist:\n\nIdentify the module being tested\nCreate test file in unit/test_&lt;module&gt;.jl\nUse fixtures from TestFixtures.jl where possible\nTest analytical formulas against numerical verification\nInclude edge cases (boundary conditions, empty inputs)\nDocument the test with comments explaining the verification\nAdd to test runner in runtests.jl\n\n\nTest Template\n@testset \"MyFeature\" begin\n    # Setup\n    fixture = appropriate_fixture()\n    model = fixture.model\n    \n    # Set known parameters\n    set_parameters!(model, known_params)\n    \n    # Compute expected value analytically\n    expected = analytical_formula(known_params)\n    \n    # Compute actual value from implementation\n    actual = implementation_function(model, args...)\n    \n    # Compare with appropriate tolerance\n    @test actual ≈ expected rtol=1e-6\nend"
  },
  {
    "objectID": "unit_tests.html#summary",
    "href": "unit_tests.html#summary",
    "title": "Unit Test Coverage",
    "section": "Summary",
    "text": "Summary\nThe unit test suite provides comprehensive coverage of MultistateModels.jl’s core functionality:\n\nHazard functions: All parametric families verified against analytical formulas\nSpline hazards: Numerical integration verification\nSimulation: Statistical correctness of path generation\nMCEM: Component-level testing of EM algorithm\nPhase-type: State expansion and sampling verification\nVariance: Multiple estimation methods tested\n\nTests are designed to catch regressions early and provide documentation of expected behavior through executable specifications."
  }
]