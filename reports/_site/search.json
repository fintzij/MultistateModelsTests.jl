[
  {
    "objectID": "02_unit_tests.html",
    "href": "02_unit_tests.html",
    "title": "Unit Test Coverage",
    "section": "",
    "text": "NoteStatus: Not Started\n\n\n\nThis report is a placeholder. Content will be added as the test documentation is developed."
  },
  {
    "objectID": "02_unit_tests.html#coverage-summary",
    "href": "02_unit_tests.html#coverage-summary",
    "title": "Unit Test Coverage",
    "section": "1. Coverage Summary",
    "text": "1. Coverage Summary\n\nOverall Statistics\n\n\n\nMetric\nValue\n\n\n\n\nTotal Test Files\n-\n\n\nTotal Test Cases\n-\n\n\nPassing\n-\n\n\nFailing\n-\n\n\nCoverage %\n-\n\n\n\n\n\nCoverage by Module\n\n\n\nModule\nTests\nCoverage\n\n\n\n\nHazard\n-\n-\n\n\nLikelihood\n-\n-\n\n\nSimulation\n-\n-\n\n\nInference\n-\n-\n\n\nSplines\n-\n-\n\n\nPhase-Type\n-\n-"
  },
  {
    "objectID": "02_unit_tests.html#hazard-functions",
    "href": "02_unit_tests.html#hazard-functions",
    "title": "Unit Test Coverage",
    "section": "2. Hazard Functions",
    "text": "2. Hazard Functions\n\nTest Summary\n\n\n\nFunction\nTest File\nCondition\nStatus\n\n\n\n\neval_hazard (Exp)\ntest_hazards.jl\nBaseline\n⏳\n\n\neval_hazard (Wei)\ntest_hazards.jl\nBaseline\n⏳\n\n\neval_hazard (Gom)\ntest_hazards.jl\nBaseline\n⏳\n\n\neval_cumhaz (Exp)\ntest_hazards.jl\nWith covariate\n⏳\n\n\neval_cumhaz (Wei)\ntest_hazards.jl\nAFT effect\n⏳\n\n\neval_cumhaz (Gom)\ntest_hazards.jl\nPH effect\n⏳\n\n\n\n\n\nValidation Approach\nTo be documented"
  },
  {
    "objectID": "02_unit_tests.html#likelihood-functions",
    "href": "02_unit_tests.html#likelihood-functions",
    "title": "Unit Test Coverage",
    "section": "3. Likelihood Functions",
    "text": "3. Likelihood Functions\n\nTest Summary\n\n\n\n\n\n\n\n\n\nFunction\nTest File\nCondition\nStatus\n\n\n\n\nloglik_path\ntest_mll_consistency.jl\nExact observation\n⏳\n\n\nloglik\ntest_mll_consistency.jl\nPanel data\n⏳\n\n\ntvc_loglik\ntest_reversible_tvc_loglik.jl\nTime-varying covariates\n⏳\n\n\n\n\n\nValidation Approach\nTo be documented"
  },
  {
    "objectID": "02_unit_tests.html#simulation",
    "href": "02_unit_tests.html#simulation",
    "title": "Unit Test Coverage",
    "section": "4. Simulation",
    "text": "4. Simulation\n\nTest Summary\n\n\n\nFunction\nTest File\nCondition\nStatus\n\n\n\n\nsimulate_path\ntest_simulation.jl\nSingle subject\n⏳\n\n\nsimulate\ntest_simulation.jl\nMultiple subjects\n⏳\n\n\n\n\n\nValidation Approach\nTo be documented"
  },
  {
    "objectID": "02_unit_tests.html#model-construction",
    "href": "02_unit_tests.html#model-construction",
    "title": "Unit Test Coverage",
    "section": "5. Model Construction",
    "text": "5. Model Construction\n\nTest Summary\n\n\n\n\n\n\n\n\n\nFunction\nTest File\nCondition\nStatus\n\n\n\n\nmultistatemodel\ntest_modelgeneration.jl\nBasic model\n⏳\n\n\nHazard\ntest_hazards.jl\nAll families\n⏳\n\n\nset_parameters!\ntest_initialization.jl\nParameter setting\n⏳\n\n\n\n\n\nValidation Approach\nTo be documented"
  },
  {
    "objectID": "02_unit_tests.html#splines-penalization",
    "href": "02_unit_tests.html#splines-penalization",
    "title": "Unit Test Coverage",
    "section": "6. Splines & Penalization",
    "text": "6. Splines & Penalization\n\nTest Summary\n\n\n\nFunction\nTest File\nCondition\nStatus\n\n\n\n\nB-spline basis\ntest_splines.jl\nEvaluation\n⏳\n\n\nPenalty matrix\ntest_splines.jl\nSecond derivative\n⏳\n\n\n\n\n\nValidation Approach\nTo be documented"
  },
  {
    "objectID": "02_unit_tests.html#phase-type-models",
    "href": "02_unit_tests.html#phase-type-models",
    "title": "Unit Test Coverage",
    "section": "7. Phase-Type Models",
    "text": "7. Phase-Type Models\n\nTest Summary\n\n\n\nFunction\nTest File\nCondition\nStatus\n\n\n\n\nExpansion\ntest_phasetype.jl\nState expansion\n⏳\n\n\nCollapse\ntest_phasetype.jl\nState collapse\n⏳\n\n\nFFBS\ntest_phasetype.jl\nForward-backward\n⏳\n\n\n\n\n\nValidation Approach\nTo be documented"
  },
  {
    "objectID": "02_unit_tests.html#helpers-utilities",
    "href": "02_unit_tests.html#helpers-utilities",
    "title": "Unit Test Coverage",
    "section": "8. Helpers & Utilities",
    "text": "8. Helpers & Utilities\n\nTest Summary\n\n\n\nFunction\nTest File\nCondition\nStatus\n\n\n\n\nextract_covariates\ntest_helpers.jl\nCovariate extraction\n⏳\n\n\nget_hazard_params\ntest_helpers.jl\nParameter retrieval\n⏳\n\n\n\n\n\nValidation Approach\nTo be documented"
  },
  {
    "objectID": "simulation_diagnostics.html",
    "href": "simulation_diagnostics.html",
    "title": "Simulation Diagnostics",
    "section": "",
    "text": "This report validates that MultistateModels.jl correctly simulates event times by comparing:\n\nEmpirical CDFs of simulated event times against theoretical CDFs\nHazard functions computed by the package against analytical formulas\nCumulative hazard functions computed vs. expected\n\nFor each hazard family (Exponential, Weibull, Gompertz) and covariate effect type (PH, AFT), we: - Simulate many event times from a 2-state model - Compare the empirical distribution to the theoretical distribution - Report the maximum absolute difference in CDF (should be ≈ 0)"
  },
  {
    "objectID": "simulation_diagnostics.html#overview",
    "href": "simulation_diagnostics.html#overview",
    "title": "Simulation Diagnostics",
    "section": "",
    "text": "This report validates that MultistateModels.jl correctly simulates event times by comparing:\n\nEmpirical CDFs of simulated event times against theoretical CDFs\nHazard functions computed by the package against analytical formulas\nCumulative hazard functions computed vs. expected\n\nFor each hazard family (Exponential, Weibull, Gompertz) and covariate effect type (PH, AFT), we: - Simulate many event times from a 2-state model - Compare the empirical distribution to the theoretical distribution - Report the maximum absolute difference in CDF (should be ≈ 0)"
  },
  {
    "objectID": "simulation_diagnostics.html#configuration",
    "href": "simulation_diagnostics.html#configuration",
    "title": "Simulation Diagnostics",
    "section": "Configuration",
    "text": "Configuration\n\n\nShow code\nconst COVARIATE_VALUE = 1.5\nconst SIM_SAMPLES = 40_000\nconst DIST_GRID_POINTS = 400\n\n# Horizons must be large enough to ensure negligible right-truncation (&lt;0.1%)\n# For Exponential with AFT covariates: effective rate = 0.35 * exp(-0.6*1.5) ≈ 0.14\n# Need: exp(-rate * horizon) &lt; 0.001 =&gt; horizon &gt; log(1000)/rate ≈ 50\n# Setting horizon = 100 provides ample margin\nconst FAMILY_CONFIG = Dict(\n    \"exp\" =&gt; (; rate = 0.35, beta = 0.6, horizon = 100.0),\n    \"wei\" =&gt; (; shape = 1.35, scale = 0.4, beta = -0.35, horizon = 50.0),\n    \"gom\" =&gt; (; shape = 0.6, rate = 0.4, beta = 0.5, horizon = 10.0),  # Gompertz diverges quickly\n)\n\n\nDict{String, NamedTuple} with 3 entries:\n  \"exp\" =&gt; (rate = 0.35, beta = 0.6, horizon = 100.0)\n  \"wei\" =&gt; (shape = 1.35, scale = 0.4, beta = -0.35, horizon = 50.0)\n  \"gom\" =&gt; (shape = 0.6, rate = 0.4, beta = 0.5, horizon = 10.0)"
  },
  {
    "objectID": "simulation_diagnostics.html#analytical-reference-formulas",
    "href": "simulation_diagnostics.html#analytical-reference-formulas",
    "title": "Simulation Diagnostics",
    "section": "Analytical Reference Formulas",
    "text": "Analytical Reference Formulas\n\nExponential Distribution\n\nHazard: \\(h(t) = \\lambda\\)\nCumulative hazard: \\(H(t) = \\lambda t\\)\nCDF: \\(F(t) = 1 - e^{-\\lambda t}\\)\n\n\n\nWeibull Distribution (shape \\(\\kappa\\), scale \\(\\lambda\\))\n\nHazard: \\(h(t) = \\kappa \\lambda t^{\\kappa-1}\\)\nCumulative hazard: \\(H(t) = \\lambda t^\\kappa\\)\nCDF: \\(F(t) = 1 - e^{-\\lambda t^\\kappa}\\)\n\n\n\nGompertz Distribution (flexsurv parameterization: shape \\(a\\), rate \\(b\\))\n\nHazard: \\(h(t) = b e^{at}\\)\nCumulative hazard: \\(H(t) = \\frac{b}{a}(e^{at} - 1)\\)\nCDF: \\(F(t) = 1 - e^{-H(t)}\\)\n\n\n\nCovariate Effects\nProportional Hazards (PH): \\(h(t|x) = h_0(t) e^{\\beta x}\\)\nAccelerated Failure Time (AFT): \\(h(t|x) = h_0(t \\cdot e^{-\\beta x}) \\cdot e^{-\\beta x}\\)"
  },
  {
    "objectID": "simulation_diagnostics.html#helper-functions",
    "href": "simulation_diagnostics.html#helper-functions",
    "title": "Simulation Diagnostics",
    "section": "Helper Functions",
    "text": "Helper Functions\n\n\nShow code\n# Create a 2-state model for a given scenario\nfunction build_test_model(family::String, effect::Symbol, with_covariate::Bool)\n    cfg = FAMILY_CONFIG[family]\n    \n    # Build data frame\n    if with_covariate\n        data = DataFrame(\n            id = [1], tstart = [0.0], tstop = [cfg.horizon],\n            statefrom = [1], stateto = [2], obstype = [1],\n            x = [COVARIATE_VALUE]\n        )\n        formula = @formula(0 ~ x)\n    else\n        data = DataFrame(\n            id = [1], tstart = [0.0], tstop = [cfg.horizon],\n            statefrom = [1], stateto = [2], obstype = [1]\n        )\n        formula = @formula(0 ~ 1)\n    end\n    \n    # Build hazard\n    hazard = Hazard(formula, family, 1, 2; linpred_effect = effect)\n    model = multistatemodel(hazard; data = data)\n    \n    # Set parameters\n    if family == \"exp\"\n        base = [log(cfg.rate)]\n    elseif family == \"wei\"\n        base = [log(cfg.shape), log(cfg.scale)]\n    elseif family == \"gom\"\n        base = [cfg.shape, log(cfg.rate)]  # shape unconstrained, rate log-transformed\n    end\n    \n    pars = with_covariate ? vcat(base, [cfg.beta]) : base\n    hazname = model.hazards[1].hazname\n    set_parameters!(model, NamedTuple{(hazname,)}((pars,)))\n    \n    return model, cfg\nend\n\n# Compute expected CDF for given scenario\nfunction expected_cdf(family::String, effect::Symbol, with_covariate::Bool, t::Float64)\n    cfg = FAMILY_CONFIG[family]\n    xval = with_covariate ? COVARIATE_VALUE : 0.0\n    beta = with_covariate ? cfg.beta : 0.0\n    \n    cumhaz = if family == \"exp\"\n        rate = effect == :ph ? cfg.rate * exp(beta * xval) : cfg.rate * exp(-beta * xval)\n        rate * t\n    elseif family == \"wei\"\n        shape, scale = cfg.shape, cfg.scale\n        mult = effect == :ph ? exp(beta * xval) : exp(-shape * beta * xval)\n        scale * mult * (t^shape)\n    elseif family == \"gom\"\n        shape, rate = cfg.shape, cfg.rate\n        linpred = beta * xval\n        if effect == :ph\n            (rate / shape) * exp(linpred) * (exp(shape * t) - 1)\n        else\n            time_scale = exp(-linpred)\n            scaled_shape = shape * time_scale\n            scaled_rate = rate * time_scale\n            (scaled_rate / scaled_shape) * (exp(scaled_shape * t) - 1)\n        end\n    end\n    \n    return 1 - exp(-cumhaz)\nend\n\n# Simulate event times from model\n# WARNING: Only collects paths where a transition occurred within horizon.\n# Set horizon large enough so P(T &gt; horizon) &lt; 0.001 to avoid right-truncation bias.\nfunction simulate_event_times(model, nsim::Int; rng = Random.default_rng())\n    durations = Float64[]\n    n_censored = 0\n    strategy = CachedTransformStrategy()\n    total_attempts = 0\n    max_attempts = nsim * 20  # Safety limit\n    \n    while length(durations) &lt; nsim && total_attempts &lt; max_attempts\n        total_attempts += 1\n        path = simulate_path(model, 1; strategy = strategy, rng = rng)\n        if path.states[end] != path.states[1]\n            push!(durations, path.times[end] - path.times[1])\n        else\n            n_censored += 1\n        end\n    end\n    \n    # Warn if significant truncation detected\n    truncation_rate = n_censored / total_attempts\n    if truncation_rate &gt; 0.01\n        @warn \"High right-truncation rate: $(round(truncation_rate*100, digits=1))%. Increase horizon.\"\n    end\n    \n    return durations\nend\n\n# Compute maximum CDF difference\nfunction max_cdf_diff(durations::Vector{Float64}, cdf_func, horizon::Float64)\n    # Compute empirical CDF\n    sorted = sort(durations)\n    n = length(sorted)\n    ecdf_vals = (1:n) ./ n\n    \n    # Compute theoretical CDF at each point\n    tcdf_vals = [cdf_func(t) for t in sorted]\n    \n    # Max absolute difference\n    return maximum(abs.(ecdf_vals .- tcdf_vals))\nend\n\n\nmax_cdf_diff (generic function with 1 method)"
  },
  {
    "objectID": "simulation_diagnostics.html#diagnostic-results",
    "href": "simulation_diagnostics.html#diagnostic-results",
    "title": "Simulation Diagnostics",
    "section": "Diagnostic Results",
    "text": "Diagnostic Results\n\n\nShow code\n# Run diagnostics for all scenarios\nresults = DataFrame(\n    Family = String[],\n    Effect = String[],\n    Covariate = String[],\n    MaxCDFDiff = Float64[],\n    Status = String[]\n)\n\nscenarios = [\n    (\"exp\", :ph, false), (\"exp\", :ph, true),\n    (\"exp\", :aft, false), (\"exp\", :aft, true),\n    (\"wei\", :ph, false), (\"wei\", :ph, true),\n    (\"wei\", :aft, false), (\"wei\", :aft, true),\n    (\"gom\", :ph, false), (\"gom\", :ph, true),\n    (\"gom\", :aft, false), (\"gom\", :aft, true),\n]\n\nRandom.seed!(12345)\n\nfor (family, effect, with_cov) in scenarios\n    model, cfg = build_test_model(family, effect, with_cov)\n    \n    # Simulate event times\n    durations = simulate_event_times(model, SIM_SAMPLES)\n    \n    # Expected CDF function\n    cdf_func = t -&gt; expected_cdf(family, effect, with_cov, t)\n    \n    # Compute max difference\n    max_diff = max_cdf_diff(durations, cdf_func, cfg.horizon)\n    \n    push!(results, (\n        uppercasefirst(family),\n        uppercase(String(effect)),\n        with_cov ? \"Yes\" : \"No\",\n        round(max_diff, digits=4),\n        max_diff &lt; 0.02 ? \"✅ Pass\" : \"❌ Fail\"\n    ))\nend\n\nresults\n\n\n\n******************************************************************************\nThis program contains Ipopt, a library for large-scale nonlinear optimization.\n Ipopt is released as open source code under the Eclipse Public License (EPL).\n         For more information visit https://github.com/coin-or/Ipopt\n******************************************************************************\n\n\n\n\n\nTable 1: Simulation Diagnostic Summary\n\n\n\n12×5 DataFrame\n\n\n\nRow\nFamily\nEffect\nCovariate\nMaxCDFDiff\nStatus\n\n\n\nString\nString\nString\nFloat64\nString\n\n\n\n\n1\nExp\nPH\nNo\n0.0042\n✅ Pass\n\n\n2\nExp\nPH\nYes\n0.0034\n✅ Pass\n\n\n3\nExp\nAFT\nNo\n0.0039\n✅ Pass\n\n\n4\nExp\nAFT\nYes\n0.0042\n✅ Pass\n\n\n5\nWei\nPH\nNo\n0.0063\n✅ Pass\n\n\n6\nWei\nPH\nYes\n0.0035\n✅ Pass\n\n\n7\nWei\nAFT\nNo\n0.0063\n✅ Pass\n\n\n8\nWei\nAFT\nYes\n0.0031\n✅ Pass\n\n\n9\nGom\nPH\nNo\n0.0088\n✅ Pass\n\n\n10\nGom\nPH\nYes\n0.0045\n✅ Pass\n\n\n11\nGom\nAFT\nNo\n0.0054\n✅ Pass\n\n\n12\nGom\nAFT\nYes\n0.0046\n✅ Pass"
  },
  {
    "objectID": "simulation_diagnostics.html#diagnostic-plots",
    "href": "simulation_diagnostics.html#diagnostic-plots",
    "title": "Simulation Diagnostics",
    "section": "Diagnostic Plots",
    "text": "Diagnostic Plots\n\nExponential Distribution\n\n\nShow code\nfig = Figure(size=(900, 700))\n\nRandom.seed!(11111)\n\n# Baseline PH\nmodel_exp_base, cfg_exp = build_test_model(\"exp\", :ph, false)\ndurations_exp_base = simulate_event_times(model_exp_base, SIM_SAMPLES)\n\nax1 = Axis(fig[1, 1], xlabel=\"Time\", ylabel=\"CDF\", title=\"Exp PH Baseline\")\nt_grid = range(0, cfg_exp.horizon, length=DIST_GRID_POINTS)\necdf_exp = ecdf(durations_exp_base)\nlines!(ax1, t_grid, [ecdf_exp(t) for t in t_grid], label=\"Empirical\", linewidth=2)\nlines!(ax1, t_grid, [expected_cdf(\"exp\", :ph, false, t) for t in t_grid], \n       label=\"Theoretical\", linestyle=:dash, linewidth=2, color=:red)\naxislegend(ax1, position=:rb)\n\n# With covariate PH\nmodel_exp_cov, _ = build_test_model(\"exp\", :ph, true)\ndurations_exp_cov = simulate_event_times(model_exp_cov, SIM_SAMPLES)\n\nax2 = Axis(fig[1, 2], xlabel=\"Time\", ylabel=\"CDF\", title=\"Exp PH with Covariate\")\necdf_exp_cov = ecdf(durations_exp_cov)\nlines!(ax2, t_grid, [ecdf_exp_cov(t) for t in t_grid], label=\"Empirical\", linewidth=2)\nlines!(ax2, t_grid, [expected_cdf(\"exp\", :ph, true, t) for t in t_grid], \n       label=\"Theoretical\", linestyle=:dash, linewidth=2, color=:red)\naxislegend(ax2, position=:rb)\n\n# AFT baseline\nmodel_exp_aft, _ = build_test_model(\"exp\", :aft, false)\ndurations_exp_aft = simulate_event_times(model_exp_aft, SIM_SAMPLES)\n\nax3 = Axis(fig[2, 1], xlabel=\"Time\", ylabel=\"CDF\", title=\"Exp AFT Baseline\")\necdf_exp_aft = ecdf(durations_exp_aft)\nlines!(ax3, t_grid, [ecdf_exp_aft(t) for t in t_grid], label=\"Empirical\", linewidth=2)\nlines!(ax3, t_grid, [expected_cdf(\"exp\", :aft, false, t) for t in t_grid], \n       label=\"Theoretical\", linestyle=:dash, linewidth=2, color=:red)\naxislegend(ax3, position=:rb)\n\n# AFT with covariate\nmodel_exp_aft_cov, _ = build_test_model(\"exp\", :aft, true)\ndurations_exp_aft_cov = simulate_event_times(model_exp_aft_cov, SIM_SAMPLES)\n\nax4 = Axis(fig[2, 2], xlabel=\"Time\", ylabel=\"CDF\", title=\"Exp AFT with Covariate\")\necdf_exp_aft_cov = ecdf(durations_exp_aft_cov)\nlines!(ax4, t_grid, [ecdf_exp_aft_cov(t) for t in t_grid], label=\"Empirical\", linewidth=2)\nlines!(ax4, t_grid, [expected_cdf(\"exp\", :aft, true, t) for t in t_grid], \n       label=\"Theoretical\", linestyle=:dash, linewidth=2, color=:red)\naxislegend(ax4, position=:rb)\n\nfig\n\n\n\n\n\n\n\n\nFigure 1: Exponential Hazard Diagnostics\n\n\n\n\n\n\n\nWeibull Distribution\n\n\nShow code\nfig = Figure(size=(900, 700))\n\nRandom.seed!(22222)\ncfg_wei = FAMILY_CONFIG[\"wei\"]\nt_grid_wei = range(0.02, cfg_wei.horizon, length=DIST_GRID_POINTS)  # Start &gt; 0 for Weibull\n\n# Baseline PH\nmodel_wei_base, _ = build_test_model(\"wei\", :ph, false)\ndurations_wei_base = simulate_event_times(model_wei_base, SIM_SAMPLES)\n\nax1 = Axis(fig[1, 1], xlabel=\"Time\", ylabel=\"CDF\", title=\"Weibull PH Baseline\")\necdf_wei = ecdf(durations_wei_base)\nlines!(ax1, t_grid_wei, [ecdf_wei(t) for t in t_grid_wei], label=\"Empirical\", linewidth=2)\nlines!(ax1, t_grid_wei, [expected_cdf(\"wei\", :ph, false, t) for t in t_grid_wei], \n       label=\"Theoretical\", linestyle=:dash, linewidth=2, color=:red)\naxislegend(ax1, position=:rb)\n\n# With covariate PH\nmodel_wei_cov, _ = build_test_model(\"wei\", :ph, true)\ndurations_wei_cov = simulate_event_times(model_wei_cov, SIM_SAMPLES)\n\nax2 = Axis(fig[1, 2], xlabel=\"Time\", ylabel=\"CDF\", title=\"Weibull PH with Covariate\")\necdf_wei_cov = ecdf(durations_wei_cov)\nlines!(ax2, t_grid_wei, [ecdf_wei_cov(t) for t in t_grid_wei], label=\"Empirical\", linewidth=2)\nlines!(ax2, t_grid_wei, [expected_cdf(\"wei\", :ph, true, t) for t in t_grid_wei], \n       label=\"Theoretical\", linestyle=:dash, linewidth=2, color=:red)\naxislegend(ax2, position=:rb)\n\n# AFT baseline\nmodel_wei_aft, _ = build_test_model(\"wei\", :aft, false)\ndurations_wei_aft = simulate_event_times(model_wei_aft, SIM_SAMPLES)\n\nax3 = Axis(fig[2, 1], xlabel=\"Time\", ylabel=\"CDF\", title=\"Weibull AFT Baseline\")\necdf_wei_aft = ecdf(durations_wei_aft)\nlines!(ax3, t_grid_wei, [ecdf_wei_aft(t) for t in t_grid_wei], label=\"Empirical\", linewidth=2)\nlines!(ax3, t_grid_wei, [expected_cdf(\"wei\", :aft, false, t) for t in t_grid_wei], \n       label=\"Theoretical\", linestyle=:dash, linewidth=2, color=:red)\naxislegend(ax3, position=:rb)\n\n# AFT with covariate\nmodel_wei_aft_cov, _ = build_test_model(\"wei\", :aft, true)\ndurations_wei_aft_cov = simulate_event_times(model_wei_aft_cov, SIM_SAMPLES)\n\nax4 = Axis(fig[2, 2], xlabel=\"Time\", ylabel=\"CDF\", title=\"Weibull AFT with Covariate\")\necdf_wei_aft_cov = ecdf(durations_wei_aft_cov)\nlines!(ax4, t_grid_wei, [ecdf_wei_aft_cov(t) for t in t_grid_wei], label=\"Empirical\", linewidth=2)\nlines!(ax4, t_grid_wei, [expected_cdf(\"wei\", :aft, true, t) for t in t_grid_wei], \n       label=\"Theoretical\", linestyle=:dash, linewidth=2, color=:red)\naxislegend(ax4, position=:rb)\n\nfig\n\n\n\n\n\n\n\n\nFigure 2: Weibull Hazard Diagnostics\n\n\n\n\n\n\n\nGompertz Distribution\n\n\nShow code\nfig = Figure(size=(900, 700))\n\nRandom.seed!(33333)\ncfg_gom = FAMILY_CONFIG[\"gom\"]\nt_grid_gom = range(0, cfg_gom.horizon, length=DIST_GRID_POINTS)\n\n# Baseline PH\nmodel_gom_base, _ = build_test_model(\"gom\", :ph, false)\ndurations_gom_base = simulate_event_times(model_gom_base, SIM_SAMPLES)\n\nax1 = Axis(fig[1, 1], xlabel=\"Time\", ylabel=\"CDF\", title=\"Gompertz PH Baseline\")\necdf_gom = ecdf(durations_gom_base)\nlines!(ax1, t_grid_gom, [ecdf_gom(t) for t in t_grid_gom], label=\"Empirical\", linewidth=2)\nlines!(ax1, t_grid_gom, [expected_cdf(\"gom\", :ph, false, t) for t in t_grid_gom], \n       label=\"Theoretical\", linestyle=:dash, linewidth=2, color=:red)\naxislegend(ax1, position=:rb)\n\n# With covariate PH\nmodel_gom_cov, _ = build_test_model(\"gom\", :ph, true)\ndurations_gom_cov = simulate_event_times(model_gom_cov, SIM_SAMPLES)\n\nax2 = Axis(fig[1, 2], xlabel=\"Time\", ylabel=\"CDF\", title=\"Gompertz PH with Covariate\")\necdf_gom_cov = ecdf(durations_gom_cov)\nlines!(ax2, t_grid_gom, [ecdf_gom_cov(t) for t in t_grid_gom], label=\"Empirical\", linewidth=2)\nlines!(ax2, t_grid_gom, [expected_cdf(\"gom\", :ph, true, t) for t in t_grid_gom], \n       label=\"Theoretical\", linestyle=:dash, linewidth=2, color=:red)\naxislegend(ax2, position=:rb)\n\n# AFT baseline\nmodel_gom_aft, _ = build_test_model(\"gom\", :aft, false)\ndurations_gom_aft = simulate_event_times(model_gom_aft, SIM_SAMPLES)\n\nax3 = Axis(fig[2, 1], xlabel=\"Time\", ylabel=\"CDF\", title=\"Gompertz AFT Baseline\")\necdf_gom_aft = ecdf(durations_gom_aft)\nlines!(ax3, t_grid_gom, [ecdf_gom_aft(t) for t in t_grid_gom], label=\"Empirical\", linewidth=2)\nlines!(ax3, t_grid_gom, [expected_cdf(\"gom\", :aft, false, t) for t in t_grid_gom], \n       label=\"Theoretical\", linestyle=:dash, linewidth=2, color=:red)\naxislegend(ax3, position=:rb)\n\n# AFT with covariate\nmodel_gom_aft_cov, _ = build_test_model(\"gom\", :aft, true)\ndurations_gom_aft_cov = simulate_event_times(model_gom_aft_cov, SIM_SAMPLES)\n\nax4 = Axis(fig[2, 2], xlabel=\"Time\", ylabel=\"CDF\", title=\"Gompertz AFT with Covariate\")\necdf_gom_aft_cov = ecdf(durations_gom_aft_cov)\nlines!(ax4, t_grid_gom, [ecdf_gom_aft_cov(t) for t in t_grid_gom], label=\"Empirical\", linewidth=2)\nlines!(ax4, t_grid_gom, [expected_cdf(\"gom\", :aft, true, t) for t in t_grid_gom], \n       label=\"Theoretical\", linestyle=:dash, linewidth=2, color=:red)\naxislegend(ax4, position=:rb)\n\nfig\n\n\n\n\n\n\n\n\nFigure 3: Gompertz Hazard Diagnostics"
  },
  {
    "objectID": "simulation_diagnostics.html#hazard-function-verification",
    "href": "simulation_diagnostics.html#hazard-function-verification",
    "title": "Simulation Diagnostics",
    "section": "Hazard Function Verification",
    "text": "Hazard Function Verification\nThe CDF plots above implicitly verify hazard function correctness - if the hazard functions were wrong, the simulated CDFs would not match the theoretical CDFs.\nFor explicit verification, the hazard functions use the following formulas:\n\n\n\nFamily\nHazard \\(h(t)\\)\nImplementation\n\n\n\n\nExponential\n\\(\\lambda\\)\nrate\n\n\nWeibull\n\\(a \\cdot b \\cdot t^{a-1}\\)\nshape * scale * t^(shape-1)\n\n\nGompertz\n\\(b \\cdot e^{at}\\)\nrate * exp(shape * t)\n\n\n\nWhere shape and scale (or rate) are the distribution parameters. The Gompertz uses the flexsurv parameterization."
  },
  {
    "objectID": "simulation_diagnostics.html#summary",
    "href": "simulation_diagnostics.html#summary",
    "title": "Simulation Diagnostics",
    "section": "Summary",
    "text": "Summary\nAll simulation diagnostics pass:\n\nExponential: PH and AFT baseline and with covariates ✅\nWeibull: PH and AFT baseline and with covariates ✅\nGompertz: PH and AFT baseline and with covariates ✅\n\nThe maximum CDF differences are all essentially zero (within Monte Carlo error), confirming that:\n\nEvent time simulation is statistically correct\nHazard functions are implemented correctly\nCovariate effects (PH and AFT) work as expected\nThe flexsurv Gompertz parameterization is correctly implemented"
  },
  {
    "objectID": "simulation_diagnostics.html#technical-notes",
    "href": "simulation_diagnostics.html#technical-notes",
    "title": "Simulation Diagnostics",
    "section": "Technical Notes",
    "text": "Technical Notes\n\nGompertz Parameterization\nMultistateModels.jl uses the flexsurv Gompertz parameterization: - shape (\\(a\\)): Rate of hazard increase (can be negative for decreasing hazard) - rate (\\(b\\)): Initial hazard at \\(t=0\\)\nThis differs from some other parameterizations. The hazard is: \\[h(t) = b \\cdot e^{at}\\]\n\n\nSimulation Strategy\nThe diagnostics use CachedTransformStrategy() which caches inverse CDF computations for efficiency. The DirectTransformStrategy() computes inversions fresh each time. Both should produce identical results.\n\n\nMonte Carlo Error\nWith 40,000 samples, the expected maximum CDF error from Monte Carlo is approximately: \\[\\sqrt{\\frac{\\log(n)}{2n}} \\approx 0.007\\]\nSo maximum differences &lt; 0.02 are consistent with simulation being correct."
  },
  {
    "objectID": "01_architecture.html",
    "href": "01_architecture.html",
    "title": "Package Architecture & Workflow",
    "section": "",
    "text": "NoteStatus: Not Started\n\n\n\nThis report is a placeholder. Content will be added as the package documentation is developed."
  },
  {
    "objectID": "01_architecture.html#introduction",
    "href": "01_architecture.html#introduction",
    "title": "Package Architecture & Workflow",
    "section": "1. Introduction",
    "text": "1. Introduction\n\nDesign Philosophy\nMultistateModels.jl is designed to provide flexible tools for analyzing multistate survival data. The package supports:\n\nMultiple hazard families (Exponential, Weibull, Gompertz, B-splines)\nBoth proportional hazards (PH) and accelerated failure time (AFT) covariate effects\nExactly observed and panel (interval-censored) data\nTime-varying covariates\nSemi-Markov models with duration dependence\n\n\n\nPackage Overview\n\n\nShow code\n# Core workflow\nusing MultistateModels\n\n# 1. Define hazards\nhazards = (\n    h12 = Hazard(@formula(0 ~ x), \"wei\", 1, 2),\n    h23 = Hazard(@formula(0 ~ 1), \"exp\", 2, 3)\n)\n\n# 2. Build model\nmodel = multistatemodel(hazards; data = df)\n\n# 3. Fit model\nfit!(model)\n\n# 4. Simulate from fitted model\npaths = simulate(model; nsim = 1000)"
  },
  {
    "objectID": "01_architecture.html#model-construction",
    "href": "01_architecture.html#model-construction",
    "title": "Package Architecture & Workflow",
    "section": "2. Model Construction",
    "text": "2. Model Construction\n\n2.1 The MultistateProcess Struct\nTo be documented\n\n\n2.2 Hazard Specification\nTo be documented\n\n\n2.3 Parameterization Conventions\nAll hazard families follow flexsurv conventions:\n\n\n\n\n\n\n\n\nFamily\nHazard Function\nParameters\n\n\n\n\nExponential\n\\(h(t) = \\text{rate}\\)\nrate &gt; 0\n\n\nWeibull\n\\(h(t) = \\text{shape} \\times \\text{scale} \\times t^{\\text{shape}-1}\\)\nshape &gt; 0, scale &gt; 0\n\n\nGompertz\n\\(h(t) = \\text{rate} \\times \\exp(\\text{shape} \\times t)\\)\nshape ∈ ℝ, rate &gt; 0\n\n\nB-Spline\n\\(h(t) = \\exp(\\mathbf{B}(t)' \\boldsymbol{\\theta})\\)\nθ ∈ ℝ^k\n\n\n\n\n\n2.4 Covariate Effects\nTo be documented\n\n\n2.5 Time-Varying Covariates\nTo be documented\n\n\n2.6 The multistatemodel() Constructor\nTo be documented\n\n\n2.7 Data Requirements\nTo be documented"
  },
  {
    "objectID": "01_architecture.html#simulation-engine",
    "href": "01_architecture.html#simulation-engine",
    "title": "Package Architecture & Workflow",
    "section": "3. Simulation Engine",
    "text": "3. Simulation Engine\n\n3.1 simulate() vs simulate_path()\nTo be documented\n\n\n3.2 Transform Strategies\nTo be documented\n\n\n3.3 Jump Solvers\nTo be documented\n\n\n3.4 Phase-Type Expansion\nTo be documented"
  },
  {
    "objectID": "01_architecture.html#inference",
    "href": "01_architecture.html#inference",
    "title": "Package Architecture & Workflow",
    "section": "4. Inference",
    "text": "4. Inference\n\n4.1 Likelihood Calculations\nTo be documented\n\n\n4.2 MCEM Algorithm\nTo be documented\n\n\n4.3 Optimization Wrappers\nTo be documented\n\n\n4.4 Parameter Constraints\nTo be documented"
  },
  {
    "objectID": "01_architecture.html#key-internal-functions",
    "href": "01_architecture.html#key-internal-functions",
    "title": "Package Architecture & Workflow",
    "section": "5. Key Internal Functions",
    "text": "5. Key Internal Functions\n\n5.1 Hazard Evaluation\nTo be documented\n\n\n5.2 Survival Probability\nTo be documented\n\n\n5.3 Parameter Handling\nTo be documented\n\n\n5.4 Time Transforms\nTo be documented"
  },
  {
    "objectID": "01_architecture.html#option-reference",
    "href": "01_architecture.html#option-reference",
    "title": "Package Architecture & Workflow",
    "section": "6. Option Reference",
    "text": "6. Option Reference\nTo be documented"
  },
  {
    "objectID": "benchmarks.html",
    "href": "benchmarks.html",
    "title": "Performance Benchmarks",
    "section": "",
    "text": "Note: These results are generated from MultistateModelsTests/benchmarks/run_benchmarks.jl. Last run: December 2025.\n\n\n0×2 DataFrame\n\n\n\nRow\nThreads\nRuntime\n\n\n\nUnion{}\nUnion{}"
  },
  {
    "objectID": "benchmarks.html#benchmark-results",
    "href": "benchmarks.html#benchmark-results",
    "title": "Performance Benchmarks",
    "section": "",
    "text": "Note: These results are generated from MultistateModelsTests/benchmarks/run_benchmarks.jl. Last run: December 2025.\n\n\n0×2 DataFrame\n\n\n\nRow\nThreads\nRuntime\n\n\n\nUnion{}\nUnion{}"
  },
  {
    "objectID": "benchmarks.html#scalability-analysis",
    "href": "benchmarks.html#scalability-analysis",
    "title": "Performance Benchmarks",
    "section": "Scalability Analysis",
    "text": "Scalability Analysis\n\nSample Size Scaling\n\n\nShow code\nif !isempty(scalability_df)\n    fig = Figure(size=(700, 400))\n    \n    ax = Axis(fig[1, 1],\n        xlabel=\"Sample Size (n)\",\n        ylabel=\"Runtime (seconds)\",\n        title=\"Runtime Scaling\",\n        xscale=log10,\n        yscale=log10,\n        xticks=(scalability_df.N, string.(scalability_df.N)))\n    \n    scatter!(ax, scalability_df.N, scalability_df.Runtime, label=\"Panel (MCEM)\", \n             markersize=12, color=:orange)\n    lines!(ax, scalability_df.N, scalability_df.Runtime, color=:orange, linewidth=2)\n    \n    axislegend(ax, position=:lt)\n    fig\nelse\n    println(\"No scalability data available.\")\nend\n\n\n\n\n\n\n\n\nFigure 1: Runtime Scaling with Sample Size"
  },
  {
    "objectID": "benchmarks.html#squarem-acceleration",
    "href": "benchmarks.html#squarem-acceleration",
    "title": "Performance Benchmarks",
    "section": "SQUAREM Acceleration",
    "text": "SQUAREM Acceleration\n\n\nSQUAREM Runtime (N=200): 0.0108 seconds"
  },
  {
    "objectID": "benchmarks.html#threading-performance",
    "href": "benchmarks.html#threading-performance",
    "title": "Performance Benchmarks",
    "section": "Threading Performance",
    "text": "Threading Performance\n\n\nNo threading data available.\n\n\n\nComplexity Analysis\n\n\n\nOperation\nComplexity\nNotes\n\n\n\n\nExact likelihood\nO(n)\nPer-subject TPM computation\n\n\nPanel likelihood\nO(n × k)\nk = paths per subject\n\n\nGradient computation\nO(n × p)\np = number of parameters\n\n\nMCEM per iteration\nO(n × k × m)\nm = MCEM paths\n\n\n\n\n\nThreading Recommendations\n\n\n4×3 DataFrame\n\n\n\nRow\nScenario\nRecommendedThreads\nNotes\n\n\n\nString\nString\nString\n\n\n\n\n1\nSmall dataset (n &lt; 500)\n1-2\nThread overhead dominates\n\n\n2\nMedium dataset (n ~ 1000)\n4\nGood balance\n\n\n3\nLarge dataset (n &gt; 2000)\n8-16\nNear-linear scaling\n\n\n4\nMCEM with many paths\nMatch physical cores\nMemory bandwidth limit"
  },
  {
    "objectID": "benchmarks.html#phase-type-proposal-performance",
    "href": "benchmarks.html#phase-type-proposal-performance",
    "title": "Performance Benchmarks",
    "section": "Phase-Type Proposal Performance",
    "text": "Phase-Type Proposal Performance\nBenchmark pending implementation."
  },
  {
    "objectID": "benchmarks.html#running-benchmarks",
    "href": "benchmarks.html#running-benchmarks",
    "title": "Performance Benchmarks",
    "section": "Running Benchmarks",
    "text": "Running Benchmarks\n# Full benchmark suite\njulia --project=MultistateModelsTests MultistateModelsTests/benchmarks/run_benchmarks.jl\n\nBenchmark Environment\n\n\nShow code\n# System information for reproducibility\nprintln(\"Julia version: \", VERSION)\nprintln(\"Threads available: \", Threads.nthreads())\n# println(\"Physical cores: \", MultistateModels.get_physical_cores())\n\n\nJulia version: 1.12.2\nThreads available: 1"
  },
  {
    "objectID": "benchmarks.html#summary",
    "href": "benchmarks.html#summary",
    "title": "Performance Benchmarks",
    "section": "Summary",
    "text": "Summary\n\nPerformance Highlights\n\nExact data fitting: Scales linearly with sample size\nPanel data (MCEM): Slower than exact, but handles interval censoring\nSQUAREM: Accelerated EM convergence (enabled by default)\nThreading: Parallel likelihood computation\nPhase-type proposals: Critical for non-exponential hazards in MCEM\n\n\n\nOptimization Tips\n\nUse exact observations when available - much faster than panel\nEnable SQUAREM - default in fit(), significantly faster\nMatch threads to physical cores - avoid hyperthreading overhead\nUse phase-type proposals for semi-Markov - automatic selection in fit()\nProfile before optimizing - identify actual bottlenecks\n\n\n\nMemory Management\n\nPre-allocate path storage for MCEM\nUse CachedTransformStrategy() for repeated simulations\nConsider batched processing for very large datasets"
  },
  {
    "objectID": "03_long_tests.html",
    "href": "03_long_tests.html",
    "title": "Long Tests Status",
    "section": "",
    "text": "**Summary**: 23 / 28 tests passed (5 failed)\n\n\n\n\n\nTable 1: Long Test Results Summary\n\n\n\n28×7 DataFrame3 rows omitted\n\n\n\nRow\nTestName\nFamily\nDataType\nCovariates\nNSubjects\nStatus\nTimestamp\n\n\n\nString\nString\nString\nString\nInt64\nString\nString\n\n\n\n\n1\nexp_exact_fixed\nexp\nexact\nfixed\n1000\n✅ Pass\n2026-01-01T16:30:59.909\n\n\n2\nexp_exact_nocov\nexp\nexact\nnocov\n1000\n✅ Pass\n2026-01-01T16:30:56.638\n\n\n3\nexp_exact_tvc\nexp\nexact\ntvc\n1000\n✅ Pass\n2026-01-01T16:31:00.825\n\n\n4\nexp_panel_fixed\nexp\npanel\nfixed\n986\n✅ Pass\n2026-01-01T16:33:12.818\n\n\n5\nexp_panel_nocov\nexp\npanel\nnocov\n990\n✅ Pass\n2026-01-01T16:33:02.121\n\n\n6\nexp_panel_tvc\nexp\npanel\ntvc\n990\n✅ Pass\n2026-01-01T16:33:23.251\n\n\n7\ngom_exact_fixed\ngom\nexact\nfixed\n1000\n✅ Pass\n2026-01-01T16:32:31.437\n\n\n8\ngom_exact_nocov\ngom\nexact\nnocov\n1000\n✅ Pass\n2026-01-01T16:32:13.335\n\n\n9\ngom_exact_tvc\ngom\nexact\ntvc\n1000\n✅ Pass\n2026-01-01T16:32:51.437\n\n\n10\ngom_mcem_fixed\ngom\nmcem\nfixed\n984\n✅ Pass\n2026-01-01T16:37:58.797\n\n\n11\ngom_mcem_nocov\ngom\nmcem\nnocov\n992\n✅ Pass\n2026-01-01T16:37:05.896\n\n\n12\ngom_mcem_tvc\ngom\nmcem\ntvc\n993\n❌ Fail\n2026-01-01T16:38:53.898\n\n\n13\npt_mixed_simple\nphasetype\nmixed\nnone\n1000\n✅ Pass\n2026-01-01T16:50:16.242\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n17\npt_panel_simple\nphasetype\npanel\nnone\n1000\n✅ Pass\n2026-01-01T16:49:53.801\n\n\n18\npt_panel_tvc\nphasetype\npanel\ntvc\n1000\n❌ Fail\n2026-01-01T16:50:57.991\n\n\n19\npt_exact_fixed\npt\nexact\nfixed\n1000\n✅ Pass\n2026-01-01T16:49:44.907\n\n\n20\npt_exact_nocov\npt\nexact\nnocov\n1000\n✅ Pass\n2026-01-01T16:49:39.984\n\n\n21\npt_exact_tvc\npt\nexact\ntvc\n1000\n✅ Pass\n2026-01-01T16:49:45.453\n\n\n22\nsp_mcem_fixed\nsp\npanel\nfixed\n1000\n❌ Fail\n2026-01-01T17:08:41.835\n\n\n23\nwei_exact_fixed\nwei\nexact\nfixed\n1000\n✅ Pass\n2026-01-01T16:31:38.432\n\n\n24\nwei_exact_nocov\nwei\nexact\nnocov\n1000\n✅ Pass\n2026-01-01T16:31:17.325\n\n\n25\nwei_exact_tvc\nwei\nexact\ntvc\n1000\n✅ Pass\n2026-01-01T16:31:58.169\n\n\n26\nwei_mcem_fixed\nwei\nmcem\nfixed\n989\n✅ Pass\n2026-01-01T16:35:28.655\n\n\n27\nwei_mcem_nocov\nwei\nmcem\nnocov\n991\n✅ Pass\n2026-01-01T16:34:12.161\n\n\n28\nwei_mcem_tvc\nwei\nmcem\ntvc\n995\n❌ Fail\n2026-01-01T16:36:30.196"
  },
  {
    "objectID": "03_long_tests.html#test-inventory",
    "href": "03_long_tests.html#test-inventory",
    "title": "Long Tests Status",
    "section": "",
    "text": "**Summary**: 23 / 28 tests passed (5 failed)\n\n\n\n\n\nTable 1: Long Test Results Summary\n\n\n\n28×7 DataFrame3 rows omitted\n\n\n\nRow\nTestName\nFamily\nDataType\nCovariates\nNSubjects\nStatus\nTimestamp\n\n\n\nString\nString\nString\nString\nInt64\nString\nString\n\n\n\n\n1\nexp_exact_fixed\nexp\nexact\nfixed\n1000\n✅ Pass\n2026-01-01T16:30:59.909\n\n\n2\nexp_exact_nocov\nexp\nexact\nnocov\n1000\n✅ Pass\n2026-01-01T16:30:56.638\n\n\n3\nexp_exact_tvc\nexp\nexact\ntvc\n1000\n✅ Pass\n2026-01-01T16:31:00.825\n\n\n4\nexp_panel_fixed\nexp\npanel\nfixed\n986\n✅ Pass\n2026-01-01T16:33:12.818\n\n\n5\nexp_panel_nocov\nexp\npanel\nnocov\n990\n✅ Pass\n2026-01-01T16:33:02.121\n\n\n6\nexp_panel_tvc\nexp\npanel\ntvc\n990\n✅ Pass\n2026-01-01T16:33:23.251\n\n\n7\ngom_exact_fixed\ngom\nexact\nfixed\n1000\n✅ Pass\n2026-01-01T16:32:31.437\n\n\n8\ngom_exact_nocov\ngom\nexact\nnocov\n1000\n✅ Pass\n2026-01-01T16:32:13.335\n\n\n9\ngom_exact_tvc\ngom\nexact\ntvc\n1000\n✅ Pass\n2026-01-01T16:32:51.437\n\n\n10\ngom_mcem_fixed\ngom\nmcem\nfixed\n984\n✅ Pass\n2026-01-01T16:37:58.797\n\n\n11\ngom_mcem_nocov\ngom\nmcem\nnocov\n992\n✅ Pass\n2026-01-01T16:37:05.896\n\n\n12\ngom_mcem_tvc\ngom\nmcem\ntvc\n993\n❌ Fail\n2026-01-01T16:38:53.898\n\n\n13\npt_mixed_simple\nphasetype\nmixed\nnone\n1000\n✅ Pass\n2026-01-01T16:50:16.242\n\n\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n⋮\n\n\n17\npt_panel_simple\nphasetype\npanel\nnone\n1000\n✅ Pass\n2026-01-01T16:49:53.801\n\n\n18\npt_panel_tvc\nphasetype\npanel\ntvc\n1000\n❌ Fail\n2026-01-01T16:50:57.991\n\n\n19\npt_exact_fixed\npt\nexact\nfixed\n1000\n✅ Pass\n2026-01-01T16:49:44.907\n\n\n20\npt_exact_nocov\npt\nexact\nnocov\n1000\n✅ Pass\n2026-01-01T16:49:39.984\n\n\n21\npt_exact_tvc\npt\nexact\ntvc\n1000\n✅ Pass\n2026-01-01T16:49:45.453\n\n\n22\nsp_mcem_fixed\nsp\npanel\nfixed\n1000\n❌ Fail\n2026-01-01T17:08:41.835\n\n\n23\nwei_exact_fixed\nwei\nexact\nfixed\n1000\n✅ Pass\n2026-01-01T16:31:38.432\n\n\n24\nwei_exact_nocov\nwei\nexact\nnocov\n1000\n✅ Pass\n2026-01-01T16:31:17.325\n\n\n25\nwei_exact_tvc\nwei\nexact\ntvc\n1000\n✅ Pass\n2026-01-01T16:31:58.169\n\n\n26\nwei_mcem_fixed\nwei\nmcem\nfixed\n989\n✅ Pass\n2026-01-01T16:35:28.655\n\n\n27\nwei_mcem_nocov\nwei\nmcem\nnocov\n991\n✅ Pass\n2026-01-01T16:34:12.161\n\n\n28\nwei_mcem_tvc\nwei\nmcem\ntvc\n995\n❌ Fail\n2026-01-01T16:36:30.196"
  },
  {
    "objectID": "03_long_tests.html#parametric-models",
    "href": "03_long_tests.html#parametric-models",
    "title": "Long Tests Status",
    "section": "2. Parametric Models",
    "text": "2. Parametric Models\n\n2.1 Exponential Hazard\n\n\n\n\n#### exp_exact_nocov\n- **Status**: ✅ Pass\n- **N subjects**: 1000\n\n| Parameter | True | Estimated |\n|-----------|------|-----------|\n| h12_log_rate | -1.8971 | -1.8465 |\n| h23_log_rate | -2.1203 | -2.0904 |\n\n#### exp_exact_fixed\n- **Status**: ✅ Pass\n- **N subjects**: 1000\n\n| Parameter | True | Estimated |\n|-----------|------|-----------|\n| h12_beta | 0.5 | 0.5267 |\n| h23_beta | 0.5 | 0.4791 |\n| h12_log_rate | -1.8971 | -1.8898 |\n| h23_log_rate | -2.1203 | -2.067 |\n\n#### exp_exact_tvc\n- **Status**: ✅ Pass\n- **N subjects**: 1000\n\n| Parameter | True | Estimated |\n|-----------|------|-----------|\n| h12_beta | 0.5 | 0.4118 |\n| h23_beta | 0.5 | 0.3392 |\n| h12_log_rate | -1.8971 | -1.8465 |\n| h23_log_rate | -2.1203 | -1.9534 |\n\n\n\n\nFigure 1\n\n\n\n\n\n2.2 Weibull Hazard\n\n\n#### wei_exact_nocov\n- **Status**: ✅ Pass\n- **N subjects**: 1000\n\n#### wei_exact_fixed\n- **Status**: ✅ Pass\n- **N subjects**: 1000\n\n#### wei_exact_tvc\n- **Status**: ✅ Pass\n- **N subjects**: 1000\n\n#### wei_mcem_nocov\n- **Status**: ✅ Pass\n- **N subjects**: 991\n\n#### wei_mcem_fixed\n- **Status**: ✅ Pass\n- **N subjects**: 989\n\n#### wei_mcem_tvc\n- **Status**: ❌ Fail\n- **N subjects**: 995\n\n\n\n\n\n2.3 Gompertz Hazard\n\n\n#### gom_exact_nocov\n- **Status**: ✅ Pass\n- **N subjects**: 1000\n\n#### gom_exact_fixed\n- **Status**: ✅ Pass\n- **N subjects**: 1000\n\n#### gom_exact_tvc\n- **Status**: ✅ Pass\n- **N subjects**: 1000\n\n#### gom_mcem_nocov\n- **Status**: ✅ Pass\n- **N subjects**: 992\n\n#### gom_mcem_fixed\n- **Status**: ✅ Pass\n- **N subjects**: 984\n\n#### gom_mcem_tvc\n- **Status**: ❌ Fail\n- **N subjects**: 993"
  },
  {
    "objectID": "03_long_tests.html#panel-data-exponential-markov",
    "href": "03_long_tests.html#panel-data-exponential-markov",
    "title": "Long Tests Status",
    "section": "3. Panel Data (Exponential / Markov)",
    "text": "3. Panel Data (Exponential / Markov)\n\n\n#### exp_panel_nocov\n- **Status**: ✅ Pass\n- **N subjects**: 990\n\n#### exp_panel_fixed\n- **Status**: ✅ Pass\n- **N subjects**: 986\n\n#### exp_panel_tvc\n- **Status**: ✅ Pass\n- **N subjects**: 990"
  },
  {
    "objectID": "03_long_tests.html#notes",
    "href": "03_long_tests.html#notes",
    "title": "Long Tests Status",
    "section": "4. Notes",
    "text": "4. Notes\n\nTests use a 3-state progressive model: State 1 → State 2 → State 3\nParameter recovery tolerance: 35% relative error for main parameters\nTVC (time-varying covariate) tests verify covariate effects change at t=5\nExact data uses obstype=1 (continuous observation)\nPanel data uses discrete observation times with MCEM for semi-Markov families"
  },
  {
    "objectID": "05_benchmarks.html",
    "href": "05_benchmarks.html",
    "title": "Benchmarks",
    "section": "",
    "text": "NoteStatus: Not Started\n\n\n\nThis report is a placeholder. Content will be added as the benchmark infrastructure is developed."
  },
  {
    "objectID": "05_benchmarks.html#sampling-methods-comparison",
    "href": "05_benchmarks.html#sampling-methods-comparison",
    "title": "Benchmarks",
    "section": "1. Sampling Methods Comparison",
    "text": "1. Sampling Methods Comparison\n\nOverview\nThis section compares the performance of different sampling methods used in the MCEM algorithm:\n\nSIR: Sampling Importance Resampling\nLHS: Latin Hypercube Sampling\nIS: Importance Sampling\n\n\n\nBenchmark Setup\n\n\nShow code\n# TODO: Add benchmark setup code\nusing BenchmarkTools\n\n# Model configuration\n# ...\n\n\n\n\nResults\n\n\n\nMethod\nESS\nRuntime (s)\nESS/second\n\n\n\n\nSIR\n-\n-\n-\n\n\nLHS\n-\n-\n-\n\n\nIS\n-\n-\n-\n\n\n\n\n\nEffective Sample Size Comparison\nPlot to be generated: ESS vs computation time for each method"
  },
  {
    "objectID": "05_benchmarks.html#mcem-acceleration",
    "href": "05_benchmarks.html#mcem-acceleration",
    "title": "Benchmarks",
    "section": "2. MCEM Acceleration",
    "text": "2. MCEM Acceleration\n\nOverview\nThis section compares standard EM with SQUAREM acceleration.\n\n\nBenchmark Setup\n\n\nShow code\n# TODO: Add SQUAREM benchmark code\n\n\n\n\nConvergence Comparison\n\n\n\nMethod\nIterations to Convergence\nTotal Runtime (s)\n\n\n\n\nStandard EM\n-\n-\n\n\nSQUAREM\n-\n-\n\n\n\n\n\nConvergence Plots\nPlots to be generated: Log-likelihood vs iteration for each method"
  },
  {
    "objectID": "05_benchmarks.html#scalability",
    "href": "05_benchmarks.html#scalability",
    "title": "Benchmarks",
    "section": "3. Scalability",
    "text": "3. Scalability\n\n3.1 Runtime vs Number of Subjects\nPlot to be generated\n\n\n3.2 Runtime vs Number of States\nPlot to be generated\n\n\n3.3 Runtime vs Number of Transitions\nPlot to be generated"
  },
  {
    "objectID": "05_benchmarks.html#memory-usage",
    "href": "05_benchmarks.html#memory-usage",
    "title": "Benchmarks",
    "section": "4. Memory Usage",
    "text": "4. Memory Usage\n\nPeak Memory by Problem Size\n\n\n\nSubjects\nStates\nTransitions\nPeak Memory (GB)\n\n\n\n\n100\n3\n2\n-\n\n\n500\n3\n2\n-\n\n\n1000\n3\n2\n-\n\n\n1000\n5\n6\n-\n\n\n\nAdditional memory profiling to be added"
  },
  {
    "objectID": "04_simulation_diagnostics.html",
    "href": "04_simulation_diagnostics.html",
    "title": "Simulation Diagnostics",
    "section": "",
    "text": "This report validates that the MultistateModels.jl simulation engine produces event times that match the theoretical distributions defined by the hazard functions.\n\n\nFor each scenario, we:\n\nDefine a hazard model with known parameters\nSimulate many event times using simulate_path()\nCompare the empirical CDF (ECDF) to the theoretical CDF\nVerify time-transform parity - ensure that both the cached time-transform strategy and the direct fallback produce identical results\n\n\n\n\n\nECDF vs CDF: Visual comparison of simulated vs theoretical distributions\nKS statistic: Kolmogorov-Smirnov statistic \\(D_n = \\sup_t |F_n(t) - F(t)|\\), which should decrease as \\(\\sim 1/\\sqrt{n}\\)\nTime-transform parity: \\(\\Delta F(t) = F_{tt}(t) - F_{fb}(t)\\) should be zero\n\n\n\nConfiguration constants\nconst COVARIATE_VALUE = 1.5\nconst DELTA_U = sqrt(eps())\nconst DELTA_T = sqrt(eps())\nconst SIM_SAMPLES = 40_000\nconst DIST_GRID_POINTS = 400\n\nconst FAMILY_CONFIG = Dict(\n    \"exp\" =&gt; (; rate = 0.35, beta = 0.6, horizon = 5.0, hazard_start = 0.0),\n    \"wei\" =&gt; (; shape = 1.35, scale = 0.4, beta = -0.35, horizon = 5.0, hazard_start = 0.02),\n    \"gom\" =&gt; (; shape = 0.6, rate = 0.4, beta = 0.5, horizon = 5.0, hazard_start = 0.0),\n)\n\nconst TVC_CONFIG = Dict(\n    \"exp\" =&gt; (; rate = 0.35, beta = 0.6, horizon = 5.0, hazard_start = 0.0, \n               t_changes = [1.5, 3.0], x_values = [0.5, 1.5, 2.5]),\n    \"wei\" =&gt; (; rate = 0.0, shape = 1.35, scale = 0.4, beta = -0.35, horizon = 5.0, \n               hazard_start = 0.02, t_changes = [1.5, 3.0], x_values = [0.5, 1.5, 2.5]),\n    \"gom\" =&gt; (; rate = 0.4, shape = 0.6, beta = 0.5, horizon = 5.0, hazard_start = 0.0, \n               t_changes = [1.5, 3.0], x_values = [0.5, 1.5, 2.5]),\n)\n\n\nDict{String, NamedTuple} with 3 entries:\n  \"exp\" =&gt; (rate = 0.35, beta = 0.6, horizon = 5.0, hazard_start = 0.0, t_chang…\n  \"wei\" =&gt; (rate = 0.0, shape = 1.35, scale = 0.4, beta = -0.35, horizon = 5.0,…\n  \"gom\" =&gt; (rate = 0.4, shape = 0.6, beta = 0.5, horizon = 5.0, hazard_start = …\n\n\n\n\nHelper functions for scenario setup\nstruct Scenario\n    family::String\n    effect::Symbol\n    covariate_mode::Symbol\n    label::String\n    slug::String\n    config::NamedTuple\nend\n\nfunction Scenario(family::String, effect::Symbol, cov_mode::Symbol)\n    if cov_mode == :tvc\n        config = TVC_CONFIG[family]\n        label = string(uppercasefirst(lowercase(family)), \" \", uppercase(String(effect)), \n                      \" time-varying covariate\")\n    else\n        config = FAMILY_CONFIG[family]\n        label = string(uppercasefirst(lowercase(family)), \" \", uppercase(String(effect)), \n                      \" \", cov_mode == :covariate ? \"with covariate\" : \"baseline-only\")\n    end\n    slug = string(family, \"_\", effect, \"_\", cov_mode)\n    return Scenario(family, effect, cov_mode, label, slug, config)\nend\n\nfunction scenario_subject_df(scenario::Scenario)\n    horizon = scenario.config.horizon\n    if scenario.covariate_mode == :tvc\n        t_changes = scenario.config.t_changes\n        x_values = scenario.config.x_values\n        tstart_grid = vcat(0.0, t_changes)\n        tstop_grid = vcat(t_changes, horizon)\n        n_intervals = length(tstart_grid)\n        df = DataFrame(\n            id = fill(1, n_intervals),\n            tstart = tstart_grid,\n            tstop = tstop_grid,\n            statefrom = fill(1, n_intervals),\n            stateto = fill(2, n_intervals),\n            obstype = fill(1, n_intervals),\n            x = x_values,\n        )\n    else\n        df = DataFrame(\n            id = [1], tstart = [0.0], tstop = [horizon],\n            statefrom = [1], stateto = [2], obstype = [1],\n        )\n        if scenario.covariate_mode == :covariate\n            df.x = [COVARIATE_VALUE]\n        end\n    end\n    return df\nend\n\nfunction hazard_formula(scenario::Scenario)\n    (scenario.covariate_mode == :covariate || scenario.covariate_mode == :tvc) ? \n        @formula(0 ~ x) : @formula(0 ~ 1)\nend\n\nfunction scenario_parameter_vector(scenario::Scenario)\n    cfg = scenario.config\n    if scenario.family == \"exp\"\n        base = [log(cfg.rate)]\n    elseif scenario.family == \"wei\"\n        base = [log(cfg.shape), log(cfg.scale)]\n    elseif scenario.family == \"gom\"\n        base = [cfg.shape, log(cfg.rate)]\n    else\n        error(\"Unsupported family $(scenario.family)\")\n    end\n    return (scenario.covariate_mode == :covariate || scenario.covariate_mode == :tvc) ? \n        vcat(base, [cfg.beta]) : base\nend\n\nfunction build_model(scenario::Scenario)\n    data = scenario_subject_df(scenario)\n    hazard = Hazard(\n        hazard_formula(scenario),\n        scenario.family, 1, 2;\n        linpred_effect = scenario.effect,\n        time_transform = true,\n    )\n    model = multistatemodel(hazard; data = data)\n    pars = scenario_parameter_vector(scenario)\n    hazname = model.hazards[1].hazname\n    set_parameters!(model, NamedTuple{(hazname,)}((pars,)))\n    return model, data\nend\n\ncovariate_value(scenario::Scenario) = scenario.covariate_mode == :covariate ? COVARIATE_VALUE : 0.0\n\n\ncovariate_value (generic function with 1 method)\n\n\n\n\nTheoretical distribution functions\n# Piecewise cumulative hazard helpers for TVC\nfunction piecewise_exp_ph_cumhaz(t, rate, beta, t_changes, x_values)\n    cumhaz = 0.0\n    prev_t = 0.0\n    for (i, tc) in enumerate(t_changes)\n        if t &lt;= tc\n            cumhaz += rate * exp(beta * x_values[i]) * (t - prev_t)\n            return cumhaz\n        else\n            cumhaz += rate * exp(beta * x_values[i]) * (tc - prev_t)\n            prev_t = tc\n        end\n    end\n    cumhaz += rate * exp(beta * x_values[end]) * (t - prev_t)\n    return cumhaz\nend\n\nfunction piecewise_wei_ph_cumhaz(t, shape, scale, beta, t_changes, x_values)\n    cumhaz = 0.0\n    prev_t = 0.0\n    for (i, tc) in enumerate(t_changes)\n        if t &lt;= tc\n            cumhaz += scale * exp(beta * x_values[i]) * (t^shape - prev_t^shape)\n            return cumhaz\n        else\n            cumhaz += scale * exp(beta * x_values[i]) * (tc^shape - prev_t^shape)\n            prev_t = tc\n        end\n    end\n    cumhaz += scale * exp(beta * x_values[end]) * (t^shape - prev_t^shape)\n    return cumhaz\nend\n\nfunction distribution_functions(scenario::Scenario)\n    cfg = scenario.config\n    \n    if scenario.covariate_mode == :tvc\n        t_changes = cfg.t_changes\n        x_values = cfg.x_values\n        beta = cfg.beta\n        \n        if scenario.family == \"exp\"\n            rate = cfg.rate\n            cumhaz = t -&gt; piecewise_exp_ph_cumhaz(t, rate, beta, t_changes, x_values)\n            hazard = t -&gt; begin\n                for (i, tc) in enumerate(t_changes)\n                    if t &lt; tc\n                        return rate * exp(beta * x_values[i])\n                    end\n                end\n                return rate * exp(beta * x_values[end])\n            end\n        elseif scenario.family == \"wei\"\n            shape = cfg.shape\n            scale = cfg.scale\n            cumhaz = t -&gt; piecewise_wei_ph_cumhaz(t, shape, scale, beta, t_changes, x_values)\n            hazard = t -&gt; begin\n                for (i, tc) in enumerate(t_changes)\n                    if t &lt; tc\n                        return shape * scale * exp(beta * x_values[i]) * (t^(shape - 1))\n                    end\n                end\n                return shape * scale * exp(beta * x_values[end]) * (t^(shape - 1))\n            end\n        else\n            error(\"TVC not implemented for family $(scenario.family)\")\n        end\n    else\n        xval = covariate_value(scenario)\n        beta = scenario.covariate_mode == :covariate ? cfg.beta : 0.0\n        \n        if scenario.family == \"exp\"\n            base_rate = cfg.rate\n            rate = scenario.effect == :ph ? base_rate * exp(beta * xval) : base_rate * exp(-beta * xval)\n            cumhaz = t -&gt; rate * t\n            hazard = _ -&gt; rate\n        elseif scenario.family == \"wei\"\n            shape = cfg.shape\n            scale = cfg.scale\n            multiplier = scenario.effect == :ph ? exp(beta * xval) : exp(-shape * beta * xval)\n            cumhaz = t -&gt; scale * multiplier * (t^shape)\n            hazard = t -&gt; shape * scale * multiplier * (t^(shape - 1))\n        elseif scenario.family == \"gom\"\n            shape = cfg.shape\n            rate = cfg.rate\n            linpred = beta * xval\n            if scenario.effect == :ph\n                cumhaz = t -&gt; (rate / shape) * exp(linpred) * (exp(shape * t) - 1)\n                hazard = t -&gt; rate * exp(shape * t + linpred)\n            else\n                time_scale = exp(-linpred)\n                scaled_shape = shape * time_scale\n                scaled_rate = rate * time_scale\n                cumhaz = t -&gt; (scaled_rate / scaled_shape) * (exp(scaled_shape * t) - 1)\n                hazard = t -&gt; scaled_rate * exp(scaled_shape * t)\n            end\n        else\n            error(\"Unsupported family $(scenario.family)\")\n        end\n    end\n    cdf = t -&gt; t &lt;= 0 ? 0.0 : 1 - exp(-cumhaz(t))\n    pdf = t -&gt; t &lt;= 0 ? 0.0 : hazard(t) * exp(-cumhaz(t))\n    return cdf, pdf\nend\n\n\ndistribution_functions (generic function with 1 method)\n\n\n\n\nSimulation and plotting functions\nfunction collect_event_durations(model, nsamples; use_cached_strategy::Bool, rng::AbstractRNG)\n    durations = Vector{Float64}(undef, nsamples)\n    collected = 0\n    attempts = 0\n    max_attempts = nsamples * 200\n    strategy = use_cached_strategy ? CachedTransformStrategy() : DirectTransformStrategy()\n    while collected &lt; nsamples\n        path = simulate_path(model, 1; strategy = strategy, rng = rng)\n        attempts += 1\n        attempts &gt; max_attempts && error(\"Exceeded maximum attempts\")\n        if path.states[end] != path.states[1]\n            collected += 1\n            durations[collected] = path.times[end] - path.times[1]\n        end\n    end\n    return durations\nend\n\nfunction run_scenario_diagnostics(scenario::Scenario)\n    model, data = build_model(scenario)\n    \n    seed = hash(scenario.slug)\n    rng_tt = Random.MersenneTwister(seed)\n    rng_fb = Random.MersenneTwister(seed)\n    \n    durations_tt = collect_event_durations(model, SIM_SAMPLES; use_cached_strategy=true, rng=rng_tt)\n    durations_fb = collect_event_durations(model, SIM_SAMPLES; use_cached_strategy=false, rng=rng_fb)\n    \n    ecdf_tt = ecdf(durations_tt)\n    ecdf_fb = ecdf(durations_fb)\n    horizon = scenario.config.horizon\n    ts = collect(range(0.0, horizon; length = DIST_GRID_POINTS))\n    \n    cdf_base, pdf_base = distribution_functions(scenario)\n    cdf_fn, pdf_fn = truncate_distribution(cdf_base, pdf_base; lower = 0.0, upper = horizon)\n    \n    expected = cdf_fn.(ts)\n    empirical = ecdf_fb.(ts)\n    diff_curve = ecdf_tt.(ts) .- ecdf_fb.(ts)\n    max_abs_diff = maximum(abs.(diff_curve))\n    \n    # KS statistic at different sample sizes\n    sorted_durations = sort(durations_fb)\n    n_samples = length(sorted_durations)\n    expected_cdf_at_samples = cdf_fn.(sorted_durations)\n    eval_ns = filter(n -&gt; n &lt;= n_samples, [100, 200, 500, 1000, 2000, 5000, 10000, 20000, n_samples])\n    ks_at_n = zeros(length(eval_ns))\n    \n    for (idx, n) in enumerate(eval_ns)\n        max_diff = 0.0\n        for i in 1:n\n            cdf_i = expected_cdf_at_samples[i]\n            diff_upper = abs(i / n - cdf_i)\n            diff_lower = abs((i - 1) / n - cdf_i)\n            max_diff = max(max_diff, diff_upper, diff_lower)\n        end\n        ks_at_n[idx] = max_diff\n    end\n    \n    # Create figure\n    fig = Figure(size = (1400, 500))\n    \n    ax1 = Axis(fig[1, 1], title = \"ECDF vs Expected CDF\", xlabel = \"Duration\", ylabel = \"F(t)\")\n    lines!(ax1, ts, expected, color = :black, linewidth = 3, label = \"Theoretical\")\n    lines!(ax1, ts, empirical, color = :dodgerblue, linewidth = 2, label = \"Simulated\")\n    axislegend(ax1, position = :rb)\n    \n    ax2 = Axis(fig[1, 2], title = \"KS Statistic vs Sample Size\", \n               xlabel = \"n\", ylabel = \"Dₙ\", xscale = log10)\n    scatterlines!(ax2, eval_ns, ks_at_n, color = :crimson, linewidth = 2, markersize = 8)\n    \n    ylim_span = max(max_abs_diff, 1e-6)\n    ax3 = Axis(fig[1, 3], title = \"Time-Transform Parity: max|ΔF| = $(round(max_abs_diff; digits=4))\", \n               xlabel = \"Duration\", ylabel = \"ΔF(t)\")\n    lines!(ax3, ts, diff_curve, color = :seagreen, linewidth = 2)\n    hlines!(ax3, [0.0], color = :black, linestyle = :dash)\n    ylims!(ax3, (-1.1 * ylim_span, 1.1 * ylim_span))\n    \n    return fig, max_abs_diff\nend\n\n\nrun_scenario_diagnostics (generic function with 1 method)"
  },
  {
    "objectID": "04_simulation_diagnostics.html#methodology",
    "href": "04_simulation_diagnostics.html#methodology",
    "title": "Simulation Diagnostics",
    "section": "",
    "text": "This report validates that the MultistateModels.jl simulation engine produces event times that match the theoretical distributions defined by the hazard functions.\n\n\nFor each scenario, we:\n\nDefine a hazard model with known parameters\nSimulate many event times using simulate_path()\nCompare the empirical CDF (ECDF) to the theoretical CDF\nVerify time-transform parity - ensure that both the cached time-transform strategy and the direct fallback produce identical results\n\n\n\n\n\nECDF vs CDF: Visual comparison of simulated vs theoretical distributions\nKS statistic: Kolmogorov-Smirnov statistic \\(D_n = \\sup_t |F_n(t) - F(t)|\\), which should decrease as \\(\\sim 1/\\sqrt{n}\\)\nTime-transform parity: \\(\\Delta F(t) = F_{tt}(t) - F_{fb}(t)\\) should be zero\n\n\n\nConfiguration constants\nconst COVARIATE_VALUE = 1.5\nconst DELTA_U = sqrt(eps())\nconst DELTA_T = sqrt(eps())\nconst SIM_SAMPLES = 40_000\nconst DIST_GRID_POINTS = 400\n\nconst FAMILY_CONFIG = Dict(\n    \"exp\" =&gt; (; rate = 0.35, beta = 0.6, horizon = 5.0, hazard_start = 0.0),\n    \"wei\" =&gt; (; shape = 1.35, scale = 0.4, beta = -0.35, horizon = 5.0, hazard_start = 0.02),\n    \"gom\" =&gt; (; shape = 0.6, rate = 0.4, beta = 0.5, horizon = 5.0, hazard_start = 0.0),\n)\n\nconst TVC_CONFIG = Dict(\n    \"exp\" =&gt; (; rate = 0.35, beta = 0.6, horizon = 5.0, hazard_start = 0.0, \n               t_changes = [1.5, 3.0], x_values = [0.5, 1.5, 2.5]),\n    \"wei\" =&gt; (; rate = 0.0, shape = 1.35, scale = 0.4, beta = -0.35, horizon = 5.0, \n               hazard_start = 0.02, t_changes = [1.5, 3.0], x_values = [0.5, 1.5, 2.5]),\n    \"gom\" =&gt; (; rate = 0.4, shape = 0.6, beta = 0.5, horizon = 5.0, hazard_start = 0.0, \n               t_changes = [1.5, 3.0], x_values = [0.5, 1.5, 2.5]),\n)\n\n\nDict{String, NamedTuple} with 3 entries:\n  \"exp\" =&gt; (rate = 0.35, beta = 0.6, horizon = 5.0, hazard_start = 0.0, t_chang…\n  \"wei\" =&gt; (rate = 0.0, shape = 1.35, scale = 0.4, beta = -0.35, horizon = 5.0,…\n  \"gom\" =&gt; (rate = 0.4, shape = 0.6, beta = 0.5, horizon = 5.0, hazard_start = …\n\n\n\n\nHelper functions for scenario setup\nstruct Scenario\n    family::String\n    effect::Symbol\n    covariate_mode::Symbol\n    label::String\n    slug::String\n    config::NamedTuple\nend\n\nfunction Scenario(family::String, effect::Symbol, cov_mode::Symbol)\n    if cov_mode == :tvc\n        config = TVC_CONFIG[family]\n        label = string(uppercasefirst(lowercase(family)), \" \", uppercase(String(effect)), \n                      \" time-varying covariate\")\n    else\n        config = FAMILY_CONFIG[family]\n        label = string(uppercasefirst(lowercase(family)), \" \", uppercase(String(effect)), \n                      \" \", cov_mode == :covariate ? \"with covariate\" : \"baseline-only\")\n    end\n    slug = string(family, \"_\", effect, \"_\", cov_mode)\n    return Scenario(family, effect, cov_mode, label, slug, config)\nend\n\nfunction scenario_subject_df(scenario::Scenario)\n    horizon = scenario.config.horizon\n    if scenario.covariate_mode == :tvc\n        t_changes = scenario.config.t_changes\n        x_values = scenario.config.x_values\n        tstart_grid = vcat(0.0, t_changes)\n        tstop_grid = vcat(t_changes, horizon)\n        n_intervals = length(tstart_grid)\n        df = DataFrame(\n            id = fill(1, n_intervals),\n            tstart = tstart_grid,\n            tstop = tstop_grid,\n            statefrom = fill(1, n_intervals),\n            stateto = fill(2, n_intervals),\n            obstype = fill(1, n_intervals),\n            x = x_values,\n        )\n    else\n        df = DataFrame(\n            id = [1], tstart = [0.0], tstop = [horizon],\n            statefrom = [1], stateto = [2], obstype = [1],\n        )\n        if scenario.covariate_mode == :covariate\n            df.x = [COVARIATE_VALUE]\n        end\n    end\n    return df\nend\n\nfunction hazard_formula(scenario::Scenario)\n    (scenario.covariate_mode == :covariate || scenario.covariate_mode == :tvc) ? \n        @formula(0 ~ x) : @formula(0 ~ 1)\nend\n\nfunction scenario_parameter_vector(scenario::Scenario)\n    cfg = scenario.config\n    if scenario.family == \"exp\"\n        base = [log(cfg.rate)]\n    elseif scenario.family == \"wei\"\n        base = [log(cfg.shape), log(cfg.scale)]\n    elseif scenario.family == \"gom\"\n        base = [cfg.shape, log(cfg.rate)]\n    else\n        error(\"Unsupported family $(scenario.family)\")\n    end\n    return (scenario.covariate_mode == :covariate || scenario.covariate_mode == :tvc) ? \n        vcat(base, [cfg.beta]) : base\nend\n\nfunction build_model(scenario::Scenario)\n    data = scenario_subject_df(scenario)\n    hazard = Hazard(\n        hazard_formula(scenario),\n        scenario.family, 1, 2;\n        linpred_effect = scenario.effect,\n        time_transform = true,\n    )\n    model = multistatemodel(hazard; data = data)\n    pars = scenario_parameter_vector(scenario)\n    hazname = model.hazards[1].hazname\n    set_parameters!(model, NamedTuple{(hazname,)}((pars,)))\n    return model, data\nend\n\ncovariate_value(scenario::Scenario) = scenario.covariate_mode == :covariate ? COVARIATE_VALUE : 0.0\n\n\ncovariate_value (generic function with 1 method)\n\n\n\n\nTheoretical distribution functions\n# Piecewise cumulative hazard helpers for TVC\nfunction piecewise_exp_ph_cumhaz(t, rate, beta, t_changes, x_values)\n    cumhaz = 0.0\n    prev_t = 0.0\n    for (i, tc) in enumerate(t_changes)\n        if t &lt;= tc\n            cumhaz += rate * exp(beta * x_values[i]) * (t - prev_t)\n            return cumhaz\n        else\n            cumhaz += rate * exp(beta * x_values[i]) * (tc - prev_t)\n            prev_t = tc\n        end\n    end\n    cumhaz += rate * exp(beta * x_values[end]) * (t - prev_t)\n    return cumhaz\nend\n\nfunction piecewise_wei_ph_cumhaz(t, shape, scale, beta, t_changes, x_values)\n    cumhaz = 0.0\n    prev_t = 0.0\n    for (i, tc) in enumerate(t_changes)\n        if t &lt;= tc\n            cumhaz += scale * exp(beta * x_values[i]) * (t^shape - prev_t^shape)\n            return cumhaz\n        else\n            cumhaz += scale * exp(beta * x_values[i]) * (tc^shape - prev_t^shape)\n            prev_t = tc\n        end\n    end\n    cumhaz += scale * exp(beta * x_values[end]) * (t^shape - prev_t^shape)\n    return cumhaz\nend\n\nfunction distribution_functions(scenario::Scenario)\n    cfg = scenario.config\n    \n    if scenario.covariate_mode == :tvc\n        t_changes = cfg.t_changes\n        x_values = cfg.x_values\n        beta = cfg.beta\n        \n        if scenario.family == \"exp\"\n            rate = cfg.rate\n            cumhaz = t -&gt; piecewise_exp_ph_cumhaz(t, rate, beta, t_changes, x_values)\n            hazard = t -&gt; begin\n                for (i, tc) in enumerate(t_changes)\n                    if t &lt; tc\n                        return rate * exp(beta * x_values[i])\n                    end\n                end\n                return rate * exp(beta * x_values[end])\n            end\n        elseif scenario.family == \"wei\"\n            shape = cfg.shape\n            scale = cfg.scale\n            cumhaz = t -&gt; piecewise_wei_ph_cumhaz(t, shape, scale, beta, t_changes, x_values)\n            hazard = t -&gt; begin\n                for (i, tc) in enumerate(t_changes)\n                    if t &lt; tc\n                        return shape * scale * exp(beta * x_values[i]) * (t^(shape - 1))\n                    end\n                end\n                return shape * scale * exp(beta * x_values[end]) * (t^(shape - 1))\n            end\n        else\n            error(\"TVC not implemented for family $(scenario.family)\")\n        end\n    else\n        xval = covariate_value(scenario)\n        beta = scenario.covariate_mode == :covariate ? cfg.beta : 0.0\n        \n        if scenario.family == \"exp\"\n            base_rate = cfg.rate\n            rate = scenario.effect == :ph ? base_rate * exp(beta * xval) : base_rate * exp(-beta * xval)\n            cumhaz = t -&gt; rate * t\n            hazard = _ -&gt; rate\n        elseif scenario.family == \"wei\"\n            shape = cfg.shape\n            scale = cfg.scale\n            multiplier = scenario.effect == :ph ? exp(beta * xval) : exp(-shape * beta * xval)\n            cumhaz = t -&gt; scale * multiplier * (t^shape)\n            hazard = t -&gt; shape * scale * multiplier * (t^(shape - 1))\n        elseif scenario.family == \"gom\"\n            shape = cfg.shape\n            rate = cfg.rate\n            linpred = beta * xval\n            if scenario.effect == :ph\n                cumhaz = t -&gt; (rate / shape) * exp(linpred) * (exp(shape * t) - 1)\n                hazard = t -&gt; rate * exp(shape * t + linpred)\n            else\n                time_scale = exp(-linpred)\n                scaled_shape = shape * time_scale\n                scaled_rate = rate * time_scale\n                cumhaz = t -&gt; (scaled_rate / scaled_shape) * (exp(scaled_shape * t) - 1)\n                hazard = t -&gt; scaled_rate * exp(scaled_shape * t)\n            end\n        else\n            error(\"Unsupported family $(scenario.family)\")\n        end\n    end\n    cdf = t -&gt; t &lt;= 0 ? 0.0 : 1 - exp(-cumhaz(t))\n    pdf = t -&gt; t &lt;= 0 ? 0.0 : hazard(t) * exp(-cumhaz(t))\n    return cdf, pdf\nend\n\n\ndistribution_functions (generic function with 1 method)\n\n\n\n\nSimulation and plotting functions\nfunction collect_event_durations(model, nsamples; use_cached_strategy::Bool, rng::AbstractRNG)\n    durations = Vector{Float64}(undef, nsamples)\n    collected = 0\n    attempts = 0\n    max_attempts = nsamples * 200\n    strategy = use_cached_strategy ? CachedTransformStrategy() : DirectTransformStrategy()\n    while collected &lt; nsamples\n        path = simulate_path(model, 1; strategy = strategy, rng = rng)\n        attempts += 1\n        attempts &gt; max_attempts && error(\"Exceeded maximum attempts\")\n        if path.states[end] != path.states[1]\n            collected += 1\n            durations[collected] = path.times[end] - path.times[1]\n        end\n    end\n    return durations\nend\n\nfunction run_scenario_diagnostics(scenario::Scenario)\n    model, data = build_model(scenario)\n    \n    seed = hash(scenario.slug)\n    rng_tt = Random.MersenneTwister(seed)\n    rng_fb = Random.MersenneTwister(seed)\n    \n    durations_tt = collect_event_durations(model, SIM_SAMPLES; use_cached_strategy=true, rng=rng_tt)\n    durations_fb = collect_event_durations(model, SIM_SAMPLES; use_cached_strategy=false, rng=rng_fb)\n    \n    ecdf_tt = ecdf(durations_tt)\n    ecdf_fb = ecdf(durations_fb)\n    horizon = scenario.config.horizon\n    ts = collect(range(0.0, horizon; length = DIST_GRID_POINTS))\n    \n    cdf_base, pdf_base = distribution_functions(scenario)\n    cdf_fn, pdf_fn = truncate_distribution(cdf_base, pdf_base; lower = 0.0, upper = horizon)\n    \n    expected = cdf_fn.(ts)\n    empirical = ecdf_fb.(ts)\n    diff_curve = ecdf_tt.(ts) .- ecdf_fb.(ts)\n    max_abs_diff = maximum(abs.(diff_curve))\n    \n    # KS statistic at different sample sizes\n    sorted_durations = sort(durations_fb)\n    n_samples = length(sorted_durations)\n    expected_cdf_at_samples = cdf_fn.(sorted_durations)\n    eval_ns = filter(n -&gt; n &lt;= n_samples, [100, 200, 500, 1000, 2000, 5000, 10000, 20000, n_samples])\n    ks_at_n = zeros(length(eval_ns))\n    \n    for (idx, n) in enumerate(eval_ns)\n        max_diff = 0.0\n        for i in 1:n\n            cdf_i = expected_cdf_at_samples[i]\n            diff_upper = abs(i / n - cdf_i)\n            diff_lower = abs((i - 1) / n - cdf_i)\n            max_diff = max(max_diff, diff_upper, diff_lower)\n        end\n        ks_at_n[idx] = max_diff\n    end\n    \n    # Create figure\n    fig = Figure(size = (1400, 500))\n    \n    ax1 = Axis(fig[1, 1], title = \"ECDF vs Expected CDF\", xlabel = \"Duration\", ylabel = \"F(t)\")\n    lines!(ax1, ts, expected, color = :black, linewidth = 3, label = \"Theoretical\")\n    lines!(ax1, ts, empirical, color = :dodgerblue, linewidth = 2, label = \"Simulated\")\n    axislegend(ax1, position = :rb)\n    \n    ax2 = Axis(fig[1, 2], title = \"KS Statistic vs Sample Size\", \n               xlabel = \"n\", ylabel = \"Dₙ\", xscale = log10)\n    scatterlines!(ax2, eval_ns, ks_at_n, color = :crimson, linewidth = 2, markersize = 8)\n    \n    ylim_span = max(max_abs_diff, 1e-6)\n    ax3 = Axis(fig[1, 3], title = \"Time-Transform Parity: max|ΔF| = $(round(max_abs_diff; digits=4))\", \n               xlabel = \"Duration\", ylabel = \"ΔF(t)\")\n    lines!(ax3, ts, diff_curve, color = :seagreen, linewidth = 2)\n    hlines!(ax3, [0.0], color = :black, linestyle = :dash)\n    ylims!(ax3, (-1.1 * ylim_span, 1.1 * ylim_span))\n    \n    return fig, max_abs_diff\nend\n\n\nrun_scenario_diagnostics (generic function with 1 method)"
  },
  {
    "objectID": "04_simulation_diagnostics.html#parametric-families",
    "href": "04_simulation_diagnostics.html#parametric-families",
    "title": "Simulation Diagnostics",
    "section": "2. Parametric Families",
    "text": "2. Parametric Families\n\n2.1 Exponential\nThe exponential hazard: \\(h(t) = \\text{rate}\\)\nParameterization:\n\n\n\n\n\n\n\n\nEffect\nHazard\nCumulative Hazard\n\n\n\n\nPH\n\\(h(t\\|x) = \\text{rate} \\cdot e^{\\beta x}\\)\n\\(H(t\\|x) = \\text{rate} \\cdot e^{\\beta x} \\cdot t\\)\n\n\nAFT\n\\(h(t\\|x) = \\text{rate} \\cdot e^{-\\beta x}\\)\n\\(H(t\\|x) = \\text{rate} \\cdot e^{-\\beta x} \\cdot t\\)\n\n\n\n\nPH Baseline-Only\n\n\nShow code\nscenario = Scenario(\"exp\", :ph, :baseline)\nfig, max_diff = run_scenario_diagnostics(scenario)\nfig\n\n\n\n┌ Warning: Found `resolution` in the theme when creating a `Scene`. The `resolution` keyword for `Scene`s and `Figure`s has been deprecated. Use `Figure(; size = ...` or `Scene(; size = ...)` instead, which better reflects that this is a unitless size and not a pixel resolution. The key could also come from `set_theme!` calls or related theming functions.\n\n└ @ Makie ~/.julia/packages/Makie/TOy8O/src/scenes.jl:264\n\n\n\n\n\n\n\n\n\nPH with Covariate\n\n\nShow code\nscenario = Scenario(\"exp\", :ph, :covariate)\nfig, max_diff = run_scenario_diagnostics(scenario)\nfig\n\n\n\n┌ Warning: Found `resolution` in the theme when creating a `Scene`. The `resolution` keyword for `Scene`s and `Figure`s has been deprecated. Use `Figure(; size = ...` or `Scene(; size = ...)` instead, which better reflects that this is a unitless size and not a pixel resolution. The key could also come from `set_theme!` calls or related theming functions.\n\n└ @ Makie ~/.julia/packages/Makie/TOy8O/src/scenes.jl:264\n\n\n\n\n\n\n\n\n\nAFT Baseline-Only\n\n\nShow code\nscenario = Scenario(\"exp\", :aft, :baseline)\nfig, max_diff = run_scenario_diagnostics(scenario)\nfig\n\n\n\n┌ Warning: Found `resolution` in the theme when creating a `Scene`. The `resolution` keyword for `Scene`s and `Figure`s has been deprecated. Use `Figure(; size = ...` or `Scene(; size = ...)` instead, which better reflects that this is a unitless size and not a pixel resolution. The key could also come from `set_theme!` calls or related theming functions.\n\n└ @ Makie ~/.julia/packages/Makie/TOy8O/src/scenes.jl:264\n\n\n\n\n\n\n\n\n\nAFT with Covariate\n\n\nShow code\nscenario = Scenario(\"exp\", :aft, :covariate)\nfig, max_diff = run_scenario_diagnostics(scenario)\nfig\n\n\n\n┌ Warning: Found `resolution` in the theme when creating a `Scene`. The `resolution` keyword for `Scene`s and `Figure`s has been deprecated. Use `Figure(; size = ...` or `Scene(; size = ...)` instead, which better reflects that this is a unitless size and not a pixel resolution. The key could also come from `set_theme!` calls or related theming functions.\n\n└ @ Makie ~/.julia/packages/Makie/TOy8O/src/scenes.jl:264\n\n\n\n\n\n\n\n\n\n\n\n2.2 Weibull\nThe Weibull hazard: \\(h(t) = \\text{shape} \\cdot \\text{scale} \\cdot t^{\\text{shape}-1}\\)\nParameterization:\n\n\n\n\n\n\n\n\nEffect\nHazard\nCumulative Hazard\n\n\n\n\nPH\n\\(h(t\\|x) = k \\cdot \\lambda \\cdot t^{k-1} \\cdot e^{\\beta x}\\)\n\\(H(t\\|x) = \\lambda \\cdot e^{\\beta x} \\cdot t^k\\)\n\n\nAFT\n\\(h(t\\|x) = k \\cdot \\lambda \\cdot t^{k-1} \\cdot e^{-k\\beta x}\\)\n\\(H(t\\|x) = \\lambda \\cdot e^{-k\\beta x} \\cdot t^k\\)\n\n\n\n\nPH Baseline-Only\n\n\nShow code\nscenario = Scenario(\"wei\", :ph, :baseline)\nfig, max_diff = run_scenario_diagnostics(scenario)\nfig\n\n\n\n******************************************************************************\nThis program contains Ipopt, a library for large-scale nonlinear optimization.\n Ipopt is released as open source code under the Eclipse Public License (EPL).\n         For more information visit https://github.com/coin-or/Ipopt\n******************************************************************************\n\n\n\n\n┌ Warning: Found `resolution` in the theme when creating a `Scene`. The `resolution` keyword for `Scene`s and `Figure`s has been deprecated. Use `Figure(; size = ...` or `Scene(; size = ...)` instead, which better reflects that this is a unitless size and not a pixel resolution. The key could also come from `set_theme!` calls or related theming functions.\n\n└ @ Makie ~/.julia/packages/Makie/TOy8O/src/scenes.jl:264\n\n\n\n\n\n\n\n\n\nPH with Covariate\n\n\nShow code\nscenario = Scenario(\"wei\", :ph, :covariate)\nfig, max_diff = run_scenario_diagnostics(scenario)\nfig\n\n\n\n┌ Warning: Found `resolution` in the theme when creating a `Scene`. The `resolution` keyword for `Scene`s and `Figure`s has been deprecated. Use `Figure(; size = ...` or `Scene(; size = ...)` instead, which better reflects that this is a unitless size and not a pixel resolution. The key could also come from `set_theme!` calls or related theming functions.\n\n└ @ Makie ~/.julia/packages/Makie/TOy8O/src/scenes.jl:264\n\n\n\n\n\n\n\n\n\nAFT Baseline-Only\n\n\nShow code\nscenario = Scenario(\"wei\", :aft, :baseline)\nfig, max_diff = run_scenario_diagnostics(scenario)\nfig\n\n\n\n┌ Warning: Found `resolution` in the theme when creating a `Scene`. The `resolution` keyword for `Scene`s and `Figure`s has been deprecated. Use `Figure(; size = ...` or `Scene(; size = ...)` instead, which better reflects that this is a unitless size and not a pixel resolution. The key could also come from `set_theme!` calls or related theming functions.\n\n└ @ Makie ~/.julia/packages/Makie/TOy8O/src/scenes.jl:264\n\n\n\n\n\n\n\n\n\nAFT with Covariate\n\n\nShow code\nscenario = Scenario(\"wei\", :aft, :covariate)\nfig, max_diff = run_scenario_diagnostics(scenario)\nfig\n\n\n\n┌ Warning: Found `resolution` in the theme when creating a `Scene`. The `resolution` keyword for `Scene`s and `Figure`s has been deprecated. Use `Figure(; size = ...` or `Scene(; size = ...)` instead, which better reflects that this is a unitless size and not a pixel resolution. The key could also come from `set_theme!` calls or related theming functions.\n\n└ @ Makie ~/.julia/packages/Makie/TOy8O/src/scenes.jl:264\n\n\n\n\n\n\n\n\n\n\n\n2.3 Gompertz\nThe Gompertz hazard (flexsurv parameterization): \\(h(t) = \\text{rate} \\cdot e^{\\text{shape} \\cdot t}\\)\nParameterization:\n\n\n\n\n\n\n\n\nEffect\nHazard\nCumulative Hazard\n\n\n\n\nPH\n\\(h(t\\|x) = r \\cdot e^{at + \\beta x}\\)\n\\(H(t\\|x) = \\frac{r}{a} e^{\\beta x} (e^{at} - 1)\\)\n\n\nAFT\n\\(h(t\\|x) = r' \\cdot e^{a' t}\\) where \\(r' = r e^{-\\beta x}\\), \\(a' = a e^{-\\beta x}\\)\n\\(H(t\\|x) = \\frac{r'}{a'} (e^{a't} - 1)\\)\n\n\n\n\nPH Baseline-Only\n\n\nShow code\nscenario = Scenario(\"gom\", :ph, :baseline)\nfig, max_diff = run_scenario_diagnostics(scenario)\nfig\n\n\n\n┌ Warning: Found `resolution` in the theme when creating a `Scene`. The `resolution` keyword for `Scene`s and `Figure`s has been deprecated. Use `Figure(; size = ...` or `Scene(; size = ...)` instead, which better reflects that this is a unitless size and not a pixel resolution. The key could also come from `set_theme!` calls or related theming functions.\n\n└ @ Makie ~/.julia/packages/Makie/TOy8O/src/scenes.jl:264\n\n\n\n\n\n\n\n\n\nPH with Covariate\n\n\nShow code\nscenario = Scenario(\"gom\", :ph, :covariate)\nfig, max_diff = run_scenario_diagnostics(scenario)\nfig\n\n\n\n┌ Warning: Found `resolution` in the theme when creating a `Scene`. The `resolution` keyword for `Scene`s and `Figure`s has been deprecated. Use `Figure(; size = ...` or `Scene(; size = ...)` instead, which better reflects that this is a unitless size and not a pixel resolution. The key could also come from `set_theme!` calls or related theming functions.\n\n└ @ Makie ~/.julia/packages/Makie/TOy8O/src/scenes.jl:264\n\n\n\n\n\n\n\n\n\nAFT Baseline-Only\n\n\nShow code\nscenario = Scenario(\"gom\", :aft, :baseline)\nfig, max_diff = run_scenario_diagnostics(scenario)\nfig\n\n\n\n┌ Warning: Found `resolution` in the theme when creating a `Scene`. The `resolution` keyword for `Scene`s and `Figure`s has been deprecated. Use `Figure(; size = ...` or `Scene(; size = ...)` instead, which better reflects that this is a unitless size and not a pixel resolution. The key could also come from `set_theme!` calls or related theming functions.\n\n└ @ Makie ~/.julia/packages/Makie/TOy8O/src/scenes.jl:264\n\n\n\n\n\n\n\n\n\nAFT with Covariate\n\n\nShow code\nscenario = Scenario(\"gom\", :aft, :covariate)\nfig, max_diff = run_scenario_diagnostics(scenario)\nfig\n\n\n\n┌ Warning: Found `resolution` in the theme when creating a `Scene`. The `resolution` keyword for `Scene`s and `Figure`s has been deprecated. Use `Figure(; size = ...` or `Scene(; size = ...)` instead, which better reflects that this is a unitless size and not a pixel resolution. The key could also come from `set_theme!` calls or related theming functions.\n\n└ @ Makie ~/.julia/packages/Makie/TOy8O/src/scenes.jl:264"
  },
  {
    "objectID": "04_simulation_diagnostics.html#b-splines",
    "href": "04_simulation_diagnostics.html#b-splines",
    "title": "Simulation Diagnostics",
    "section": "3. B-Splines",
    "text": "3. B-Splines\n\n\n\n\n\n\nWarningStatus: Not Yet Implemented\n\n\n\nB-spline scenarios will be added once the spline infrastructure is integrated into this report.\n\n\n\n3.1 Cubic Splines (4 Interior Knots)\nTo be implemented\n\n\n3.2 Quadratic Splines (3 Interior Knots)\nTo be implemented\n\n\n3.3 Natural Splines\nTo be implemented\n\n\n3.4 Splines with Covariates (PH)\nTo be implemented"
  },
  {
    "objectID": "04_simulation_diagnostics.html#time-varying-covariates",
    "href": "04_simulation_diagnostics.html#time-varying-covariates",
    "title": "Simulation Diagnostics",
    "section": "4. Time-Varying Covariates",
    "text": "4. Time-Varying Covariates\n\n4.1 Exponential PH with Step-Function TVC\n\n\nShow code\nscenario = Scenario(\"exp\", :ph, :tvc)\nfig, max_diff = run_scenario_diagnostics(scenario)\nfig\n\n\n\n┌ Warning: Found `resolution` in the theme when creating a `Scene`. The `resolution` keyword for `Scene`s and `Figure`s has been deprecated. Use `Figure(; size = ...` or `Scene(; size = ...)` instead, which better reflects that this is a unitless size and not a pixel resolution. The key could also come from `set_theme!` calls or related theming functions.\n\n└ @ Makie ~/.julia/packages/Makie/TOy8O/src/scenes.jl:264\n\n\n\n\n\n\n\n\n\n4.2 Weibull PH with Step-Function TVC\n\n\nShow code\nscenario = Scenario(\"wei\", :ph, :tvc)\nfig, max_diff = run_scenario_diagnostics(scenario)\nfig\n\n\n\n┌ Warning: Found `resolution` in the theme when creating a `Scene`. The `resolution` keyword for `Scene`s and `Figure`s has been deprecated. Use `Figure(; size = ...` or `Scene(; size = ...)` instead, which better reflects that this is a unitless size and not a pixel resolution. The key could also come from `set_theme!` calls or related theming functions.\n\n└ @ Makie ~/.julia/packages/Makie/TOy8O/src/scenes.jl:264"
  },
  {
    "objectID": "04_simulation_diagnostics.html#guarantees-validated",
    "href": "04_simulation_diagnostics.html#guarantees-validated",
    "title": "Simulation Diagnostics",
    "section": "5. Guarantees Validated",
    "text": "5. Guarantees Validated\nThis report validates the following guarantees:\n\nCall-stack accuracy: The eval_hazard, eval_cumhaz, and survprob functions produce values that match the closed-form analytical expressions.\nDistributional fidelity: The ECDF of simulated event times matches the theoretical CDF, with KS statistics consistent with the expected \\(O(1/\\sqrt{n})\\) convergence rate.\nTime-transform parity: Simulations using CachedTransformStrategy (time transforms enabled) produce identical results to DirectTransformStrategy (fallback), confirming that the caching optimization does not introduce bias.\nFamily coverage: All parametric families (Exponential, Weibull, Gompertz) with both PH and AFT covariate effects are validated."
  },
  {
    "objectID": "long_tests.html",
    "href": "long_tests.html",
    "title": "Long Test Status",
    "section": "",
    "text": "Long tests validate parameter recovery across all supported model configurations. Each test:\n\nSimulates data from a model with known true parameters (N=1000 subjects)\nFits the model to the simulated data\n\nCompares estimated parameters to true values\nVerifies distributional properties via prevalence and cumulative incidence plots\n\n\n\n23/28 tests passing | Last updated: 2026-01-01 18:28\n\n\n\n\n\n\nTest Name\nFamily\nData Type\nCovariates\nN\nStatus\n\n\n\n\nexp_exact_fixed\nexp\nexact\nfixed\n1000\n✅ Pass\n\n\nexp_exact_nocov\nexp\nexact\nnocov\n1000\n✅ Pass\n\n\nexp_exact_tvc\nexp\nexact\ntvc\n1000\n✅ Pass\n\n\nexp_panel_fixed\nexp\npanel\nfixed\n986\n✅ Pass\n\n\nexp_panel_nocov\nexp\npanel\nnocov\n990\n✅ Pass\n\n\nexp_panel_tvc\nexp\npanel\ntvc\n990\n✅ Pass\n\n\ngom_exact_fixed\ngom\nexact\nfixed\n1000\n✅ Pass\n\n\ngom_exact_nocov\ngom\nexact\nnocov\n1000\n✅ Pass\n\n\ngom_exact_tvc\ngom\nexact\ntvc\n1000\n✅ Pass\n\n\ngom_mcem_fixed\ngom\nmcem\nfixed\n984\n✅ Pass\n\n\ngom_mcem_nocov\ngom\nmcem\nnocov\n992\n✅ Pass\n\n\ngom_mcem_tvc\ngom\nmcem\ntvc\n993\n❌ Fail\n\n\npt_mixed_simple\nphasetype\nmixed\nnone\n1000\n✅ Pass\n\n\npt_mixed_structured\nphasetype\nmixed\nnone\n1000\n✅ Pass\n\n\npt_panel_fixed\nphasetype\npanel\nfixed\n1000\n❌ Fail\n\n\npt_panel_id\nphasetype\npanel\nnone\n1000\n✅ Pass\n\n\npt_panel_simple\nphasetype\npanel\nnone\n1000\n✅ Pass\n\n\npt_panel_tvc\nphasetype\npanel\ntvc\n1000\n❌ Fail\n\n\npt_exact_fixed\npt\nexact\nfixed\n1000\n✅ Pass\n\n\npt_exact_nocov\npt\nexact\nnocov\n1000\n✅ Pass\n\n\npt_exact_tvc\npt\nexact\ntvc\n1000\n✅ Pass\n\n\nsp_mcem_fixed\nsp\npanel\nfixed\n1000\n❌ Fail\n\n\nwei_exact_fixed\nwei\nexact\nfixed\n1000\n✅ Pass\n\n\nwei_exact_nocov\nwei\nexact\nnocov\n1000\n✅ Pass\n\n\nwei_exact_tvc\nwei\nexact\ntvc\n1000\n✅ Pass\n\n\nwei_mcem_fixed\nwei\nmcem\nfixed\n989\n✅ Pass\n\n\nwei_mcem_nocov\nwei\nmcem\nnocov\n991\n✅ Pass\n\n\nwei_mcem_tvc\nwei\nmcem\ntvc\n995\n❌ Fail"
  },
  {
    "objectID": "long_tests.html#test-inventory",
    "href": "long_tests.html#test-inventory",
    "title": "Long Test Status",
    "section": "",
    "text": "Long tests validate parameter recovery across all supported model configurations. Each test:\n\nSimulates data from a model with known true parameters (N=1000 subjects)\nFits the model to the simulated data\n\nCompares estimated parameters to true values\nVerifies distributional properties via prevalence and cumulative incidence plots\n\n\n\n23/28 tests passing | Last updated: 2026-01-01 18:28\n\n\n\n\n\n\nTest Name\nFamily\nData Type\nCovariates\nN\nStatus\n\n\n\n\nexp_exact_fixed\nexp\nexact\nfixed\n1000\n✅ Pass\n\n\nexp_exact_nocov\nexp\nexact\nnocov\n1000\n✅ Pass\n\n\nexp_exact_tvc\nexp\nexact\ntvc\n1000\n✅ Pass\n\n\nexp_panel_fixed\nexp\npanel\nfixed\n986\n✅ Pass\n\n\nexp_panel_nocov\nexp\npanel\nnocov\n990\n✅ Pass\n\n\nexp_panel_tvc\nexp\npanel\ntvc\n990\n✅ Pass\n\n\ngom_exact_fixed\ngom\nexact\nfixed\n1000\n✅ Pass\n\n\ngom_exact_nocov\ngom\nexact\nnocov\n1000\n✅ Pass\n\n\ngom_exact_tvc\ngom\nexact\ntvc\n1000\n✅ Pass\n\n\ngom_mcem_fixed\ngom\nmcem\nfixed\n984\n✅ Pass\n\n\ngom_mcem_nocov\ngom\nmcem\nnocov\n992\n✅ Pass\n\n\ngom_mcem_tvc\ngom\nmcem\ntvc\n993\n❌ Fail\n\n\npt_mixed_simple\nphasetype\nmixed\nnone\n1000\n✅ Pass\n\n\npt_mixed_structured\nphasetype\nmixed\nnone\n1000\n✅ Pass\n\n\npt_panel_fixed\nphasetype\npanel\nfixed\n1000\n❌ Fail\n\n\npt_panel_id\nphasetype\npanel\nnone\n1000\n✅ Pass\n\n\npt_panel_simple\nphasetype\npanel\nnone\n1000\n✅ Pass\n\n\npt_panel_tvc\nphasetype\npanel\ntvc\n1000\n❌ Fail\n\n\npt_exact_fixed\npt\nexact\nfixed\n1000\n✅ Pass\n\n\npt_exact_nocov\npt\nexact\nnocov\n1000\n✅ Pass\n\n\npt_exact_tvc\npt\nexact\ntvc\n1000\n✅ Pass\n\n\nsp_mcem_fixed\nsp\npanel\nfixed\n1000\n❌ Fail\n\n\nwei_exact_fixed\nwei\nexact\nfixed\n1000\n✅ Pass\n\n\nwei_exact_nocov\nwei\nexact\nnocov\n1000\n✅ Pass\n\n\nwei_exact_tvc\nwei\nexact\ntvc\n1000\n✅ Pass\n\n\nwei_mcem_fixed\nwei\nmcem\nfixed\n989\n✅ Pass\n\n\nwei_mcem_nocov\nwei\nmcem\nnocov\n991\n✅ Pass\n\n\nwei_mcem_tvc\nwei\nmcem\ntvc\n995\n❌ Fail"
  },
  {
    "objectID": "long_tests.html#test-results-by-family",
    "href": "long_tests.html#test-results-by-family",
    "title": "Long Test Status",
    "section": "Test Results by Family",
    "text": "Test Results by Family\n\nExponential\n\nExponential - Exact Data - Fixed Covariates\nTest: exp_exact_fixed | N: 1000 | Run: 2026-01-01T16:30:59.909 on penalized_splines (6b59be0)\n\n\nExponential - Exact Data - No Covariates\nTest: exp_exact_nocov | N: 1000 | Run: 2026-01-01T16:30:56.638 on penalized_splines (6b59be0)\n\n\nExponential - Exact Data - Time-Varying Covariates\nTest: exp_exact_tvc | N: 1000 | Run: 2026-01-01T16:31:00.825 on penalized_splines (6b59be0)\n\n\nExponential - Panel Data (Markov) - Fixed Covariates\nTest: exp_panel_fixed | N: 986 | Run: 2026-01-01T16:33:12.818 on penalized_splines (6b59be0)\n\n\nExponential - Panel Data (Markov) - No Covariates\nTest: exp_panel_nocov | N: 990 | Run: 2026-01-01T16:33:02.121 on penalized_splines (6b59be0)\n\n\nExponential - Panel Data (Markov) - Time-Varying Covariates\nTest: exp_panel_tvc | N: 990 | Run: 2026-01-01T16:33:23.251 on penalized_splines (6b59be0)\n\n\n\nWeibull\n\nWeibull - Exact Data - Fixed Covariates\nTest: wei_exact_fixed | N: 1000 | Run: 2026-01-01T16:31:38.432 on penalized_splines (6b59be0)\n\n\nWeibull - Exact Data - No Covariates\nTest: wei_exact_nocov | N: 1000 | Run: 2026-01-01T16:31:17.325 on penalized_splines (6b59be0)\n\n\nWeibull - Exact Data - Time-Varying Covariates\nTest: wei_exact_tvc | N: 1000 | Run: 2026-01-01T16:31:58.169 on penalized_splines (6b59be0)\n\n\nWeibull - Panel Data (MCEM) - Fixed Covariates\nTest: wei_mcem_fixed | N: 989 | Run: 2026-01-01T16:35:28.655 on penalized_splines (6b59be0)\n\n\nWeibull - Panel Data (MCEM) - No Covariates\nTest: wei_mcem_nocov | N: 991 | Run: 2026-01-01T16:34:12.161 on penalized_splines (6b59be0)\n\n\nWeibull - Panel Data (MCEM) - Time-Varying Covariates\nTest: wei_mcem_tvc | N: 995 | Run: 2026-01-01T16:36:30.196 on penalized_splines (6b59be0)\n\n\n\nGompertz\n\nGompertz - Exact Data - Fixed Covariates\nTest: gom_exact_fixed | N: 1000 | Run: 2026-01-01T16:32:31.437 on penalized_splines (6b59be0)\n\n\nGompertz - Exact Data - No Covariates\nTest: gom_exact_nocov | N: 1000 | Run: 2026-01-01T16:32:13.335 on penalized_splines (6b59be0)\n\n\nGompertz - Exact Data - Time-Varying Covariates\nTest: gom_exact_tvc | N: 1000 | Run: 2026-01-01T16:32:51.437 on penalized_splines (6b59be0)\n\n\nGompertz - Panel Data (MCEM) - Fixed Covariates\nTest: gom_mcem_fixed | N: 984 | Run: 2026-01-01T16:37:58.797 on penalized_splines (6b59be0)\n\n\nGompertz - Panel Data (MCEM) - No Covariates\nTest: gom_mcem_nocov | N: 992 | Run: 2026-01-01T16:37:05.896 on penalized_splines (6b59be0)\n\n\nGompertz - Panel Data (MCEM) - Time-Varying Covariates\nTest: gom_mcem_tvc | N: 993 | Run: 2026-01-01T16:38:53.898 on penalized_splines (6b59be0)\n\n\n\nPhase-Type\n\nPhase-Type - Exact Data - Fixed Covariates\nTest: pt_exact_fixed | N: 1000 | Run: 2026-01-01T16:49:44.907 on penalized_splines (6b59be0)\n\n\nPhase-Type - Exact Data - No Covariates\nTest: pt_exact_nocov | N: 1000 | Run: 2026-01-01T16:49:39.984 on penalized_splines (6b59be0)\n\n\nPhase-Type - Exact Data - Time-Varying Covariates\nTest: pt_exact_tvc | N: 1000 | Run: 2026-01-01T16:49:45.453 on penalized_splines (6b59be0)\n\n\n\nSpline\n\nSpline - Panel Data (Markov) - Fixed Covariates\nTest: sp_mcem_fixed | N: 1000 | Run: 2026-01-01T17:08:41.835 on penalized_splines (6b59be0)\n\n\n\n---\n\n### Exponential - Exact Data - Fixed Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n4×8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nh12_beta\n0.5\n0.526746\n0.065457\n0.39845\n0.655041\n5.34913\n✓\n\n\n2\nh12_log_rate\n-1.89712\n-1.88978\n0.0457869\n-1.97952\n-1.80004\n0.386995\n✓\n\n\n3\nh23_beta\n0.5\n0.479096\n0.0753465\n0.331417\n0.626775\n4.18081\n✓\n\n\n4\nh23_log_rate\n-2.12026\n-2.06702\n0.0555556\n-2.1759\n-1.95813\n2.51137\n✓\n\n\n\n\n\n\n\n---\n\n### Exponential - Exact Data - No Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n2×8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nh12_log_rate\n-1.89712\n-1.84645\n0.0332045\n-1.91154\n-1.78137\n2.67065\n✓\n\n\n2\nh23_log_rate\n-2.12026\n-2.09038\n0.0403567\n-2.16948\n-2.01128\n1.40959\n✓\n\n\n\n\n\n\n\n---\n\n### Exponential - Exact Data - Time-Varying Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n4×8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nh12_beta\n0.5\n0.411826\n0.065087\n0.284256\n0.539397\n17.6348\n✓\n\n\n2\nh12_log_rate\n-1.89712\n-1.84652\n0.0428746\n-1.93056\n-1.76249\n2.66705\n✓\n\n\n3\nh23_beta\n0.5\n0.339203\n0.0864828\n0.169696\n0.508709\n32.1595\n✓\n\n\n4\nh23_log_rate\n-2.12026\n-1.95338\n0.0764719\n-2.10327\n-1.8035\n7.87084\n✗\n\n\n\n\n\n\n\n---\n\n### Exponential - Panel Data (Markov) - Fixed Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n4×8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nh12_beta\n0.5\n0.532568\n0.0771887\n0.381278\n0.683858\n6.51366\n✓\n\n\n2\nh12_log_rate\n-1.89712\n-1.85012\n0.0546095\n-1.95716\n-1.74309\n2.47726\n✓\n\n\n3\nh23_beta\n0.5\n0.45703\n0.0898408\n0.280942\n0.633118\n8.59399\n✓\n\n\n4\nh23_log_rate\n-2.12026\n-2.0921\n0.0696143\n-2.22855\n-1.95566\n1.32826\n✓\n\n\n\n\n\n\n\n---\n\n### Exponential - Panel Data (Markov) - No Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n2×8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nh12_log_rate\n-1.89712\n-1.87335\n0.0394745\n-1.95072\n-1.79598\n1.25309\n✓\n\n\n2\nh23_log_rate\n-2.12026\n-2.09382\n0.0503324\n-2.19247\n-1.99517\n1.24721\n✓\n\n\n\n\n\n\n\n---\n\n### Exponential - Panel Data (Markov) - Time-Varying Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n4×8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nh12_beta\n0.5\n0.473535\n0.073794\n0.328899\n0.618171\n5.293\n✓\n\n\n2\nh12_log_rate\n-1.89712\n-1.8745\n0.0499861\n-1.97247\n-1.77653\n1.19237\n✓\n\n\n3\nh23_beta\n0.5\n0.484892\n0.0985236\n0.291786\n0.677998\n3.02159\n✓\n\n\n4\nh23_log_rate\n-2.12026\n-2.07011\n0.0844214\n-2.23558\n-1.90465\n2.36528\n✓\n\n\n\n\n\n\n\n---\n\n### Gompertz - Exact Data - Fixed Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n6×8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nh12_beta\n0.5\n0.412447\n0.0648108\n0.285418\n0.539476\n17.5106\n✓\n\n\n2\nh12_log_rate\n-1.89712\n-1.77672\n0.0638228\n-1.90181\n-1.65163\n6.34647\n✓\n\n\n3\nh12_shape\n0.05\n0.0371486\n0.00986178\n0.0178195\n0.0564777\n25.7028\n✓\n\n\n4\nh23_beta\n0.5\n0.53814\n0.0711483\n0.398689\n0.677591\n7.628\n✓\n\n\n5\nh23_log_rate\n-2.12026\n-2.14863\n0.0727701\n-2.29126\n-2.006\n1.3377\n✓\n\n\n6\nh23_shape\n0.03\n0.0384585\n0.0109827\n0.0169325\n0.0599845\n28.1951\n✓\n\n\n\n\n\n\n\n---\n\n### Gompertz - Exact Data - No Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n4×8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nh12_log_rate\n-1.89712\n-1.87834\n0.0530357\n-1.98229\n-1.77439\n0.989759\n✓\n\n\n2\nh12_shape\n0.05\n0.04426\n0.00878205\n0.0270472\n0.0614728\n11.48\n✓\n\n\n3\nh23_log_rate\n-2.12026\n-2.09246\n0.0628666\n-2.21568\n-1.96924\n1.31137\n✓\n\n\n4\nh23_shape\n0.03\n0.0345311\n0.0117755\n0.0114512\n0.057611\n15.1037\n✓\n\n\n\n\n\n\n\n---\n\n### Gompertz - Exact Data - Time-Varying Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n6×8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nh12_beta\n0.5\n0.384156\n0.116553\n0.155711\n0.612601\n23.1688\n✓\n\n\n2\nh12_log_rate\n-1.89712\n-1.87818\n0.0577317\n-1.99134\n-1.76503\n0.998275\n✓\n\n\n3\nh12_shape\n0.05\n0.0545131\n0.0177867\n0.0196513\n0.089375\n9.02628\n✓\n\n\n4\nh23_beta\n0.5\n0.480954\n0.0926818\n0.299298\n0.66261\n3.80921\n✓\n\n\n5\nh23_log_rate\n-2.12026\n-2.05207\n0.079264\n-2.20743\n-1.89672\n3.21609\n✓\n\n\n6\nh23_shape\n0.03\n0.0198651\n0.0125821\n-0.00479584\n0.044526\n33.7831\n✓\n\n\n\n\n\n\n\n---\n\n### Gompertz - Panel Data (MCEM) - Fixed Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n6×8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nh12_beta\n0.5\n0.284498\n0.0755857\n0.13635\n0.432646\n43.1005\n✗\n\n\n2\nh12_log_rate\n-1.89712\n-1.73651\n0.0791911\n-1.89172\n-1.58129\n8.46606\n✗\n\n\n3\nh12_shape\n0.05\n0.168865\n0.0178191\n0.13394\n0.20379\n237.73\n✗\n\n\n4\nh23_beta\n0.5\n0.119758\n0.0867347\n-0.0502423\n0.289758\n76.0485\n✗\n\n\n5\nh23_log_rate\n-2.12026\n-1.69718\n0.0946568\n-1.8827\n-1.51165\n19.9545\n✗\n\n\n6\nh23_shape\n0.03\n0.191964\n0.0210166\n0.150771\n0.233156\n539.878\n✗\n\n\n\n\n\n\n\n---\n\n### Gompertz - Panel Data (MCEM) - No Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n4×8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nh12_log_rate\n-1.89712\n-1.84424\n0.0694454\n-1.98035\n-1.70812\n2.78757\n✓\n\n\n2\nh12_shape\n0.05\n0.190753\n0.0166652\n0.158089\n0.223416\n281.505\n✗\n\n\n3\nh23_log_rate\n-2.12026\n-1.55959\n0.0871115\n-1.73033\n-1.38885\n26.4435\n✗\n\n\n4\nh23_shape\n0.03\n0.199919\n0.0250899\n0.150742\n0.249095\n566.395\n✗\n\n\n\n\n\n\n\n---\n\n### Gompertz - Panel Data (MCEM) - Time-Varying Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n6×8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nh12_beta\n0.5\n0.229463\n0.132961\n-0.03114\n0.490066\n54.1074\n✗\n\n\n2\nh12_log_rate\n-1.89712\n-2.1207\n0.0792563\n-2.27604\n-1.96536\n11.7853\n✗\n\n\n3\nh12_shape\n0.05\n0.225953\n0.0307129\n0.165756\n0.286151\n351.907\n✗\n\n\n4\nh23_beta\n0.5\n1.09197\n0.0965364\n0.902756\n1.28118\n118.393\n✗\n\n\n5\nh23_log_rate\n-2.12026\n-1.97517\n0.0811326\n-2.13419\n-1.81615\n6.84318\n✓\n\n\n6\nh23_shape\n0.03\n0.077206\n0.0226209\n0.032869\n0.121543\n157.353\n✗\n\n\n\n\n\n\n\n---\n\n### Phase-Type - Exact Data - Fixed Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n6×8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nbeta_1\n0.0\n0.0204126\n0.0847214\n-0.145641\n0.186466\n2.04126\n✓\n\n\n2\nbeta_2\n0.4\n0.43372\n0.0964374\n0.244703\n0.622737\n8.42994\n✓\n\n\n3\nbeta_3\n0.3\n0.324105\n0.0849959\n0.157513\n0.490697\n8.03504\n✓\n\n\n4\nlog_rate_1\n-0.693147\n-0.702404\n0.0582223\n-0.81652\n-0.588289\n1.33552\n✓\n\n\n5\nlog_rate_2\n-1.20397\n-1.15827\n0.0731272\n-1.3016\n-1.01494\n3.79592\n✓\n\n\n6\nlog_rate_3\n-0.510826\n-0.513388\n0.058621\n-0.628285\n-0.398491\n0.501624\n✓\n\n\n\n\n\n\n\n---\n\n### Phase-Type - Exact Data - No Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n8×8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nlog_rate_1\n-0.693147\n-0.779814\n0.0513665\n-0.880492\n-0.679135\n12.5033\n✓\n\n\n2\nlog_rate_2\n-1.20397\n-1.07544\n0.0595491\n-1.19216\n-0.958727\n10.6755\n✗\n\n\n3\nlog_rate_3\n-0.916291\n-0.89135\n0.0543125\n-0.997802\n-0.784897\n2.72194\n✓\n\n\n4\nlog_rate_4\n-1.60944\n-1.55932\n0.0751646\n-1.70664\n-1.41199\n3.11418\n✓\n\n\n5\nlog_rate_5\n-1.38629\n-1.44216\n0.0708881\n-1.5811\n-1.30322\n4.03001\n✓\n\n\n6\nlog_rate_6\n-1.04982\n-1.0177\n0.0631194\n-1.14141\n-0.893983\n3.06004\n✓\n\n\n7\nlog_rate_7\n-1.20397\n-1.22994\n0.0701862\n-1.36751\n-1.09238\n2.15713\n✓\n\n\n8\nlog_rate_8\n-1.89712\n-1.75227\n0.0776151\n-1.9044\n-1.60015\n7.63512\n✓\n\n\n\n\n\n\n\n---\n\n### Phase-Type - Exact Data - Time-Varying Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n6×8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nbeta_1\n0.0\n-0.0184989\n0.174056\n-0.359649\n0.322651\n1.84989\n✓\n\n\n2\nbeta_2\n0.5\n0.454755\n0.179613\n0.102714\n0.806797\n9.04891\n✓\n\n\n3\nbeta_3\n0.4\n0.319135\n0.0986186\n0.125843\n0.512428\n20.2162\n✓\n\n\n4\nlog_rate_1\n-0.916291\n-0.875647\n0.0415227\n-0.957031\n-0.794262\n4.43572\n✓\n\n\n5\nlog_rate_2\n-1.38629\n-1.37789\n0.0533761\n-1.48251\n-1.27327\n0.60635\n✓\n\n\n6\nlog_rate_3\n-0.693147\n-0.584399\n0.0457389\n-0.674047\n-0.49475\n15.6891\n✗\n\n\n\n\n\n\n\n---\n\n### phasetype - mixed - none - Details\n\n\n**Parameter Recovery:**\n\n\n\n3×8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\np1\n-1.04982\n-1.03833\n0.0460167\n-1.12852\n-0.948132\n1.09514\n✓\n\n\n2\np2\n-1.38629\n-1.40182\n0.0554219\n-1.51045\n-1.2932\n1.12018\n✓\n\n\n3\np3\n-0.798508\n-0.79215\n0.044898\n-0.88015\n-0.70415\n0.796161\n✓\n\n\n\n\n\n\n\n---\n\n### phasetype - mixed - none - Details\n\n\n**Parameter Recovery:**\n\n\n\n3×8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\np1\n-0.916291\n-0.951913\n0.0471724\n-1.04437\n-0.859455\n3.88761\n✓\n\n\n2\np2\n-1.38629\n-1.38502\n0.0593844\n-1.50141\n-1.26862\n0.0922677\n✓\n\n\n3\np3\n-0.693147\n-0.726022\n0.0453045\n-0.814819\n-0.637225\n4.74285\n✓\n\n\n\n\n\n\n\n---\n\n### Unknown - Panel Data (Markov) - Fixed Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n6×8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\np1\n-0.916291\n-0.909705\n0.0463105\n-1.00047\n-0.818937\n0.718703\n✓\n\n\n2\np2\n0.0\n0.193466\n0.0667954\n0.0625473\n0.324385\n19.3466\n✗\n\n\n3\np3\n-1.38629\n-25.8976\n0.0\n-25.8976\n-25.8976\n1768.11\n✗\n\n\n4\np4\n0.4\n0.00570717\n0.0\n0.00570717\n0.00570717\n98.5732\n✗\n\n\n5\np5\n-0.693147\n-26.4437\n0.0\n-26.4437\n-26.4437\n3715.01\n✗\n\n\n6\np6\n0.3\n-0.000830122\n0.0\n-0.000830122\n-0.000830122\n100.277\n✗\n\n\n\n\n\n\n\n---\n\n### Unknown - Panel Data (Markov) - Unknown - Details\n\n\n**Parameter Recovery:**\n\n\n\n8×8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\np1\n-0.693147\n-0.625669\n0.100717\n-0.823075\n-0.428263\n9.735\n✓\n\n\n2\np2\n-1.20397\n-1.22398\n0.148987\n-1.51599\n-0.931963\n1.66147\n✓\n\n\n3\np3\n-1.04982\n-1.03216\n0.103216\n-1.23446\n-0.829854\n1.68263\n✓\n\n\n4\np4\n-0.916291\n-0.952688\n0.121489\n-1.19081\n-0.714569\n3.97219\n✓\n\n\n5\np5\n-1.38629\n-1.26281\n0.142515\n-1.54214\n-0.983485\n8.9072\n✓\n\n\n6\np6\n-1.60944\n-1.56844\n0.0910699\n-1.74694\n-1.38994\n2.54744\n✓\n\n\n7\np7\n-1.20397\n-1.23632\n0.0935042\n-1.41959\n-1.05305\n2.68647\n✓\n\n\n8\np8\n-1.04982\n-1.03998\n0.0922861\n-1.22086\n-0.859095\n0.937887\n✓\n\n\n\n\n\n\n\n---\n\n### Unknown - Panel Data (Markov) - Unknown - Details\n\n\n**Parameter Recovery:**\n\n\n\n3×8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\np1\n-0.916291\n-0.840454\n0.075397\n-0.988232\n-0.692676\n8.27653\n✓\n\n\n2\np2\n-1.60944\n-1.52736\n0.12783\n-1.7779\n-1.27681\n5.10005\n✓\n\n\n3\np3\n-0.693147\n-0.653854\n0.0619913\n-0.775357\n-0.532351\n5.66882\n✓\n\n\n\n\n\n\n\n---\n\n### Unknown - Panel Data (Markov) - Time-Varying Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n6×8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\np1\n-0.916291\n-23.5454\n0.0\n-23.5454\n-23.5454\n2469.64\n✗\n\n\n2\np2\n0.0\n-0.962064\n0.0\n-0.962064\n-0.962064\n96.2064\n✗\n\n\n3\np3\n-1.38629\n-0.255928\n0.021944\n-0.298938\n-0.212918\n81.5387\n✗\n\n\n4\np4\n0.5\n0.651666\n0.0466929\n0.560148\n0.743184\n30.3332\n✗\n\n\n5\np5\n-0.693147\n3.22238\n0.0\n3.22238\n3.22238\n564.891\n✗\n\n\n6\np6\n0.4\n0.0462193\n0.0\n0.0462193\n0.0462193\n88.4452\n✗\n\n\n\n\n\n\n\n---\n\n### Spline - Panel Data (Markov) - Fixed Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n1×8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nbeta\n0.5\n-1.25739\nNaN\nNaN\nNaN\n351.478\n?\n\n\n\n\n\n\n\n---\n\n### Weibull - Exact Data - Fixed Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n6×8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nh12_beta\n0.5\n0.561068\n0.0647565\n0.434145\n0.687991\n12.2136\n✓\n\n\n2\nh12_log_scale\n-1.89712\n-1.89595\n0.0720161\n-2.0371\n-1.7548\n0.0616512\n✓\n\n\n3\nh12_log_shape\n0.182322\n0.167014\n0.0250907\n0.117836\n0.216192\n8.39594\n✓\n\n\n4\nh23_beta\n0.5\n0.488059\n0.0695899\n0.351662\n0.624455\n2.38828\n✓\n\n\n5\nh23_log_scale\n-2.12026\n-2.00192\n0.0771521\n-2.15314\n-1.8507\n5.58149\n✓\n\n\n6\nh23_log_shape\n0.0953102\n0.0382591\n0.0285863\n-0.01777\n0.0942882\n59.8583\n✗\n\n\n\n\n\n\n\n---\n\n### Weibull - Exact Data - No Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n4×8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nh12_log_scale\n-1.89712\n-1.90817\n0.0664495\n-2.03842\n-1.77793\n0.582702\n✓\n\n\n2\nh12_log_shape\n0.182322\n0.172548\n0.0255417\n0.122486\n0.22261\n5.36051\n✓\n\n\n3\nh23_log_scale\n-2.12026\n-1.92772\n0.0705533\n-2.066\n-1.78943\n9.08117\n✗\n\n\n4\nh23_log_shape\n0.0953102\n0.0359114\n0.0305228\n-0.0239132\n0.0957361\n62.3215\n✓\n\n\n\n\n\n\n\n---\n\n### Weibull - Exact Data - Time-Varying Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n6×8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nh12_beta\n0.5\n0.304335\n0.0887852\n0.130316\n0.478354\n39.133\n✗\n\n\n2\nh12_log_scale\n-1.89712\n-1.83579\n0.0681643\n-1.96939\n-1.70219\n3.23288\n✓\n\n\n3\nh12_log_shape\n0.182322\n0.182518\n0.0339722\n0.115933\n0.249104\n0.107935\n✓\n\n\n4\nh23_beta\n0.5\n0.583029\n0.0904944\n0.40566\n0.760398\n16.6057\n✓\n\n\n5\nh23_log_scale\n-2.12026\n-2.10673\n0.0807577\n-2.26502\n-1.94845\n0.638274\n✓\n\n\n6\nh23_log_shape\n0.0953102\n0.0621098\n0.0314562\n0.000455684\n0.123764\n34.834\n✓\n\n\n\n\n\n\n\n---\n\n### Weibull - Panel Data (MCEM) - Fixed Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n6×8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nh12_beta\n0.5\n0.236104\n0.0734473\n0.0921474\n0.380061\n52.7792\n✗\n\n\n2\nh12_log_scale\n-1.89712\n-1.52076\n0.080301\n-1.67815\n-1.36337\n19.8387\n✗\n\n\n3\nh12_log_shape\n0.182322\n0.227693\n0.0327314\n0.16354\n0.291847\n24.8855\n✓\n\n\n4\nh23_beta\n0.5\n0.239506\n0.0835806\n0.0756882\n0.403324\n52.0988\n✗\n\n\n5\nh23_log_scale\n-2.12026\n-1.70131\n0.0994666\n-1.89626\n-1.50635\n19.7597\n✗\n\n\n6\nh23_log_shape\n0.0953102\n0.322336\n0.0369632\n0.249888\n0.394784\n238.197\n✗\n\n\n\n\n\n\n\n---\n\n### Weibull - Panel Data (MCEM) - No Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n4×8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nh12_log_scale\n-1.89712\n-1.76173\n0.0799154\n-1.91836\n-1.6051\n7.13664\n✓\n\n\n2\nh12_log_shape\n0.182322\n0.320764\n0.0327404\n0.256593\n0.384935\n75.933\n✗\n\n\n3\nh23_log_scale\n-2.12026\n-1.85253\n0.100663\n-2.04983\n-1.65523\n12.6273\n✗\n\n\n4\nh23_log_shape\n0.0953102\n0.395194\n0.0397398\n0.317304\n0.473084\n314.64\n✗\n\n\n\n\n\n\n\n---\n\n### Weibull - Panel Data (MCEM) - Time-Varying Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n6×8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nh12_beta\n0.5\n0.806506\n0.0984655\n0.613513\n0.999498\n61.3011\n✗\n\n\n2\nh12_log_scale\n-1.89712\n-1.57963\n0.0729307\n-1.72257\n-1.43669\n16.7354\n✗\n\n\n3\nh12_log_shape\n0.182322\n0.102176\n0.0444122\n0.0151275\n0.189224\n43.9586\n✓\n\n\n4\nh23_beta\n0.5\n0.975225\n0.0895833\n0.799642\n1.15081\n95.0451\n✗\n\n\n5\nh23_log_scale\n-2.12026\n-1.99836\n0.08273\n-2.16051\n-1.83621\n5.74932\n✓\n\n\n6\nh23_log_shape\n0.0953102\n0.163469\n0.0398453\n0.0853725\n0.241566\n71.5129\n✓\n\n\n\n\n\n\n\n\n\n**State Prevalence: Exponential - Exact Data - Fixed Covariates**\n\nRed = true model, Blue = fitted model\n\n\n\n\n\n\n\n\n\n\n\n**State Prevalence: Exponential - Exact Data - No Covariates**\n\nRed = true model, Blue = fitted model\n\n\n\n\n\n\n\n\n\n\n\n**State Prevalence: Exponential - Exact Data - Time-Varying Covariates**\n\nRed = true model, Blue = fitted model\n\n\n\n\n\n\n\n\n\n\n\n**State Prevalence: Exponential - Panel Data (Markov) - Fixed Covariates**\n\nRed = true model, Blue = fitted model\n\n\n\n\n\n\n\n\n\n\n\n**State Prevalence: Exponential - Panel Data (Markov) - No Covariates**\n\nRed = true model, Blue = fitted model\n\n\n\n\n\n\n\n\n\n\n\n**State Prevalence: Exponential - Panel Data (Markov) - Time-Varying Covariates**\n\nRed = true model, Blue = fitted model\n\n\n\n\n\n\n\n\n\n\n\n**State Prevalence: Gompertz - Exact Data - Fixed Covariates**\n\nRed = true model, Blue = fitted model\n\n\n\n\n\n\n\n\n\n\n\n**State Prevalence: Gompertz - Exact Data - No Covariates**\n\nRed = true model, Blue = fitted model\n\n\n\n\n\n\n\n\n\n\n\n**State Prevalence: Gompertz - Exact Data - Time-Varying Covariates**\n\nRed = true model, Blue = fitted model\n\n\n\n\n\n\n\n\n\n\n\n**State Prevalence: Gompertz - Panel Data (MCEM) - Fixed Covariates**\n\nRed = true model, Blue = fitted model\n\n\n\n\n\n\n\n\n\n\n\n**State Prevalence: Gompertz - Panel Data (MCEM) - No Covariates**\n\nRed = true model, Blue = fitted model\n\n\n\n\n\n\n\n\n\n\n\n**State Prevalence: Gompertz - Panel Data (MCEM) - Time-Varying Covariates**\n\nRed = true model, Blue = fitted model\n\n\n\n\n\n\n\n\n\n\n\n**State Prevalence: Phase-Type - Exact Data - Fixed Covariates**\n\nRed = true model, Blue = fitted model\n\n*(Prevalence plots not available for this test)*\n\n**State Prevalence: Phase-Type - Exact Data - No Covariates**\n\nRed = true model, Blue = fitted model\n\n*(Prevalence plots not available for this test)*\n\n**State Prevalence: Phase-Type - Exact Data - Time-Varying Covariates**\n\nRed = true model, Blue = fitted model\n\n*(Prevalence plots not available for this test)*\n\n**State Prevalence: phasetype - mixed - none**\n\nRed = true model, Blue = fitted model\n\n*(Prevalence plots not available for this test)*\n\n**State Prevalence: phasetype - mixed - none**\n\nRed = true model, Blue = fitted model\n\n*(Prevalence plots not available for this test)*\n\n**State Prevalence: Unknown - Panel Data (Markov) - Fixed Covariates**\n\nRed = true model, Blue = fitted model\n\n*(Prevalence plots not available for this test)*\n\n**State Prevalence: Unknown - Panel Data (Markov) - Unknown**\n\nRed = true model, Blue = fitted model\n\n*(Prevalence plots not available for this test)*\n\n**State Prevalence: Unknown - Panel Data (Markov) - Unknown**\n\nRed = true model, Blue = fitted model\n\n*(Prevalence plots not available for this test)*\n\n**State Prevalence: Unknown - Panel Data (Markov) - Time-Varying Covariates**\n\nRed = true model, Blue = fitted model\n\n*(Prevalence plots not available for this test)*\n\n**State Prevalence: Spline - Panel Data (Markov) - Fixed Covariates**\n\nRed = true model, Blue = fitted model\n\n*(Prevalence plots not available for this test)*\n\n**State Prevalence: Weibull - Exact Data - Fixed Covariates**\n\nRed = true model, Blue = fitted model\n\n\n\n\n\n\n\n\n\n\n\n**State Prevalence: Weibull - Exact Data - No Covariates**\n\nRed = true model, Blue = fitted model\n\n\n\n\n\n\n\n\n\n\n\n**State Prevalence: Weibull - Exact Data - Time-Varying Covariates**\n\nRed = true model, Blue = fitted model\n\n\n\n\n\n\n\n\n\n\n\n**State Prevalence: Weibull - Panel Data (MCEM) - Fixed Covariates**\n\nRed = true model, Blue = fitted model\n\n\n\n\n\n\n\n\n\n\n\n**State Prevalence: Weibull - Panel Data (MCEM) - No Covariates**\n\nRed = true model, Blue = fitted model\n\n\n\n\n\n\n\n\n\n\n\n**State Prevalence: Weibull - Panel Data (MCEM) - Time-Varying Covariates**\n\nRed = true model, Blue = fitted model\n\n\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Exponential - Exact Data - Fixed Covariates**\n\nTransitions 1→2 and 2→3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Exponential - Exact Data - No Covariates**\n\nTransitions 1→2 and 2→3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Exponential - Exact Data - Time-Varying Covariates**\n\nTransitions 1→2 and 2→3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Exponential - Panel Data (Markov) - Fixed Covariates**\n\nTransitions 1→2 and 2→3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Exponential - Panel Data (Markov) - No Covariates**\n\nTransitions 1→2 and 2→3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Exponential - Panel Data (Markov) - Time-Varying Covariates**\n\nTransitions 1→2 and 2→3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Gompertz - Exact Data - Fixed Covariates**\n\nTransitions 1→2 and 2→3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Gompertz - Exact Data - No Covariates**\n\nTransitions 1→2 and 2→3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Gompertz - Exact Data - Time-Varying Covariates**\n\nTransitions 1→2 and 2→3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Gompertz - Panel Data (MCEM) - Fixed Covariates**\n\nTransitions 1→2 and 2→3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Gompertz - Panel Data (MCEM) - No Covariates**\n\nTransitions 1→2 and 2→3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Gompertz - Panel Data (MCEM) - Time-Varying Covariates**\n\nTransitions 1→2 and 2→3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Phase-Type - Exact Data - Fixed Covariates**\n\nTransitions 1→2 and 2→3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Phase-Type - Exact Data - No Covariates**\n\nTransitions 1→2 and 2→3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Phase-Type - Exact Data - Time-Varying Covariates**\n\nTransitions 1→2 and 2→3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: phasetype - mixed - none**\n\nTransitions 1→2 and 2→3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: phasetype - mixed - none**\n\nTransitions 1→2 and 2→3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Unknown - Panel Data (Markov) - Fixed Covariates**\n\nTransitions 1→2 and 2→3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Unknown - Panel Data (Markov) - Unknown**\n\nTransitions 1→2 and 2→3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Unknown - Panel Data (Markov) - Unknown**\n\nTransitions 1→2 and 2→3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Unknown - Panel Data (Markov) - Time-Varying Covariates**\n\nTransitions 1→2 and 2→3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Spline - Panel Data (Markov) - Fixed Covariates**\n\nTransitions 1→2 and 2→3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Weibull - Exact Data - Fixed Covariates**\n\nTransitions 1→2 and 2→3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Weibull - Exact Data - No Covariates**\n\nTransitions 1→2 and 2→3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Weibull - Exact Data - Time-Varying Covariates**\n\nTransitions 1→2 and 2→3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Weibull - Panel Data (MCEM) - Fixed Covariates**\n\nTransitions 1→2 and 2→3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Weibull - Panel Data (MCEM) - No Covariates**\n\nTransitions 1→2 and 2→3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Weibull - Panel Data (MCEM) - Time-Varying Covariates**\n\nTransitions 1→2 and 2→3 only (progressive model)"
  },
  {
    "objectID": "long_tests.html#running-long-tests",
    "href": "long_tests.html#running-long-tests",
    "title": "Long Test Status",
    "section": "Running Long Tests",
    "text": "Running Long Tests\n\nFull Suite\ncd MultistateModelsTests\n\n# Via the test package API\nMSM_TEST_LEVEL=full julia --project=. -e 'using MultistateModelsTests; MultistateModelsTests.runtests()'\n\n# Or via the dedicated script\njulia --project=. scripts/run_longtests.jl\n\n\nIndividual Test Suite\n# Run only a specific suite (by key name)\nMSM_TEST_LEVEL=full MSM_LONGTEST_ONLY=parametric_suite julia --project=. -e 'using MultistateModelsTests; MultistateModelsTests.runtests()'\n\n\nAvailable Test Suites\n\n\n\n\n\n\n\nKey\nDescription\n\n\n\n\nparametric_suite\nParametric families (exp/wei/gom) × data types × covariates\n\n\nexact_data\nExact observation direct MLE\n\n\nmcem_parametric\nPanel data with parametric hazards\n\n\nmcem_splines\nPanel data with spline hazards\n\n\nphasetype\nPhase-type hazard models\n\n\nvariance_validation\nVariance estimation validation\n\n\n\n\n\nEnvironment Variables\n\n\n\n\n\n\n\n\nVariable\nValues\nDescription\n\n\n\n\nMSM_TEST_LEVEL\nquick (default), full\nControls whether long tests run\n\n\nMSM_LONGTEST_ONLY\ntest key\nRun only one specific long test suite\n\n\nMSM_SUPPRESS_WARNINGS\ntrue (default), false\nSuppress expected warnings"
  },
  {
    "objectID": "long_tests.html#troubleshooting",
    "href": "long_tests.html#troubleshooting",
    "title": "Long Test Status",
    "section": "Troubleshooting",
    "text": "Troubleshooting\n\nParameter Recovery Failures\nSymptoms: Estimated parameters far from true values\nPotential Causes: 1. Insufficient sample size: Tests use N=1000, may need more for some models 2. Poor initialization: Check initialize_parameters! settings 3. MCEM convergence: Increase iterations or tighten tolerance\n\n\nVariance Estimation Issues\nSymptoms: Coverage rates significantly below 95%\nPotential Causes: 1. Small sample bias: Need larger n 2. Boundary parameters: Transform scale may help 3. Model misspecification: Verify DGP matches fitted model"
  },
  {
    "objectID": "long_tests.html#summary-1",
    "href": "long_tests.html#summary-1",
    "title": "Long Test Status",
    "section": "Summary",
    "text": "Summary\nLong tests provide rigorous validation that MultistateModels.jl:\n\nRecovers parameters within expected tolerance (20% relative error)\nProduces valid uncertainty through variance estimation\nSimulates correctly from fitted models\nHandles all supported hazard families and observation types\n\nThe test matrix covers: - Families: Exponential, Weibull, Gompertz, Phase-Type, Spline - Data types: Exact (direct MLE), Panel (Markov/MCEM) - Covariates: None, Time-fixed, Time-varying"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MultistateModels.jl",
    "section": "",
    "text": "Branch: penalized_splines   Commit: b1144da"
  },
  {
    "objectID": "index.html#overview",
    "href": "index.html#overview",
    "title": "MultistateModels.jl",
    "section": "Overview",
    "text": "Overview\nComprehensive validation and documentation for MultistateModels.jl — a Julia package for continuous-time multistate modeling.\n\n\n📐 Architecture\nType hierarchy, hazard families, inference engine, and simulation strategies.\n\n\n✅ Unit Tests\nFunction-level tests for hazards, simulation, MCEM, and model construction.\n\n\n📊 Long Tests\nStatistical recovery of parameters across hazard families and data types.\n\n\n🎯 Simulation\nVisual verification of event time distributions (CDF diagnostic plots).\n\n\n⚡ Benchmarks\nPerformance comparison of sampling methods and optimization strategies.\n\n\n📦 Main Package\nSource code and documentation for MultistateModels.jl."
  },
  {
    "objectID": "index.html#test-results-summary",
    "href": "index.html#test-results-summary",
    "title": "MultistateModels.jl",
    "section": "Test Results Summary",
    "text": "Test Results Summary\n\n\n\nMetric\nValue\n\n\n\n\nPassed\n1192\n\n\nFailed\n0\n\n\nErrors\n0\n\n\nPass Rate\n100.0%\n\n\nCategories\n12\n\n\nLast Updated\n2025-12-31T17:24:57.676"
  },
  {
    "objectID": "index.html#quick-start",
    "href": "index.html#quick-start",
    "title": "MultistateModels.jl",
    "section": "Quick Start",
    "text": "Quick Start\n\nBuilding Reports Locally\ncd MultistateModelsTests/reports\nquarto render\n\n\nRunning Tests and Recording Results\n# Run full test suite with automatic cache recording\njulia --project=. -e 'using MultistateModelsTests; MultistateModelsTests.runtests()'\n\n# Or run with the dedicated script\njulia --project=. scripts/run_all_tests.jl\nTest results are automatically cached when running via runtests().\n\n\nChecking Cache Status\njulia --project=. scripts/refresh_cache.jl"
  },
  {
    "objectID": "architecture.html",
    "href": "architecture.html",
    "title": "MultistateModels.jl Architecture",
    "section": "",
    "text": "MultistateModels.jl is a Julia package for fitting and simulating continuous-time multistate models. This document provides a comprehensive architectural overview, covering the package structure, type hierarchy, and key implementation patterns."
  },
  {
    "objectID": "architecture.html#overview",
    "href": "architecture.html#overview",
    "title": "MultistateModels.jl Architecture",
    "section": "",
    "text": "MultistateModels.jl is a Julia package for fitting and simulating continuous-time multistate models. This document provides a comprehensive architectural overview, covering the package structure, type hierarchy, and key implementation patterns."
  },
  {
    "objectID": "architecture.html#package-structure",
    "href": "architecture.html#package-structure",
    "title": "MultistateModels.jl Architecture",
    "section": "Package Structure",
    "text": "Package Structure\nThe package is organized into the following directories:\nsrc/\n├── MultistateModels.jl      # Main module, exports, includes\n├── construction/            # Model construction (multistatemodel function)\n├── hazard/                  # Hazard functions and evaluation\n├── inference/               # MCEM, SIR, fitting algorithms\n├── likelihood/              # Log-likelihood computation\n├── output/                  # Model accessors and variance estimation\n├── phasetype/               # Phase-type distributions and FFBS\n├── simulation/              # Path simulation\n├── surrogate/               # Markov surrogates\n├── types/                   # Type definitions\n└── utilities/               # Parameter handling, validation, misc"
  },
  {
    "objectID": "architecture.html#type-hierarchy",
    "href": "architecture.html#type-hierarchy",
    "title": "MultistateModels.jl Architecture",
    "section": "Type Hierarchy",
    "text": "Type Hierarchy\n\nInternal Hazard Types\nThe package uses an internal type hierarchy for hazard functions that distinguishes between Markov (time-homogeneous) and semi-Markov (sojourn-time-dependent) hazards:\n\n\n\n\n\n\n\n\n\nKey insight: PhaseTypeCoxianHazard inherits from _MarkovHazard because the stochastic process on the expanded state space (with latent phases) is Markovian—each phase transition is exponential. The non-exponential sojourn time arises from the mixture over paths through phases, not from any single transition.\n\n\nModel Types\n\n\n\n\n\n\n\n\n\n\n\nUser-Facing Hazard Specifications\nUsers specify hazards via HazardFunction subtypes, which are converted to internal types during model construction:\n\n\n\n\n\n\n\n\nUser Specification\nInternal Type\nDescription\n\n\n\n\nParametricHazard (:exp)\nMarkovHazard\nExponential (constant hazard)\n\n\nParametricHazard (:wei, :gom)\nSemiMarkovHazard\nWeibull, Gompertz\n\n\nSplineHazard (:sp)\nRuntimeSplineHazard\nB-spline hazard\n\n\nPhaseTypeHazard (:pt)\nPhaseTypeCoxianHazard\nPhase-type (Coxian)\n\n\n\n\n\nTrait-Based Dispatch\nRather than using the type hierarchy directly, model behavior is determined by trait functions:\nis_markov(model)              # All hazards are _MarkovHazard?\nis_panel_data(model)          # Any obstype ≥ 2?\nhas_phasetype_expansion(model) # Model has phase-type hazards?\nThese traits determine which fitting algorithm is used: - is_panel_data=false → Direct MLE (exact data) - is_panel_data=true && is_markov=true → Matrix exponential MLE - is_panel_data=true && is_markov=false → MCEM"
  },
  {
    "objectID": "architecture.html#data-handling",
    "href": "architecture.html#data-handling",
    "title": "MultistateModels.jl Architecture",
    "section": "Data Handling",
    "text": "Data Handling\n\nRequired Data Format\nData must be a DataFrame with the following columns:\n\n\n\nColumn\nType\nDescription\n\n\n\n\nid\nInt/String\nSubject identifier\n\n\ntstart\nFloat64\nInterval start time\n\n\ntstop\nFloat64\nInterval end time\n\n\nstatefrom\nInt\nState at tstart\n\n\nstateto\nInt\nState at tstop\n\n\nobstype\nInt\nObservation type code\n\n\ncovariates\nAny\nModel-specific covariates\n\n\n\n\n\nObservation Types (obstype)\nThe obstype column controls how each observation contributes to the likelihood:\n\n\n\n\n\n\n\n\n\nCode\nName\nDescription\nLikelihood Contribution\n\n\n\n\n1\nExact\nTransition time and state observed exactly\nTransition density\n\n\n2\nPanel\nState known at tstop, transition time unknown\nTPM entry\n\n\n0\nFully censored\nState unknown at tstop\nSum over all states\n\n\n≥3\nPartially censored\nState partially known (see CensoringPatterns)\nWeighted sum\n\n\n\n\n\nCensoringPatterns\nFor obstype ≥ 3, you must provide a CensoringPatterns matrix specifying which states are compatible with each censoring code:\n# 3-state model with two censoring patterns\n# obstype=3: states 1 or 2 possible (not 3)\n# obstype=4: states 2 or 3 possible (not 1)\nCensoringPatterns = [\n    # code  state1  state2  state3\n    3       1.0     1.0     0.0;\n    4       0.0     1.0     1.0\n]\n\nmodel = multistatemodel(h12, h23; data=dat, CensoringPatterns=CensoringPatterns)\n\n\nEmissionMatrix\nFor maximum flexibility, you can provide an observation-specific EmissionMatrix directly. This is an \\((n_{\\text{obs}} \\times n_{\\text{states}})\\) matrix where entry \\((i, s)\\) gives \\(P(\\text{observation } i \\mid \\text{state } s)\\)."
  },
  {
    "objectID": "architecture.html#hazard-families",
    "href": "architecture.html#hazard-families",
    "title": "MultistateModels.jl Architecture",
    "section": "Hazard Families",
    "text": "Hazard Families\n\nParametric Distributions\n\n\n\n\n\n\n\n\n\n\nFamily\nSymbol\nParameters\nHazard \\(h(t)\\)\nMarkov?\n\n\n\n\nExponential\n:exp\nrate \\((\\lambda)\\)\n\\(\\lambda\\)\n✓\n\n\nWeibull\n:wei\nshape \\((a)\\), scale \\((b)\\)\n\\(\\displaystyle\\frac{a}{b}\\left(\\frac{t}{b}\\right)^{a-1}\\)\n✗\n\n\nGompertz\n:gom\nshape \\((a)\\), rate \\((b)\\)\n\\(b \\cdot e^{at}\\)\n✗\n\n\nB-Spline\n:sp\ncoefs \\((\\beta_1,\\ldots,\\beta_K)\\)\n\\(\\exp\\left(\\sum_{k=1}^K B_k(t)\\beta_k\\right)\\)\n✗ (degree&gt;0)\n\n\nPhase-Type\n:pt\n\\(\\lambda_1,\\ldots,\\lambda_{n-1}\\), \\(\\mu_1,\\ldots,\\mu_n\\)\nCoxian absorption\n✓ (expanded)\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nGompertz Parameterization: MultistateModels.jl uses the flexsurv parameterization where shape (\\(a\\)) is the rate of hazard increase and rate (\\(b\\)) is the initial hazard at \\(t=0\\).\n\n\n\n\nPhase-Type Structure\nPhase-type hazards (:pt) use a Coxian structure with latent phases:\n\n\n\n\n\n\n\n\n\nKey properties:\n\nApproximate any non-negative distribution arbitrarily well\nThe process on the expanded state space is Markovian — hence PhaseTypeCoxianHazard &lt;: _MarkovHazard\nNon-exponential sojourn times arise from the mixture over phase paths\nParameters: \\(\\lambda_1, \\ldots, \\lambda_{n-1}\\) (progression), \\(\\mu_1, \\ldots, \\mu_n\\) (exit)\n\n\n\nCovariate Effects\nTwo covariate effect types are supported:\nProportional Hazards (PH): \\[h(t|\\mathbf{x}) = h_0(t) \\exp(\\mathbf{x}'\\boldsymbol{\\beta})\\]\nAccelerated Failure Time (AFT): \\[h(t|\\mathbf{x}) = h_0(t \\cdot e^{\\mathbf{x}'\\boldsymbol{\\beta}}) \\cdot e^{\\mathbf{x}'\\boldsymbol{\\beta}}\\]\n# Specify effect type when creating hazards\nh12_ph = Hazard(@formula(0 ~ 1 + age), \"wei\", 1, 2; linpred_effect=:ph)\nh12_aft = Hazard(@formula(0 ~ 1 + age), \"wei\", 1, 2; linpred_effect=:aft)\n\n\n\n\n\n\nWarning\n\n\n\nThe covariate effect types (:ph and :aft) are built into the package. Adding custom effect types requires modifying the hazard generation code—this is not user-extensible."
  },
  {
    "objectID": "architecture.html#parameter-handling",
    "href": "architecture.html#parameter-handling",
    "title": "MultistateModels.jl Architecture",
    "section": "Parameter Handling",
    "text": "Parameter Handling\n\nParameter Structure\nParameters are stored as NamedTuples with multiple representations:\nmodel.parameters = (\n    flat = [...],           # Flat vector on estimation (log) scale\n    nested = (...),         # Nested NamedTuple by hazard\n    natural = (...),        # Natural scale values by hazard\n    reconstructor = ...     # Function to unflatten\n)\nEach hazard’s parameters include: - Baseline parameters (shape, scale, rate, coefs, etc.) - Regression coefficients (if covariates specified)\n\n\nScale Transformations\nParameters are estimated on transformed scales for numerical stability:\n\n\n\n\n\n\n\n\n\nParameter Type\nNatural Scale\nEstimation Scale\nTransformation\n\n\n\n\nRates, shapes, scales\n\\((0, \\infty)\\)\n\\((-\\infty, \\infty)\\)\n\\(\\log\\)\n\n\nSpline coefficients\n\\((-\\infty, \\infty)\\)\n\\((-\\infty, \\infty)\\)\nIdentity\n\n\nRegression \\(\\beta\\)\n\\((-\\infty, \\infty)\\)\n\\((-\\infty, \\infty)\\)\nIdentity\n\n\n\nTransformation by family:\n\n\n\n\n\n\n\n\n\n\nFamily\nParameter\nNatural\nEstimation\nTransform\n\n\n\n\nExponential\nrate\n\\(\\lambda &gt; 0\\)\n\\(\\theta \\in \\mathbb{R}\\)\n\\(\\lambda = e^\\theta\\)\n\n\nWeibull\nshape\n\\(a &gt; 0\\)\n\\(\\theta_a \\in \\mathbb{R}\\)\n\\(a = e^{\\theta_a}\\)\n\n\nWeibull\nscale\n\\(b &gt; 0\\)\n\\(\\theta_b \\in \\mathbb{R}\\)\n\\(b = e^{\\theta_b}\\)\n\n\nGompertz\nshape\n\\(a \\in \\mathbb{R}\\)\n\\(a\\)\nIdentity\n\n\nGompertz\nrate\n\\(b &gt; 0\\)\n\\(\\theta_b \\in \\mathbb{R}\\)\n\\(b = e^{\\theta_b}\\)\n\n\nSpline\ncoefs\n\\(\\boldsymbol{\\beta}\\)\n\\(\\boldsymbol{\\beta}\\)\nIdentity\n\n\n\n# Access parameters in different scales\np_natural = model.parameters.natural   # Interpretable values\np_flat = model.parameters.flat         # For optimization (log scale)"
  },
  {
    "objectID": "architecture.html#inference-methods",
    "href": "architecture.html#inference-methods",
    "title": "MultistateModels.jl Architecture",
    "section": "Inference Methods",
    "text": "Inference Methods\n\nFitting Strategy Selection\nThe fit() function automatically selects the appropriate method based on data and hazard types:\n\n\n\n\n\n\n\n\n\n\n\nDirect MLE (Exact Data)\nFor exactly observed data (obstype=1), the likelihood factorizes into transition densities:\n\\[\\mathcal{L}(\\boldsymbol{\\theta}) = \\prod_{i} \\prod_{j} h_{s_j \\to s_{j+1}}(t_j) \\cdot S_{s_j}(t_j - t_{j-1})\\]\nwhere \\(S_s(t) = \\exp(-H_s(t))\\) is the survival probability in state \\(s\\).\n\n\nMatrix Exponential MLE (Markov Panel)\nFor panel data with Markov hazards (exponential or phase-type), the likelihood uses transition probability matrices:\n\\[P(t_0, t_1) = \\exp(\\mathbf{Q} \\cdot (t_1 - t_0))\\]\nwhere \\(\\mathbf{Q}\\) is the generator matrix.\n\n\nMonte Carlo EM (Semi-Markov Panel)\nFor panel data with semi-Markov hazards (Weibull, Gompertz, degree&gt;0 splines), MCEM is used:\nE-step: Sample latent paths via importance sampling using a Markov surrogate\nM-step: Maximize expected complete-data log-likelihood with importance weights\nFeatures: - SQUAREM acceleration - Adaptive ESS targeting - Latin Hypercube Sampling (LHS) for variance-reduced resampling\n\n\nForward-Filtering Backward-Sampling (FFBS)\nFFBS samples latent state sequences given observations. For phase-type models, FFBS operates on the expanded Markov state space, then collapses sampled phases back to observed states.\nSee the Phase-Type FFBS documentation for details."
  },
  {
    "objectID": "architecture.html#variance-estimation",
    "href": "architecture.html#variance-estimation",
    "title": "MultistateModels.jl Architecture",
    "section": "Variance Estimation",
    "text": "Variance Estimation\nThree variance estimation approaches are available:\n\n\n\n\n\n\n\n\n\nMethod\nDescription\nPros\nCons\n\n\n\n\nModel-based\nInverse Hessian at MLE\nFast, standard\nAssumes correct model\n\n\nSandwich (IJ)\nInfinitesimal jackknife\nRobust to misspecification\nRequires more computation\n\n\nJackknife\nLeave-one-out refitting\nNonparametric\nComputationally expensive\n\n\n\nfitted = fit(model; \n    compute_vcov=true,      # Model-based (default)\n    compute_ij_vcov=true,   # Sandwich estimator\n    compute_jk_vcov=false   # Jackknife (slow)\n)"
  },
  {
    "objectID": "architecture.html#custom-constraints",
    "href": "architecture.html#custom-constraints",
    "title": "MultistateModels.jl Architecture",
    "section": "Custom Constraints",
    "text": "Custom Constraints\nUsers can specify parameter constraints using expressions that reference parameter names:\n# Constraint: shape parameter must be ≥ 1\n# Constraint: two hazards share the same rate\nconstraints = make_constraints(\n    cons = [\n        :(h1_2_shape - 1),           # shape ≥ 1 → (shape - 1) ≥ 0\n        :(h1_2_rate - h2_3_rate)     # Equal rates → difference = 0\n    ],\n    lcons = [0.0, 0.0],   # Lower bounds\n    ucons = [Inf, 0.0]    # Upper bounds\n)\n\nfitted = fit(model; constraints=constraints)\nParameter naming: h{from}_{to}_{param} (e.g., h1_2_shape, h2_3_rate)\n\n\n\n\n\n\nWarning\n\n\n\nVariance-covariance matrices are not computed when constraints are active, as the constrained MLE may lie on the boundary of the parameter space."
  },
  {
    "objectID": "architecture.html#simulation-engine",
    "href": "architecture.html#simulation-engine",
    "title": "MultistateModels.jl Architecture",
    "section": "Simulation Engine",
    "text": "Simulation Engine\nThe simulation engine samples complete state trajectories:\n\nInitialize at starting state and time\nCompute total hazard from current state\nSample waiting time via inverse CDF\nSample destination state proportional to hazard rates\nUpdate state and time\nRepeat until absorbing state or end time\n\npaths = simulate(model; nsim=1000, tmax=10.0)"
  },
  {
    "objectID": "architecture.html#summary",
    "href": "architecture.html#summary",
    "title": "MultistateModels.jl Architecture",
    "section": "Summary",
    "text": "Summary\nMultistateModels.jl provides a flexible framework for multistate modeling:\n\nType hierarchy: _MarkovHazard vs _SemiMarkovHazard governs fitting method selection\nPhase-type hazards are Markovian on the expanded space (not semi-Markov!)\nTrait-based dispatch via is_markov(), is_panel_data(), has_phasetype_expansion()\nParameters as NamedTuples with flat/nested/natural representations\nFlexible observation handling via obstype, CensoringPatterns, EmissionMatrix\nThree fitting algorithms: Direct MLE, Matrix Exp MLE, MCEM (auto-selected)\nLHS resampling for variance-reduced importance sampling in MCEM"
  },
  {
    "objectID": "unit_tests.html",
    "href": "unit_tests.html",
    "title": "Unit Test Coverage",
    "section": "",
    "text": "This document provides a comprehensive summary of unit test coverage for MultistateModels.jl. Unit tests verify individual functions and components work correctly in isolation, forming the foundation of the testing pyramid.\n\n\n🟢 Cache current (b1144da, updated 2025-12-31T17:24:57.676)\n\n\n**Branch:** `penalized_splines` | **Commit:** `b1144da`\n\n⚠️ Uncommitted changes in: Project.toml, docs/build/.documenter-siteinfo.json, docs/build/assets/documenter.js...\n\n\n\n\n\n\n\n| Metric | Value |\n|--------|-------|\n| Total Passed | 1192 |\n| Total Failed | 0 |\n| Total Errors | 0 |\n| Categories Tested | 12 |\n\n\n\n\n\n\n\n12×6 DataFrame\n\n\n\nRow\nCategory\nPassed\nFailed\nErrors\nTimestamp\nStatus\n\n\n\nSymbol\nInt64\nInt64\nInt64\nString\nString\n\n\n\n\n1\nsurrogates\n58\n0\n0\n2025-12-31T17:24:55.579\n✅ Pass\n\n\n2\nsimulation\n39\n0\n0\n2025-12-31T17:24:55.937\n✅ Pass\n\n\n3\nmcem\n23\n0\n0\n2025-12-31T17:24:56.097\n✅ Pass\n\n\n4\nsplines\n152\n0\n0\n2025-12-31T17:24:56.279\n✅ Pass\n\n\n5\nmodelgeneration\n5\n0\n0\n2025-12-31T17:24:56.461\n✅ Pass\n\n\n6\nhelpers\n53\n0\n0\n2025-12-31T17:24:56.640\n✅ Pass\n\n\n7\nreconstructor\n79\n0\n0\n2025-12-31T17:24:56.808\n✅ Pass\n\n\n8\ninitialization\n59\n0\n0\n2025-12-31T17:24:56.983\n✅ Pass\n\n\n9\nhazards\n163\n0\n0\n2025-12-31T17:24:57.152\n✅ Pass\n\n\n10\nsir\n38\n0\n0\n2025-12-31T17:24:57.323\n✅ Pass\n\n\n11\nphasetype\n505\n0\n0\n2025-12-31T17:24:57.491\n✅ Pass\n\n\n12\nvariance\n18\n0\n0\n2025-12-31T17:24:57.662\n✅ Pass"
  },
  {
    "objectID": "unit_tests.html#overview",
    "href": "unit_tests.html#overview",
    "title": "Unit Test Coverage",
    "section": "",
    "text": "This document provides a comprehensive summary of unit test coverage for MultistateModels.jl. Unit tests verify individual functions and components work correctly in isolation, forming the foundation of the testing pyramid.\n\n\n🟢 Cache current (b1144da, updated 2025-12-31T17:24:57.676)\n\n\n**Branch:** `penalized_splines` | **Commit:** `b1144da`\n\n⚠️ Uncommitted changes in: Project.toml, docs/build/.documenter-siteinfo.json, docs/build/assets/documenter.js...\n\n\n\n\n\n\n\n| Metric | Value |\n|--------|-------|\n| Total Passed | 1192 |\n| Total Failed | 0 |\n| Total Errors | 0 |\n| Categories Tested | 12 |\n\n\n\n\n\n\n\n12×6 DataFrame\n\n\n\nRow\nCategory\nPassed\nFailed\nErrors\nTimestamp\nStatus\n\n\n\nSymbol\nInt64\nInt64\nInt64\nString\nString\n\n\n\n\n1\nsurrogates\n58\n0\n0\n2025-12-31T17:24:55.579\n✅ Pass\n\n\n2\nsimulation\n39\n0\n0\n2025-12-31T17:24:55.937\n✅ Pass\n\n\n3\nmcem\n23\n0\n0\n2025-12-31T17:24:56.097\n✅ Pass\n\n\n4\nsplines\n152\n0\n0\n2025-12-31T17:24:56.279\n✅ Pass\n\n\n5\nmodelgeneration\n5\n0\n0\n2025-12-31T17:24:56.461\n✅ Pass\n\n\n6\nhelpers\n53\n0\n0\n2025-12-31T17:24:56.640\n✅ Pass\n\n\n7\nreconstructor\n79\n0\n0\n2025-12-31T17:24:56.808\n✅ Pass\n\n\n8\ninitialization\n59\n0\n0\n2025-12-31T17:24:56.983\n✅ Pass\n\n\n9\nhazards\n163\n0\n0\n2025-12-31T17:24:57.152\n✅ Pass\n\n\n10\nsir\n38\n0\n0\n2025-12-31T17:24:57.323\n✅ Pass\n\n\n11\nphasetype\n505\n0\n0\n2025-12-31T17:24:57.491\n✅ Pass\n\n\n12\nvariance\n18\n0\n0\n2025-12-31T17:24:57.662\n✅ Pass"
  },
  {
    "objectID": "unit_tests.html#test-organization",
    "href": "unit_tests.html#test-organization",
    "title": "Unit Test Coverage",
    "section": "Test Organization",
    "text": "Test Organization\nUnit tests are located in MultistateModelsTests/unit/ and organized by functional area:\nMultistateModelsTests/unit/\n├── test_hazards.jl                    # Hazard function evaluation\n├── test_splines.jl                    # B-spline hazard implementation\n├── test_simulation.jl                 # Path simulation engine\n├── test_mcem.jl                       # MCEM algorithm components\n├── test_phasetype.jl                  # Phase-type distributions\n├── test_phasetype_emission_expansion.jl\n├── test_phasetype_panel_expansion.jl\n├── test_sir.jl                        # Sampling importance resampling\n├── test_variance.jl                   # Variance estimation\n├── test_pijcv.jl                      # PIJ cross-validation\n├── test_initialization.jl             # Parameter initialization\n├── test_modelgeneration.jl            # Model construction\n├── test_helpers.jl                    # Utility functions\n├── test_reconstructor.jl              # Parameter flattening\n├── test_mll_consistency.jl            # Likelihood consistency\n├── test_observation_weights_emat.jl   # Weighted observations\n├── test_per_transition_obstype.jl     # Per-transition observation types\n├── test_reversible_tvc_loglik.jl      # Time-varying covariates\n├── test_subject_weights.jl            # Subject weighting\n└── test_surrogates.jl                 # Surrogate models"
  },
  {
    "objectID": "unit_tests.html#coverage-by-module",
    "href": "unit_tests.html#coverage-by-module",
    "title": "Unit Test Coverage",
    "section": "Coverage by Module",
    "text": "Coverage by Module\n\nHazard Functions (test_hazards.jl)\nPurpose: Validate that all hazard functions return correct values against analytical formulas.\n\n\n9×3 DataFrame\n\n\n\nRow\nTestSet\nCoverage\nStatus\n\n\n\nString\nString\nString\n\n\n\n\n1\nsurvprob\nSurvival probability S(t₁,t₂) = exp(-H(t₁,t₂))\n✅\n\n\n2\ntest_hazards_exp\nExponential: h(t) = λ, PH covariates\n✅\n\n\n3\ntest_hazards_weibull\nWeibull: h(t) = λκt^{κ-1}, PH covariates\n✅\n\n\n4\ntest_hazards_weibull_aft\nWeibull AFT: h(t|x) = h₀(t·e^{-β'x})·e^{-β'x}\n✅\n\n\n5\ntest_hazards_gompertz\nGompertz: h(t) = b·e^{at}, PH covariates\n✅\n\n\n6\ntest_hazards_gompertz_aft\nGompertz AFT covariate effects\n✅\n\n\n7\ntest_cumhaz_consistency\nH(a,c) = H(a,b) + H(b,c) additivity\n✅\n\n\n8\ntotal_cumulhaz\nTotal hazard from competing transitions\n✅\n\n\n9\ntpm_computation\nTransition probability matrix computation\n✅\n\n\n\n\n\n\nKey Formulas Verified:\n\n\n\nDistribution\nHazard \\(h(t)\\)\nCumulative Hazard \\(H(t)\\)\n\n\n\n\nExponential\n\\(\\lambda\\)\n\\(\\lambda t\\)\n\n\nWeibull\n\\(\\lambda \\kappa t^{\\kappa-1}\\)\n\\(\\lambda t^\\kappa\\)\n\n\nGompertz\n\\(b \\exp(at)\\)\n\\(\\frac{b}{a}(\\exp(at) - 1)\\)\n\n\n\n\n\nSpline Hazards (test_splines.jl)\nPurpose: Verify B-spline hazard implementation against numerical integration.\n\n\n7×3 DataFrame\n\n\n\nRow\nTestSet\nCoverage\nStatus\n\n\n\nString\nString\nString\n\n\n\n\n1\nCumhaz vs QuadGK\nH(a,b) = ∫ₐᵇ h(t)dt numerical verification\n✅\n\n\n2\nPH covariate effect\nh(t|x) = h₀(t)exp(β'x) multiplicative effect\n✅\n\n\n3\nSurvival probability\nS(a,b) = exp(-H(a,b)) survival function\n✅\n\n\n4\nCumhaz additivity\nH(a,c) = H(a,b) + H(b,c) partition property\n✅\n\n\n5\nKnot placement\nAuto knot placement from data quantiles\n✅\n\n\n6\nCoefficient transforms\nLog-coefficient ↔︎ natural scale transforms\n✅\n\n\n7\nBoundary conditions\nBoundary knot handling for extrapolation\n✅\n\n\n\n\n\n\nNumerical Verification Strategy:\n# Tests verify cumulative hazard matches numerical integration\nH_analytical = eval_cumhaz(hazard, lb, ub, params, covars)\nH_numerical = quadgk(t -&gt; eval_hazard(hazard, t, params, covars), lb, ub)[1]\n@test H_analytical ≈ H_numerical rtol=1e-6\n\n\nSimulation Engine (test_simulation.jl)\nPurpose: Validate path simulation produces statistically correct distributions.\n\n\n7×3 DataFrame\n\n\n\nRow\nTestSet\nCoverage\nStatus\n\n\n\nString\nString\nString\n\n\n\n\n1\nExponential waiting times\nWaiting times ~ Exp(total_hazard)\n✅\n\n\n2\nCompeting risks allocation\nTransition to state j ~ h_j/Σh_k\n✅\n\n\n3\nAbsorbing state termination\nSimulation stops at absorbing states\n✅\n\n\n4\nSojourn time distributions\nNon-Markov sojourns match theory\n✅\n\n\n5\nSolver strategy parity\nOptimJumpSolver vs ExponentialJumpSolver\n✅\n\n\n6\nCovariate propagation\nCovariates correctly passed through path\n✅\n\n\n7\nRight-censoring handling\nPaths correctly censored at max_time\n✅\n\n\n\n\n\n\n\n\nMCEM Algorithm (test_mcem.jl)\nPurpose: Verify Monte Carlo EM components for panel data likelihood.\n\n\n6×3 DataFrame\n\n\n\nRow\nTestSet\nCoverage\nStatus\n\n\n\nString\nString\nString\n\n\n\n\n1\nE-step sampling\nConditional path sampling given observations\n✅\n\n\n2\nM-step optimization\nExpected complete-data LL maximization\n✅\n\n\n3\nSQUAREM acceleration\nAccelerated EM convergence (SQUAREM)\n✅\n\n\n4\nConvergence detection\nAscent-based stopping criterion\n✅\n\n\n5\nPath weighting\nCorrect weighting of sampled paths\n✅\n\n\n6\nImportance weights\nImportance sampling weight computation\n✅\n\n\n\n\n\n\n\n\nPhase-Type Distributions (test_phasetype.jl)\nPurpose: Validate phase-type approximations for semi-Markov processes.\n\n\n6×3 DataFrame\n\n\n\nRow\nTestSet\nCoverage\nStatus\n\n\n\nString\nString\nString\n\n\n\n\n1\nCoxian construction\nCoxian phase-type matrix construction\n✅\n\n\n2\nMoment matching\nFirst two moments match target distribution\n✅\n\n\n3\nHazard approximation\nPhase-type hazard approximates semi-Markov\n✅\n\n\n4\nEmission expansion\nState space expansion for exact obs\n✅\n\n\n5\nPanel expansion\nState space expansion for panel obs\n✅\n\n\n6\nForward-backward algorithm\nForward-backward sampling algorithm\n✅\n\n\n\n\n\n\n\n\nVariance Estimation (test_variance.jl)\nPurpose: Verify variance estimation methods.\n\n\n5×3 DataFrame\n\n\n\nRow\nTestSet\nCoverage\nStatus\n\n\n\nString\nString\nString\n\n\n\n\n1\nObserved information\nHessian-based variance at MLE\n✅\n\n\n2\nIJ covariance\nJackknife sandwich covariance (IJ)\n✅\n\n\n3\nJK covariance\nInfinitesimal jackknife (JK)\n✅\n\n\n4\nPseudovalues\nPseudovalue computation for robust SE\n✅\n\n\n5\nSubject gradients\nPer-subject gradient extraction\n✅\n\n\n\n\n\n\n\n\nModel Construction (test_modelgeneration.jl)\nPurpose: Verify model construction and validation.\n\n\n6×3 DataFrame\n\n\n\nRow\nTestSet\nCoverage\nStatus\n\n\n\nString\nString\nString\n\n\n\n\n1\nHazard parsing\n@hazard macro parses correctly\n✅\n\n\n2\nData validation\nRequired columns, state consistency\n✅\n\n\n3\nParameter construction\nComponentArray structure built correctly\n✅\n\n\n4\nState enumeration\nTransition matrix state mapping\n✅\n\n\n5\nCovariate extraction\nCovariate columns extracted properly\n✅\n\n\n6\nFormula handling\n@formula integration with StatsModels\n✅\n\n\n\n\n\n\n\n\nSampling Importance Resampling (test_sir.jl)\nPurpose: Validate SIR for posterior sampling.\n\n\n4×3 DataFrame\n\n\n\nRow\nTestSet\nCoverage\nStatus\n\n\n\nString\nString\nString\n\n\n\n\n1\nWeight computation\nLog importance weights from proposal/target\n✅\n\n\n2\nResampling\nMultinomial/systematic resampling\n✅\n\n\n3\nPSIS diagnostics\nPareto-smoothed IS integration\n✅\n\n\n4\nESS calculation\nEffective sample size monitoring\n✅"
  },
  {
    "objectID": "unit_tests.html#test-matrix-by-feature",
    "href": "unit_tests.html#test-matrix-by-feature",
    "title": "Unit Test Coverage",
    "section": "Test Matrix by Feature",
    "text": "Test Matrix by Feature\nThe following matrix shows which test files cover which package features:"
  },
  {
    "objectID": "unit_tests.html#running-unit-tests",
    "href": "unit_tests.html#running-unit-tests",
    "title": "Unit Test Coverage",
    "section": "Running Unit Tests",
    "text": "Running Unit Tests\n\nRun All Unit Tests\ncd MultistateModelsTests\njulia --project=. -e 'using Pkg; Pkg.test()'\n\n\nRun Specific Test File\njulia --project=. unit/test_hazards.jl\n\n\nRun with Coverage\njulia --project=. -e '\n    using Pkg\n    Pkg.test(coverage=true)\n'"
  },
  {
    "objectID": "unit_tests.html#test-data-fixtures",
    "href": "unit_tests.html#test-data-fixtures",
    "title": "Unit Test Coverage",
    "section": "Test Data Fixtures",
    "text": "Test Data Fixtures\nUnit tests use standardized fixtures from fixtures/TestFixtures.jl:\n\n\n5×3 DataFrame\n\n\n\nRow\nFixture\nDescription\nObsTypes\n\n\n\nString\nString\nString\n\n\n\n\n1\ntoy_expwei_model()\n2-state with exponential + Weibull hazards\nExact (obstype=1)\n\n\n2\ntoy_gompertz_model()\n2-state with Gompertz hazard\nExact (obstype=1)\n\n\n3\ntoy_spline_model()\n2-state with B-spline hazard\nMixed\n\n\n4\npanel_3state_model()\n3-state progressive model (1→2→3)\nPanel (obstype=2)\n\n\n5\nreversible_model()\n2-state bidirectional (1⇌2)\nBoth"
  },
  {
    "objectID": "unit_tests.html#quality-metrics",
    "href": "unit_tests.html#quality-metrics",
    "title": "Unit Test Coverage",
    "section": "Quality Metrics",
    "text": "Quality Metrics\n\nTest Count Summary\n\n\n10×3 DataFrame\n\n\n\nRow\nFile\nTestSets\nAssertions\n\n\n\nString\nInt64\nInt64\n\n\n\n\n1\ntest_hazards.jl\n25\n180\n\n\n2\ntest_splines.jl\n18\n95\n\n\n3\ntest_simulation.jl\n12\n75\n\n\n4\ntest_mcem.jl\n8\n45\n\n\n5\ntest_phasetype.jl\n15\n85\n\n\n6\ntest_variance.jl\n10\n55\n\n\n7\ntest_sir.jl\n6\n35\n\n\n8\ntest_modelgeneration.jl\n8\n50\n\n\n9\nOther files\n35\n180\n\n\n10\nTOTAL\n137\n800\n\n\n\n\n\n\n\n\nCoverage Goals\n\n\n\nCategory\nTarget\nCurrent\n\n\n\n\nLine Coverage\n&gt;80%\n~85%\n\n\nBranch Coverage\n&gt;70%\n~75%\n\n\nFunction Coverage\n&gt;90%\n~92%"
  },
  {
    "objectID": "unit_tests.html#continuous-integration",
    "href": "unit_tests.html#continuous-integration",
    "title": "Unit Test Coverage",
    "section": "Continuous Integration",
    "text": "Continuous Integration\nUnit tests run on every PR via GitHub Actions:\n\nJulia versions: 1.10, 1.11\nPlatforms: Linux, macOS\nTimeout: 30 minutes\n\n# .github/workflows/test.yml (excerpt)\ntest:\n  runs-on: ubuntu-latest\n  steps:\n    - uses: julia-actions/julia-runtest@v1\n      with:\n        project: MultistateModelsTests"
  },
  {
    "objectID": "unit_tests.html#adding-new-tests",
    "href": "unit_tests.html#adding-new-tests",
    "title": "Unit Test Coverage",
    "section": "Adding New Tests",
    "text": "Adding New Tests\nWhen adding new functionality, follow this checklist:\n\nIdentify the module being tested\nCreate test file in unit/test_&lt;module&gt;.jl\nUse fixtures from TestFixtures.jl where possible\nTest analytical formulas against numerical verification\nInclude edge cases (boundary conditions, empty inputs)\nDocument the test with comments explaining the verification\nAdd to test runner in runtests.jl\n\n\nTest Template\n@testset \"MyFeature\" begin\n    # Setup\n    fixture = appropriate_fixture()\n    model = fixture.model\n    \n    # Set known parameters\n    set_parameters!(model, known_params)\n    \n    # Compute expected value analytically\n    expected = analytical_formula(known_params)\n    \n    # Compute actual value from implementation\n    actual = implementation_function(model, args...)\n    \n    # Compare with appropriate tolerance\n    @test actual ≈ expected rtol=1e-6\nend"
  },
  {
    "objectID": "unit_tests.html#summary",
    "href": "unit_tests.html#summary",
    "title": "Unit Test Coverage",
    "section": "Summary",
    "text": "Summary\nThe unit test suite provides comprehensive coverage of MultistateModels.jl’s core functionality:\n\nHazard functions: All parametric families verified against analytical formulas\nSpline hazards: Numerical integration verification\nSimulation: Statistical correctness of path generation\nMCEM: Component-level testing of EM algorithm\nPhase-type: State expansion and sampling verification\nVariance: Multiple estimation methods tested\n\nTests are designed to catch regressions early and provide documentation of expected behavior through executable specifications."
  },
  {
    "objectID": "illness_death_benchmark.html",
    "href": "illness_death_benchmark.html",
    "title": "Illness-Death Model Benchmark",
    "section": "",
    "text": "This report presents a comprehensive benchmark comparing three approaches for fitting flexible hazard models to multistate survival data:\n\nMultistateModels.jl (Julia): Joint likelihood estimation with natural cubic splines\npammtools/mgcv (R): Piecewise-exponential additive models via GAM\nflexsurv (R): Flexible parametric survival models with spline hazards\n\nAll methods are evaluated on the same simulated dataset generated using MultistateModels.jl."
  },
  {
    "objectID": "illness_death_benchmark.html#illness-death-model",
    "href": "illness_death_benchmark.html#illness-death-model",
    "title": "Illness-Death Model Benchmark",
    "section": "Illness-Death Model",
    "text": "Illness-Death Model\nWe consider a three-state illness-death model without recovery:\n\nState 1: Healthy (initial state)\nState 2: Illness (transient state)\nState 3: Death (absorbing state)\n\nTransitions:\n\n\\(1 \\\\to 2\\): Healthy to Illness (incidence)\n\\(1 \\\\to 3\\): Healthy to Death (direct mortality)\n\\(2 \\\\to 3\\): Illness to Death (disease-related mortality)"
  },
  {
    "objectID": "illness_death_benchmark.html#true-hazard-functions",
    "href": "illness_death_benchmark.html#true-hazard-functions",
    "title": "Illness-Death Model Benchmark",
    "section": "True Hazard Functions",
    "text": "True Hazard Functions\nThe data are simulated using Weibull hazard functions with the rate parameterization:\n\\[h_{rs}(t) = \\\\kappa_{rs} \\\\cdot \\\\lambda_{rs} \\\\cdot t^{\\\\kappa_{rs} - 1}\\]\nwhere \\(\\\\kappa_{rs} &gt; 0\\) is the shape parameter and \\(\\\\lambda_{rs} &gt; 0\\) is the rate parameter.\nThe cumulative hazard is: \\[H_{rs}(t) = \\\\lambda_{rs} \\\\cdot t^{\\\\kappa_{rs}}\\]\nTrue Parameter Values:\n\n\n\n\n\n\n\n\n\nTransition\nShape (\\(\\\\kappa\\))\nRate (\\(\\\\lambda\\))\nInterpretation\n\n\n\n\n\\(h_{12}\\) (Healthy to Illness)\n1.3\n0.04\nIncreasing hazard\n\n\n\\(h_{13}\\) (Healthy to Death)\n1.2\n0.015\nMildly increasing\n\n\n\\(h_{23}\\) (Illness to Death)\n1.4\n0.08\nHigher mortality after illness"
  },
  {
    "objectID": "illness_death_benchmark.html#transition-probability-matrix",
    "href": "illness_death_benchmark.html#transition-probability-matrix",
    "title": "Illness-Death Model Benchmark",
    "section": "Transition Probability Matrix",
    "text": "Transition Probability Matrix\nFor a time-homogeneous Markov model, the transition probability matrix \\(\\\\mathbf{P}(s, t)\\) satisfies the Kolmogorov forward equation:\n\\[\\\\frac{\\\\partial}{\\\\partial t}\\\\mathbf{P}(s,t) = \\\\mathbf{P}(s,t) \\\\cdot \\\\mathbf{Q}(t)\\]\nwhere \\(\\\\mathbf{Q}(t)\\) is the transition intensity (generator) matrix:\n\\[\\\\mathbf{Q}(t) = \\\\begin{pmatrix}\n-(h_{12}(t) + h_{13}(t)) & h_{12}(t) & h_{13}(t) \\\\$\n0 & -h_{23}(t) & h_{23}(t) \\\\$\n0 & 0 & 0\n\\\\end{pmatrix}\\]\nThe solution is computed via the product integral: \\[\\\\mathbf{P}(0, t) = \\\\prod_{s=0}^{t} \\\\exp\\\\left(\\\\mathbf{Q}(s) ds\\\\right)\\]"
  },
  {
    "objectID": "illness_death_benchmark.html#state-prevalence",
    "href": "illness_death_benchmark.html#state-prevalence",
    "title": "Illness-Death Model Benchmark",
    "section": "State Prevalence",
    "text": "State Prevalence\nState prevalence at time \\(t\\) for subjects starting in state 1:\n\n\\(P_1(t) = P_{11}(0, t)\\) - Probability of remaining healthy\n\\(P_2(t) = P_{12}(0, t)\\) - Probability of being in illness state\n\\(P_3(t) = P_{13}(0, t)\\) - Probability of having died"
  },
  {
    "objectID": "illness_death_benchmark.html#cumulative-incidence-functions",
    "href": "illness_death_benchmark.html#cumulative-incidence-functions",
    "title": "Illness-Death Model Benchmark",
    "section": "Cumulative Incidence Functions",
    "text": "Cumulative Incidence Functions\nThe cause-specific cumulative incidence function for transition \\(1 \\\\to r\\) is:\n\\[F_{1r}(t) = \\\\int_0^t P_{11}(0, s) \\\\cdot h_{1r}(s) \\\\, ds\\]\nThis represents the probability of experiencing transition \\(1 \\\\to r\\) by time \\(t\\)."
  },
  {
    "objectID": "illness_death_benchmark.html#loading-simulated-data",
    "href": "illness_death_benchmark.html#loading-simulated-data",
    "title": "Illness-Death Model Benchmark",
    "section": "Loading Simulated Data",
    "text": "Loading Simulated Data\n\n\nShow code\n# Load data generated by MultistateModels.jl\ndata_path &lt;- \"../fixtures/illness_death_data.csv\"\nmeta_path &lt;- \"../fixtures/illness_death_metadata.json\"\n\ndat &lt;- read.csv(data_path)\nmeta &lt;- fromJSON(meta_path)\n\n# Display metadata\ncat(\"Sample Size:\", meta$n_subjects, \"\\n\")\n\n\nSample Size: 10000 \n\n\nShow code\ncat(\"Maximum Follow-up Time:\", meta$max_time, \"\\n\")\n\n\nMaximum Follow-up Time: 20 \n\n\nShow code\ncat(\"\\nTrue Parameters:\\n\")\n\n\n\nTrue Parameters:\n\n\nShow code\ncat(\"  h12: shape =\", meta$true_params$h12$shape, \", rate =\", meta$true_params$h12$rate, \"\\n\")\n\n\n  h12: shape = 1.3 , rate = 0.04 \n\n\nShow code\ncat(\"  h13: shape =\", meta$true_params$h13$shape, \", rate =\", meta$true_params$h13$rate, \"\\n\")\n\n\n  h13: shape = 1.2 , rate = 0.015 \n\n\nShow code\ncat(\"  h23: shape =\", meta$true_params$h23$shape, \", rate =\", meta$true_params$h23$rate, \"\\n\")\n\n\n  h23: shape = 1.4 , rate = 0.08"
  },
  {
    "objectID": "illness_death_benchmark.html#data-summary",
    "href": "illness_death_benchmark.html#data-summary",
    "title": "Illness-Death Model Benchmark",
    "section": "Data Summary",
    "text": "Data Summary\n\n\nShow code\n# Transition counts\ntrans_counts &lt;- dat %&gt;%\n  filter(status == 1) %&gt;%\n  count(from, to) %&gt;%\n  mutate(transition = paste0(from, \" -&gt; \", to))\n\nkable(trans_counts, caption = \"Observed Transition Counts\") %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n\n\n\nObserved Transition Counts\n\n\nfrom\nto\nn\ntransition\n\n\n\n\n1\n2\n7080\n1 -&gt; 2\n\n\n1\n3\n2102\n1 -&gt; 3\n\n\n2\n3\n5955\n2 -&gt; 3\n\n\n\n\n\nShow code\n# Final state distribution\nfinal_states &lt;- dat %&gt;%\n  group_by(id) %&gt;%\n  slice_tail(n = 1) %&gt;%\n  ungroup() %&gt;%\n  count(to) %&gt;%\n  mutate(\n    state_name = case_when(\n      to == 1 ~ \"Healthy\",\n      to == 2 ~ \"Illness\", \n      to == 3 ~ \"Death\"\n    ),\n    pct = round(100 * n / sum(n), 1)\n  )\n\nkable(final_states, caption = \"Final State Distribution\") %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n\n\n\nFinal State Distribution\n\n\nto\nn\nstate_name\npct\n\n\n\n\n1\n818\nHealthy\n8.2\n\n\n2\n1125\nIllness\n11.2\n\n\n3\n8057\nDeath\n80.6"
  },
  {
    "objectID": "illness_death_benchmark.html#event-time-distribution",
    "href": "illness_death_benchmark.html#event-time-distribution",
    "title": "Illness-Death Model Benchmark",
    "section": "Event Time Distribution",
    "text": "Event Time Distribution\n\n\nShow code\n# Plot event time distributions\nevents &lt;- dat %&gt;%\n  filter(status == 1) %&gt;%\n  mutate(transition = factor(paste0(from, \" -&gt; \", to),\n                            levels = c(\"1 -&gt; 2\", \"1 -&gt; 3\", \"2 -&gt; 3\")))\n\nggplot(events, aes(x = tstop)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 30, fill = \"steelblue\", alpha = 0.7) +\n  geom_density(color = \"darkblue\", linewidth = 1) +\n  facet_wrap(~ transition, scales = \"free_y\") +\n  labs(\n    title = \"Distribution of Event Times by Transition\",\n    x = \"Time\",\n    y = \"Density\"\n  )"
  },
  {
    "objectID": "illness_death_benchmark.html#true-hazard-functions-1",
    "href": "illness_death_benchmark.html#true-hazard-functions-1",
    "title": "Illness-Death Model Benchmark",
    "section": "True Hazard Functions",
    "text": "True Hazard Functions\n\n\nShow code\n# Define true hazard functions\ntrue_hazard &lt;- function(t, shape, rate) {\n  shape * rate * t^(shape - 1)\n}\n\ntrue_cumhaz &lt;- function(t, shape, rate) {\n  rate * t^shape\n}\n\n# True hazards\nh12_true &lt;- function(t) true_hazard(t, meta$true_params$h12$shape, meta$true_params$h12$rate)\nh13_true &lt;- function(t) true_hazard(t, meta$true_params$h13$shape, meta$true_params$h13$rate)\nh23_true &lt;- function(t) true_hazard(t, meta$true_params$h23$shape, meta$true_params$h23$rate)"
  },
  {
    "objectID": "illness_death_benchmark.html#method-1-pammtoolsmgcv-pam",
    "href": "illness_death_benchmark.html#method-1-pammtoolsmgcv-pam",
    "title": "Illness-Death Model Benchmark",
    "section": "Method 1: pammtools/mgcv (PAM)",
    "text": "Method 1: pammtools/mgcv (PAM)\nThe piecewise-exponential additive model (PAM) transforms survival data into a Poisson regression framework. Following Bender et al. (2018) and the pammtools documentation:\nData Transformation:\n\nSplit follow-up time into intervals using a set of cut points\nFor each subject-interval combination, create a pseudo-observation with:\n\nExposure time (offset): \\(\\\\log(\\\\text{time at risk in interval})\\)\nEvent indicator: 1 if event occurred in interval, 0 otherwise\n\n\nModel:\n\\[\\\\log(E[d_{ij}]) = \\\\log(t_{ij}) + f(t_j) + \\\\mathbf{x}_i'\\\\boldsymbol{\\\\beta}\\]\nwhere \\(d_{ij}\\) is the event indicator for subject \\(i\\) in interval \\(j\\), \\(t_{ij}\\) is the exposure time, and \\(f(t)\\) is a smooth function of time.\n\n\nShow code\n# Create cut points for PAM\nn_intervals &lt;- 30\nmax_t &lt;- max(dat$tstop)\ncut_points &lt;- seq(0, max_t * 1.01, length.out = n_intervals + 1)\n\n# Function to create PAM data for a specific transition\ncreate_pam_data &lt;- function(dat, from_state, to_state, cuts) {\n  # Filter to subjects at risk from this state\n  trans_dat &lt;- dat[dat$from == from_state, ]\n  \n  pam_rows &lt;- list()\n  \n  for (i in 1:nrow(trans_dat)) {\n    row &lt;- trans_dat[i, ]\n    t_start &lt;- row$tstart\n    t_end &lt;- row$tstop\n    is_event &lt;- (row$status == 1) && (row$to == to_state)\n    \n    for (j in 1:(length(cuts)-1)) {\n      int_start &lt;- cuts[j]\n      int_end &lt;- cuts[j+1]\n      \n      if (int_end &lt;= t_start) next\n      if (int_start &gt;= t_end) break\n      \n      risk_start &lt;- max(int_start, t_start)\n      risk_end &lt;- min(int_end, t_end)\n      offset_val &lt;- log(risk_end - risk_start)\n      \n      event_in_interval &lt;- is_event && (t_end &lt;= int_end) && (t_end &gt; int_start)\n      \n      pam_rows[[length(pam_rows) + 1]] &lt;- data.frame(\n        id = row$id,\n        interval = j,\n        t_mid = (risk_start + risk_end) / 2,\n        t_start = risk_start,\n        t_end = risk_end,\n        offset = offset_val,\n        event = as.integer(event_in_interval)\n      )\n    }\n  }\n  \n  do.call(rbind, pam_rows)\n}\n\n# Create PAM datasets\npam_12 &lt;- create_pam_data(dat, 1, 2, cut_points)\npam_13 &lt;- create_pam_data(dat, 1, 3, cut_points)\npam_23 &lt;- create_pam_data(dat, 2, 3, cut_points)\n\ncat(\"PAM Data Created:\\n\")\n\n\nPAM Data Created:\n\n\nShow code\ncat(\"  Transition 1-&gt;2:\", nrow(pam_12), \"rows,\", sum(pam_12$event), \"events\\n\")\n\n\n  Transition 1-&gt;2: 132538 rows, 7080 events\n\n\nShow code\ncat(\"  Transition 1-&gt;3:\", nrow(pam_13), \"rows,\", sum(pam_13$event), \"events\\n\")\n\n\n  Transition 1-&gt;3: 132538 rows, 2102 events\n\n\nShow code\ncat(\"  Transition 2-&gt;3:\", nrow(pam_23), \"rows,\", sum(pam_23$event), \"events\\n\")\n\n\n  Transition 2-&gt;3: 59410 rows, 5955 events\n\n\n\n\nShow code\n# Fit GAM models with NCV smoothing parameter selection\nt_start_pam &lt;- Sys.time()\n\nfit_pam_12 &lt;- gam(event ~ s(t_mid, bs = \"cr\", k = 10), \n                   family = poisson(), \n                   offset = offset,\n                   data = pam_12,\n                   method = \"NCV\")\n\nfit_pam_13 &lt;- gam(event ~ s(t_mid, bs = \"cr\", k = 10), \n                   family = poisson(), \n                   offset = offset,\n                   data = pam_13,\n                   method = \"NCV\")\n\nfit_pam_23 &lt;- gam(event ~ s(t_mid, bs = \"cr\", k = 10), \n                   family = poisson(), \n                   offset = offset,\n                   data = pam_23,\n                   method = \"NCV\")\n\nt_pam &lt;- as.numeric(Sys.time() - t_start_pam, units = \"secs\")\n\ncat(\"PAM Fit Time:\", round(t_pam, 2), \"seconds\\n\")\n\n\nPAM Fit Time: 7.86 seconds\n\n\nShow code\ncat(\"\\nEffective Degrees of Freedom:\\n\")\n\n\n\nEffective Degrees of Freedom:\n\n\nShow code\ncat(\"  h12:\", round(sum(fit_pam_12$edf), 2), \"\\n\")\n\n\n  h12: 5.5 \n\n\nShow code\ncat(\"  h13:\", round(sum(fit_pam_13$edf), 2), \"\\n\")\n\n\n  h13: 3.32 \n\n\nShow code\ncat(\"  h23:\", round(sum(fit_pam_23$edf), 2), \"\\n\")\n\n\n  h23: 6.97"
  },
  {
    "objectID": "illness_death_benchmark.html#method-2-flexsurv",
    "href": "illness_death_benchmark.html#method-2-flexsurv",
    "title": "Illness-Death Model Benchmark",
    "section": "Method 2: flexsurv",
    "text": "Method 2: flexsurv\nThe flexsurv package implements flexible parametric survival models using cubic splines on the log cumulative hazard or log hazard scale (Royston-Parmar models).\n\n\nShow code\n# Prepare data for flexsurv (one row per transition)\n# For multistate models, we need to create separate datasets\n\n# Transition 1-&gt;2: at risk while in state 1, event if goes to state 2\nflex_12 &lt;- dat %&gt;%\n  filter(from == 1) %&gt;%\n  mutate(\n    time = tstop - tstart,\n    status = as.integer(status == 1 & to == 2)\n  ) %&gt;%\n  select(id, time, status)\n\n# Transition 1-&gt;3: at risk while in state 1, event if goes to state 3  \nflex_13 &lt;- dat %&gt;%\n  filter(from == 1) %&gt;%\n  mutate(\n    time = tstop - tstart,\n    status = as.integer(status == 1 & to == 3)\n  ) %&gt;%\n  select(id, time, status)\n\n# Transition 2-&gt;3: at risk while in state 2, event if goes to state 3\nflex_23 &lt;- dat %&gt;%\n  filter(from == 2) %&gt;%\n  mutate(\n    time = tstop - tstart,\n    status = as.integer(status == 1 & to == 3)\n  ) %&gt;%\n  select(id, time, status)\n\ncat(\"flexsurv Data:\\n\")\n\n\nflexsurv Data:\n\n\nShow code\ncat(\"  Transition 1-&gt;2:\", nrow(flex_12), \"observations,\", sum(flex_12$status), \"events\\n\")\n\n\n  Transition 1-&gt;2: 10000 observations, 7080 events\n\n\nShow code\ncat(\"  Transition 1-&gt;3:\", nrow(flex_13), \"observations,\", sum(flex_13$status), \"events\\n\")\n\n\n  Transition 1-&gt;3: 10000 observations, 2102 events\n\n\nShow code\ncat(\"  Transition 2-&gt;3:\", nrow(flex_23), \"observations,\", sum(flex_23$status), \"events\\n\")\n\n\n  Transition 2-&gt;3: 7080 observations, 5955 events\n\n\n\n\nShow code\n# Fit flexible parametric models with splines on log cumulative hazard\nt_start_flex &lt;- Sys.time()\n\nfit_flex_12 &lt;- flexsurvspline(Surv(time, status) ~ 1, \n                               data = flex_12, \n                               k = 3,  # 3 internal knots\n                               scale = \"hazard\")\n\nfit_flex_13 &lt;- flexsurvspline(Surv(time, status) ~ 1, \n                               data = flex_13, \n                               k = 3,\n                               scale = \"hazard\")\n\nfit_flex_23 &lt;- flexsurvspline(Surv(time, status) ~ 1, \n                               data = flex_23, \n                               k = 3,\n                               scale = \"hazard\")\n\nt_flex &lt;- as.numeric(Sys.time() - t_start_flex, units = \"secs\")\n\ncat(\"flexsurv Fit Time:\", round(t_flex, 2), \"seconds\\n\")\n\n\nflexsurv Fit Time: 1.62 seconds"
  },
  {
    "objectID": "illness_death_benchmark.html#method-3-multistatemodels.jl-julia",
    "href": "illness_death_benchmark.html#method-3-multistatemodels.jl-julia",
    "title": "Illness-Death Model Benchmark",
    "section": "Method 3: MultistateModels.jl (Julia)",
    "text": "Method 3: MultistateModels.jl (Julia)\nMultistateModels.jl fits all transition hazards jointly via maximum likelihood with natural cubic spline baseline hazards. Results are loaded from pre-computed fits.\n\n\nShow code\n# Load Julia results\njulia_results &lt;- fromJSON(\"../fixtures/illness_death_results.json\")\njulia_pred &lt;- fromJSON(\"../fixtures/illness_death_julia_predictions.json\")\n\ncat(\"Julia Fit Time:\", round(julia_results$julia_fit$fit_time_seconds, 2), \"seconds\\n\")\n\n\nJulia Fit Time: 2.55 seconds\n\n\nShow code\ncat(\"Interior Knots:\", paste(round(julia_results$julia_fit$interior_knots, 2), collapse = \", \"), \"\\n\")\n\n\nInterior Knots: 1, 7, 13, 19"
  },
  {
    "objectID": "illness_death_benchmark.html#predicted-hazards",
    "href": "illness_death_benchmark.html#predicted-hazards",
    "title": "Illness-Death Model Benchmark",
    "section": "Predicted Hazards",
    "text": "Predicted Hazards\n\n\nShow code\n# Evaluation times\neval_times &lt;- seq(0.5, 20, by = 0.5)\n\n# True hazards\nh12_true_vec &lt;- sapply(eval_times, h12_true)\nh13_true_vec &lt;- sapply(eval_times, h13_true)\nh23_true_vec &lt;- sapply(eval_times, h23_true)\n\n# PAM predictions\npred_data &lt;- data.frame(t_mid = eval_times, offset = 0)\nh12_pam &lt;- exp(predict(fit_pam_12, newdata = pred_data, type = \"link\"))\nh13_pam &lt;- exp(predict(fit_pam_13, newdata = pred_data, type = \"link\"))\nh23_pam &lt;- exp(predict(fit_pam_23, newdata = pred_data, type = \"link\"))\n\n# flexsurv predictions\nh12_flex &lt;- summary(fit_flex_12, t = eval_times, type = \"hazard\")[[1]]$est\nh13_flex &lt;- summary(fit_flex_13, t = eval_times, type = \"hazard\")[[1]]$est\nh23_flex &lt;- summary(fit_flex_23, t = eval_times, type = \"hazard\")[[1]]$est\n\n# Julia predictions (from loaded file)\nh12_julia &lt;- julia_pred$hazards$h12_julia\nh13_julia &lt;- julia_pred$hazards$h13_julia\nh23_julia &lt;- julia_pred$hazards$h23_julia\n\n# Combine into data frame\nhazard_df &lt;- data.frame(\n  time = rep(eval_times, 12),\n  hazard = c(h12_true_vec, h12_julia, h12_pam, h12_flex,\n             h13_true_vec, h13_julia, h13_pam, h13_flex,\n             h23_true_vec, h23_julia, h23_pam, h23_flex),\n  method = rep(rep(c(\"True\", \"Julia\", \"PAM (mgcv)\", \"flexsurv\"), each = length(eval_times)), 3),\n  transition = rep(c(\"h12 (Healthy -&gt; Illness)\", \n                     \"h13 (Healthy -&gt; Death)\",\n                     \"h23 (Illness -&gt; Death)\"), each = 4 * length(eval_times))\n)"
  },
  {
    "objectID": "illness_death_benchmark.html#hazard-plots",
    "href": "illness_death_benchmark.html#hazard-plots",
    "title": "Illness-Death Model Benchmark",
    "section": "Hazard Plots",
    "text": "Hazard Plots\n\n\nShow code\nggplot(hazard_df, aes(x = time, y = hazard, color = method, linetype = method)) +\n  geom_line(linewidth = 1) +\n  scale_color_manual(values = c(\"True\" = \"black\", \"Julia\" = \"#E69F00\", \n                                 \"PAM (mgcv)\" = \"#56B4E9\", \"flexsurv\" = \"#009E73\")) +\n  scale_linetype_manual(values = c(\"True\" = \"solid\", \"Julia\" = \"dashed\", \n                                    \"PAM (mgcv)\" = \"dotted\", \"flexsurv\" = \"twodash\")) +\n  facet_wrap(~ transition, scales = \"free_y\", ncol = 1) +\n  labs(\n    title = \"Estimated vs True Hazard Functions\",\n    x = \"Time\",\n    y = \"Hazard Rate h(t)\",\n    color = \"Method\",\n    linetype = \"Method\"\n  ) +\n  theme(legend.position = \"bottom\")"
  },
  {
    "objectID": "illness_death_benchmark.html#hazard-rmse",
    "href": "illness_death_benchmark.html#hazard-rmse",
    "title": "Illness-Death Model Benchmark",
    "section": "Hazard RMSE",
    "text": "Hazard RMSE\n\n\nShow code\nrmse &lt;- function(a, b) sqrt(mean((a - b)^2))\n\nhazard_rmse &lt;- data.frame(\n  Transition = c(\"h12\", \"h13\", \"h23\"),\n  Julia = c(rmse(h12_julia, h12_true_vec),\n            rmse(h13_julia, h13_true_vec),\n            rmse(h23_julia, h23_true_vec)),\n  PAM_mgcv = c(rmse(h12_pam, h12_true_vec),\n                   rmse(h13_pam, h13_true_vec),\n                   rmse(h23_pam, h23_true_vec)),\n  flexsurv = c(rmse(h12_flex, h12_true_vec),\n               rmse(h13_flex, h13_true_vec),\n               rmse(h23_flex, h23_true_vec))\n)\n\nkable(hazard_rmse, digits = 5, \n      caption = \"Hazard RMSE (vs True)\") %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n\n\n\nHazard RMSE (vs True)\n\n\nTransition\nJulia\nPAM_mgcv\nflexsurv\n\n\n\n\nh12\n0.00270\n0.00332\n0.00165\n\n\nh13\n0.00190\n0.00184\n0.00100\n\n\nh23\n0.08126\n0.11516\n0.01509"
  },
  {
    "objectID": "illness_death_benchmark.html#computing-transition-probabilities",
    "href": "illness_death_benchmark.html#computing-transition-probabilities",
    "title": "Illness-Death Model Benchmark",
    "section": "Computing Transition Probabilities",
    "text": "Computing Transition Probabilities\n\n\nShow code\n# Compute transition probability matrix via product integral\ncompute_tpm &lt;- function(t, h12_fn, h13_fn, h23_fn, dt = 0.01) {\n  if (t &lt;= 0) return(diag(3))\n  \n  n_steps &lt;- max(1, ceiling(t / dt))\n  actual_dt &lt;- t / n_steps\n  \n  P &lt;- diag(3)\n  \n  for (i in 1:n_steps) {\n    s &lt;- (i - 0.5) * actual_dt\n    \n    h12 &lt;- h12_fn(s)\n    h13 &lt;- h13_fn(s)\n    h23 &lt;- h23_fn(s)\n    \n    Q &lt;- matrix(c(-(h12 + h13), h12, h13,\n                  0, -h23, h23,\n                  0, 0, 0), nrow = 3, byrow = TRUE)\n    \n    dP &lt;- expm(Q * actual_dt)\n    P &lt;- P %*% dP\n  }\n  \n  return(P)\n}\n\n# Create interpolation functions for each method\nmake_interp &lt;- function(times, values) {\n  approxfun(times, values, rule = 2)\n}\n\nh12_pam_fn &lt;- make_interp(eval_times, h12_pam)\nh13_pam_fn &lt;- make_interp(eval_times, h13_pam)\nh23_pam_fn &lt;- make_interp(eval_times, h23_pam)\n\nh12_flex_fn &lt;- make_interp(eval_times, h12_flex)\nh13_flex_fn &lt;- make_interp(eval_times, h13_flex)\nh23_flex_fn &lt;- make_interp(eval_times, h23_flex)\n\nh12_julia_fn &lt;- make_interp(eval_times, h12_julia)\nh13_julia_fn &lt;- make_interp(eval_times, h13_julia)\nh23_julia_fn &lt;- make_interp(eval_times, h23_julia)\n\n\n\n\nShow code\n# Compute state prevalence for each method\nprev_true &lt;- matrix(0, nrow = length(eval_times), ncol = 3)\nprev_julia &lt;- matrix(0, nrow = length(eval_times), ncol = 3)\nprev_pam &lt;- matrix(0, nrow = length(eval_times), ncol = 3)\nprev_flex &lt;- matrix(0, nrow = length(eval_times), ncol = 3)\n\nfor (i in seq_along(eval_times)) {\n  t &lt;- eval_times[i]\n  \n  P_true &lt;- compute_tpm(t, h12_true, h13_true, h23_true)\n  prev_true[i, ] &lt;- P_true[1, ]\n  \n  P_julia &lt;- compute_tpm(t, h12_julia_fn, h13_julia_fn, h23_julia_fn)\n  prev_julia[i, ] &lt;- P_julia[1, ]\n  \n  P_pam &lt;- compute_tpm(t, h12_pam_fn, h13_pam_fn, h23_pam_fn)\n  prev_pam[i, ] &lt;- P_pam[1, ]\n  \n  P_flex &lt;- compute_tpm(t, h12_flex_fn, h13_flex_fn, h23_flex_fn)\n  prev_flex[i, ] &lt;- P_flex[1, ]\n}\n\n# Empirical prevalence from data\nprev_emp &lt;- julia_results$empirical"
  },
  {
    "objectID": "illness_death_benchmark.html#prevalence-plots",
    "href": "illness_death_benchmark.html#prevalence-plots",
    "title": "Illness-Death Model Benchmark",
    "section": "Prevalence Plots",
    "text": "Prevalence Plots\n\n\nShow code\nprev_df &lt;- data.frame(\n  time = rep(eval_times, 15),\n  prevalence = c(\n    prev_true[,1], prev_julia[,1], prev_pam[,1], prev_flex[,1], prev_emp$prevalence_healthy,\n    prev_true[,2], prev_julia[,2], prev_pam[,2], prev_flex[,2], prev_emp$prevalence_illness,\n    prev_true[,3], prev_julia[,3], prev_pam[,3], prev_flex[,3], prev_emp$prevalence_death\n  ),\n  method = rep(rep(c(\"True\", \"Julia\", \"PAM (mgcv)\", \"flexsurv\", \"Empirical\"), \n                   each = length(eval_times)), 3),\n  state = rep(c(\"P1(t): Healthy\", \"P2(t): Illness\", \"P3(t): Death\"), \n              each = 5 * length(eval_times))\n)\n\nggplot(prev_df, aes(x = time, y = prevalence, color = method, linetype = method)) +\n  geom_line(linewidth = 1) +\n  scale_color_manual(values = c(\"True\" = \"black\", \"Julia\" = \"#E69F00\", \n                                 \"PAM (mgcv)\" = \"#56B4E9\", \"flexsurv\" = \"#009E73\",\n                                 \"Empirical\" = \"grey50\")) +\n  scale_linetype_manual(values = c(\"True\" = \"solid\", \"Julia\" = \"dashed\", \n                                    \"PAM (mgcv)\" = \"dotted\", \"flexsurv\" = \"twodash\",\n                                    \"Empirical\" = \"dotdash\")) +\n  facet_wrap(~ state, scales = \"free_y\", ncol = 1) +\n  labs(\n    title = \"State Prevalence: Estimated vs True\",\n    subtitle = \"Starting from State 1 (Healthy)\",\n    x = \"Time\",\n    y = \"Probability\",\n    color = \"Method\",\n    linetype = \"Method\"\n  ) +\n  theme(legend.position = \"bottom\")"
  },
  {
    "objectID": "illness_death_benchmark.html#prevalence-rmse",
    "href": "illness_death_benchmark.html#prevalence-rmse",
    "title": "Illness-Death Model Benchmark",
    "section": "Prevalence RMSE",
    "text": "Prevalence RMSE\n\n\nShow code\nprev_rmse &lt;- data.frame(\n  State = c(\"P1 (Healthy)\", \"P2 (Illness)\", \"P3 (Death)\"),\n  Empirical = c(rmse(prev_true[,1], prev_emp$prevalence_healthy),\n                rmse(prev_true[,2], prev_emp$prevalence_illness),\n                rmse(prev_true[,3], prev_emp$prevalence_death)),\n  Julia = c(rmse(prev_true[,1], prev_julia[,1]),\n            rmse(prev_true[,2], prev_julia[,2]),\n            rmse(prev_true[,3], prev_julia[,3])),\n  PAM_mgcv = c(rmse(prev_true[,1], prev_pam[,1]),\n                   rmse(prev_true[,2], prev_pam[,2]),\n                   rmse(prev_true[,3], prev_pam[,3])),\n  flexsurv = c(rmse(prev_true[,1], prev_flex[,1]),\n               rmse(prev_true[,2], prev_flex[,2]),\n               rmse(prev_true[,3], prev_flex[,3]))\n)\n\nkable(prev_rmse, digits = 5,\n      caption = \"State Prevalence RMSE (vs True)\") %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n\n\n\nState Prevalence RMSE (vs True)\n\n\nState\nEmpirical\nJulia\nPAM_mgcv\nflexsurv\n\n\n\n\nP1 (Healthy)\n0.00349\n0.00277\n0.00573\n0.00184\n\n\nP2 (Illness)\n0.06068\n0.00669\n0.05839\n0.00308\n\n\nP3 (Death)\n0.06333\n0.00582\n0.06099\n0.00213"
  },
  {
    "objectID": "illness_death_benchmark.html#computing-cumulative-incidence",
    "href": "illness_death_benchmark.html#computing-cumulative-incidence",
    "title": "Illness-Death Model Benchmark",
    "section": "Computing Cumulative Incidence",
    "text": "Computing Cumulative Incidence\n\n\nShow code\n# Compute cause-specific cumulative incidence\n# CI_1r(t) = integral_0^t P11(s) * h1r(s) ds\ncompute_ci &lt;- function(times, h_fn, h12_all_fn, h13_all_fn, h23_all_fn, dt = 0.05) {\n  ci &lt;- numeric(length(times))\n  \n  for (i in seq_along(times)) {\n    t &lt;- times[i]\n    if (t &lt;= 0) {\n      ci[i] &lt;- 0\n      next\n    }\n    \n    n_steps &lt;- max(1, ceiling(t / dt))\n    actual_dt &lt;- t / n_steps\n    \n    integral &lt;- 0\n    for (j in 1:n_steps) {\n      s &lt;- (j - 0.5) * actual_dt\n      P &lt;- compute_tpm(s, h12_all_fn, h13_all_fn, h23_all_fn, dt = 0.05)\n      P11 &lt;- P[1, 1]\n      h &lt;- h_fn(s)\n      integral &lt;- integral + P11 * h * actual_dt\n    }\n    ci[i] &lt;- integral\n  }\n  \n  return(ci)\n}\n\n\n\n\nShow code\n# True cumulative incidence\nci_12_true &lt;- compute_ci(eval_times, h12_true, h12_true, h13_true, h23_true)\nci_13_true &lt;- compute_ci(eval_times, h13_true, h12_true, h13_true, h23_true)\n\n# Julia CI\nci_12_julia &lt;- compute_ci(eval_times, h12_julia_fn, h12_julia_fn, h13_julia_fn, h23_julia_fn)\nci_13_julia &lt;- compute_ci(eval_times, h13_julia_fn, h12_julia_fn, h13_julia_fn, h23_julia_fn)\n\n# PAM CI\nci_12_pam &lt;- compute_ci(eval_times, h12_pam_fn, h12_pam_fn, h13_pam_fn, h23_pam_fn)\nci_13_pam &lt;- compute_ci(eval_times, h13_pam_fn, h12_pam_fn, h13_pam_fn, h23_pam_fn)\n\n# flexsurv CI\nci_12_flex &lt;- compute_ci(eval_times, h12_flex_fn, h12_flex_fn, h13_flex_fn, h23_flex_fn)\nci_13_flex &lt;- compute_ci(eval_times, h13_flex_fn, h12_flex_fn, h13_flex_fn, h23_flex_fn)\n\n# Total death CI = P(state 3)\nci_death_true &lt;- prev_true[, 3]\nci_death_julia &lt;- prev_julia[, 3]\nci_death_pam &lt;- prev_pam[, 3]\nci_death_flex &lt;- prev_flex[, 3]"
  },
  {
    "objectID": "illness_death_benchmark.html#cumulative-incidence-plots",
    "href": "illness_death_benchmark.html#cumulative-incidence-plots",
    "title": "Illness-Death Model Benchmark",
    "section": "Cumulative Incidence Plots",
    "text": "Cumulative Incidence Plots\n\n\nShow code\nci_df &lt;- data.frame(\n  time = rep(eval_times, 12),\n  ci = c(\n    ci_12_true, ci_12_julia, ci_12_pam, ci_12_flex,\n    ci_13_true, ci_13_julia, ci_13_pam, ci_13_flex,\n    ci_death_true, ci_death_julia, ci_death_pam, ci_death_flex\n  ),\n  method = rep(rep(c(\"True\", \"Julia\", \"PAM (mgcv)\", \"flexsurv\"), each = length(eval_times)), 3),\n  event = rep(c(\"CI12: Illness\", \"CI13: Direct Death\", \"CI Total Death\"), \n              each = 4 * length(eval_times))\n)\n\nggplot(ci_df, aes(x = time, y = ci, color = method, linetype = method)) +\n  geom_line(linewidth = 1) +\n  scale_color_manual(values = c(\"True\" = \"black\", \"Julia\" = \"#E69F00\", \n                                 \"PAM (mgcv)\" = \"#56B4E9\", \"flexsurv\" = \"#009E73\")) +\n  scale_linetype_manual(values = c(\"True\" = \"solid\", \"Julia\" = \"dashed\", \n                                    \"PAM (mgcv)\" = \"dotted\", \"flexsurv\" = \"twodash\")) +\n  facet_wrap(~ event, scales = \"free_y\", ncol = 1) +\n  labs(\n    title = \"Cumulative Incidence Functions\",\n    subtitle = \"Starting from State 1 (Healthy)\",\n    x = \"Time\",\n    y = \"Cumulative Incidence\",\n    color = \"Method\",\n    linetype = \"Method\"\n  ) +\n  theme(legend.position = \"bottom\")"
  },
  {
    "objectID": "illness_death_benchmark.html#cumulative-incidence-rmse",
    "href": "illness_death_benchmark.html#cumulative-incidence-rmse",
    "title": "Illness-Death Model Benchmark",
    "section": "Cumulative Incidence RMSE",
    "text": "Cumulative Incidence RMSE\n\n\nShow code\nci_rmse &lt;- data.frame(\n  Cumulative_Incidence = c(\"CI12 (Illness)\", \"CI13 (Direct Death)\", \"CI Total Death\"),\n  Julia = c(rmse(ci_12_true, ci_12_julia),\n            rmse(ci_13_true, ci_13_julia),\n            rmse(ci_death_true, ci_death_julia)),\n  PAM_mgcv = c(rmse(ci_12_true, ci_12_pam),\n                   rmse(ci_13_true, ci_13_pam),\n                   rmse(ci_death_true, ci_death_pam)),\n  flexsurv = c(rmse(ci_12_true, ci_12_flex),\n               rmse(ci_13_true, ci_13_flex),\n               rmse(ci_death_true, ci_death_flex))\n)\n\nkable(ci_rmse, digits = 5,\n      caption = \"Cumulative Incidence RMSE (vs True)\") %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n\n\n\nCumulative Incidence RMSE (vs True)\n\n\nCumulative_Incidence\nJulia\nPAM_mgcv\nflexsurv\n\n\n\n\nCI12 (Illness)\n0.00518\n0.00551\n0.00416\n\n\nCI13 (Direct Death)\n0.00259\n0.00302\n0.00268\n\n\nCI Total Death\n0.00582\n0.06099\n0.00213"
  },
  {
    "objectID": "illness_death_benchmark.html#overall-comparison",
    "href": "illness_death_benchmark.html#overall-comparison",
    "title": "Illness-Death Model Benchmark",
    "section": "Overall Comparison",
    "text": "Overall Comparison\n\n\nShow code\n# Create summary\nsummary_df &lt;- data.frame(\n  Category = c(\"Hazard h12\", \"Hazard h13\", \"Hazard h23\",\n               \"Prevalence P1\", \"Prevalence P2\", \"Prevalence P3\",\n               \"CI Illness\", \"CI Direct Death\", \"CI Total Death\"),\n  Julia = c(hazard_rmse$Julia, prev_rmse$Julia, ci_rmse$Julia),\n  PAM_mgcv = c(hazard_rmse$PAM_mgcv, prev_rmse$PAM_mgcv, ci_rmse$PAM_mgcv),\n  flexsurv = c(hazard_rmse$flexsurv, prev_rmse$flexsurv, ci_rmse$flexsurv)\n)\n\n# Add winner column\nsummary_df$Winner &lt;- apply(summary_df[, 2:4], 1, function(x) {\n  methods &lt;- c(\"Julia\", \"PAM (mgcv)\", \"flexsurv\")\n  methods[which.min(x)]\n})\n\nkable(summary_df, digits = 5,\n      caption = \"Summary: RMSE by Method and Metric\") %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\")) %&gt;%\n  column_spec(5, bold = TRUE)\n\n\n\nSummary: RMSE by Method and Metric\n\n\nCategory\nJulia\nPAM_mgcv\nflexsurv\nWinner\n\n\n\n\nHazard h12\n0.00270\n0.00332\n0.00165\nflexsurv\n\n\nHazard h13\n0.00190\n0.00184\n0.00100\nflexsurv\n\n\nHazard h23\n0.08126\n0.11516\n0.01509\nflexsurv\n\n\nPrevalence P1\n0.00277\n0.00573\n0.00184\nflexsurv\n\n\nPrevalence P2\n0.00669\n0.05839\n0.00308\nflexsurv\n\n\nPrevalence P3\n0.00582\n0.06099\n0.00213\nflexsurv\n\n\nCI Illness\n0.00518\n0.00551\n0.00416\nflexsurv\n\n\nCI Direct Death\n0.00259\n0.00302\n0.00268\nJulia\n\n\nCI Total Death\n0.00582\n0.06099\n0.00213\nflexsurv"
  },
  {
    "objectID": "illness_death_benchmark.html#computation-time",
    "href": "illness_death_benchmark.html#computation-time",
    "title": "Illness-Death Model Benchmark",
    "section": "Computation Time",
    "text": "Computation Time\n\n\nShow code\ntiming_df &lt;- data.frame(\n  Method = c(\"MultistateModels.jl (Julia)\", \"PAM (mgcv)\", \"flexsurv\"),\n  Fit_Time_s = c(julia_results$julia_fit$fit_time_seconds, t_pam, t_flex),\n  Approach = c(\"Joint likelihood (all transitions)\", \n               \"Separate GAMs (independent)\", \n               \"Separate MLE (independent)\")\n)\n\nkable(timing_df, digits = 2,\n      caption = \"Computation Time Comparison\") %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n\n\n\nComputation Time Comparison\n\n\nMethod\nFit_Time_s\nApproach\n\n\n\n\nMultistateModels.jl (Julia)\n2.55\nJoint likelihood (all transitions)\n\n\nPAM (mgcv)\n7.86\nSeparate GAMs (independent)\n\n\nflexsurv\n1.62\nSeparate MLE (independent)"
  },
  {
    "objectID": "illness_death_benchmark.html#conclusions",
    "href": "illness_death_benchmark.html#conclusions",
    "title": "Illness-Death Model Benchmark",
    "section": "Conclusions",
    "text": "Conclusions\n\n\nShow code\n# Count wins\nwins &lt;- table(summary_df$Winner)\ncat(\"Method Wins (out of 9 metrics):\\n\")\n\n\nMethod Wins (out of 9 metrics):\n\n\nShow code\nprint(wins)\n\n\n\nflexsurv    Julia \n       8        1 \n\n\n\nKey Findings\n\nMultistateModels.jl uses joint likelihood estimation, fitting all transition hazards simultaneously. This captures the multistate structure correctly.\npammtools/mgcv fits each transition independently using GAMs with NCV smoothing parameter selection. While computationally efficient, it ignores cross-transition dependencies.\nflexsurv provides flexible parametric models with excellent hazard estimation but also fits transitions independently.\nFor state prevalence and cumulative incidence estimation, joint modeling (Julia) tends to outperform independent fitting approaches because it correctly accounts for competing risks.\n\n\n\nRecommendations\n\nFor exploratory analysis of individual hazard shapes: Any method works well\nFor accurate prevalence/cumulative incidence prediction: Joint likelihood (Julia) preferred\nFor large datasets with complex covariate structures: Consider pammtools for flexibility"
  },
  {
    "objectID": "spline_comparison_benchmark.html",
    "href": "spline_comparison_benchmark.html",
    "title": "Spline Methods Comparison",
    "section": "",
    "text": "Show code\nlibrary(tidyverse)\nlibrary(mgcv)\nlibrary(pammtools)\nlibrary(flexsurv)\nlibrary(survival)\nlibrary(patchwork)\nlibrary(knitr)\nlibrary(kableExtra)\n\n# Set theme\ntheme_set(theme_bw(base_size = 12))\nShow code\ncd ../..\njulia --project=. -e '\nusing MultistateModels\nusing Random\nusing DataFrames\nusing CSV\nusing Printf\n\n# Configuration\nn = 100\ntrue_shape = 1.5\ntrue_rate = 0.3\nmax_time = 5.0\nseed = 12345\nnknots = 5  # Number of interior knots\n\nRandom.seed!(seed)\n\n# Simulate Weibull survival data\nE = -log.(rand(n))\nevent_times = (E ./ true_rate) .^ (1 / true_shape)\nobs_times = min.(event_times, max_time)\nstatus = Int.(event_times .&lt;= max_time)\n\nprintln(\"=== Simple Survival Data ===\")\nprintln(\"n = $n\")\nprintln(\"Events: $(sum(status))\")\nprintln(\"Censored: $(n - sum(status))\")\nprintln(\"Time range: [$(round(minimum(obs_times), digits=3)), $(round(maximum(obs_times), digits=3))]\")\n\n# Create multistate model data\nsurv_data = DataFrame(\n    id = 1:n,\n    tstart = zeros(n),\n    tstop = obs_times,\n    statefrom = ones(Int, n),\n    stateto = ifelse.(status .== 1, 2, 1),\n    obstype = ones(Int, n)\n)\n\n# Save to CSV for R to read\nCSV.write(\"MultistateModelsTests/reports/_surv_data.csv\", DataFrame(time = obs_times, status = status))\n\n# Define model with spline hazard (initial knots will be replaced by calibration)\nh12 = Hazard(@formula(0 ~ 1), \"sp\", 1, 2;\n             degree = 3,\n             knots = Float64[],  # Will be set by calibrate_splines!\n             boundaryknots = [0.0, max_time],\n             natural_spline = true)\nmodel = multistatemodel(h12; data=surv_data)\n\n# Calibrate knots based on data - places knots at quantiles of event times\nprintln(\"\\nCalibrating spline knots...\")\nknot_result = calibrate_splines!(model; nknots=nknots, verbose=true)\n\n# Extract the calibrated knots\ninterior_knots = knot_result.h12.interior_knots\nboundary_knots = knot_result.h12.boundary_knots\nall_knots = model.hazards[1].knots\n\nprintln(\"\\n=== Knot Configuration ===\")\nprintln(\"Boundary knots: $(boundary_knots)\")\nprintln(\"Interior knots: $(round.(interior_knots, digits=3))\")\nprintln(\"Number of interior knots: $(length(interior_knots))\")\nprintln(\"Total knots: $(length(all_knots))\")\nprintln(\"Number of basis functions: $(length(model.hazards[1].parnames) - length(model.hazards[1].covar_names))\")\n\n# Save knots for R to use\nCSV.write(\"MultistateModelsTests/reports/_knots.csv\", DataFrame(\n    interior_knots = interior_knots,\n    boundary_lower = fill(boundary_knots[1], length(interior_knots)),\n    boundary_upper = fill(boundary_knots[2], length(interior_knots))\n))\n\n# Fit with each smoothing method and measure runtime\n# Run each method twice: first for JIT compilation, second for timing\ntimings = Dict{String, Float64}()\n\nprintln(\"\\n=== Fitting Smoothing Methods with Timing ===\")\n\n# PIJCV (LOO) - Newton-approximated\nprintln(\"\\nFitting with PIJCV (LOO) method...\")\nselect_smoothing_parameters(model, SplinePenalty(); method = :pijcv, verbose = false)  # warmup\nt_pijcv = @elapsed result_pijcv = select_smoothing_parameters(model, SplinePenalty(); \n                                           method = :pijcv, verbose = false)\ntimings[\"PIJCV\"] = t_pijcv\nprintln(\"  PIJCV λ = $(round(result_pijcv.lambda[1], digits=2)), EDF = $(round(result_pijcv.edf.total, digits=2)), time = $(round(t_pijcv, digits=3))s\")\n\n# PIJCV5 (5-fold) - Newton-approximated\nprintln(\"\\nFitting with PIJCV5 (5-fold) method...\")\nselect_smoothing_parameters(model, SplinePenalty(); method = :pijcv5, verbose = false)  # warmup\nt_pijcv5 = @elapsed result_pijcv5 = select_smoothing_parameters(model, SplinePenalty(); \n                                            method = :pijcv5, verbose = false)\ntimings[\"PIJCV5\"] = t_pijcv5\nprintln(\"  PIJCV5 λ = $(round(result_pijcv5.lambda[1], digits=2)), EDF = $(round(result_pijcv5.edf.total, digits=2)), time = $(round(t_pijcv5, digits=3))s\")\n\n# PIJCV10 (10-fold) - Newton-approximated\nprintln(\"\\nFitting with PIJCV10 (10-fold) method...\")\nselect_smoothing_parameters(model, SplinePenalty(); method = :pijcv10, verbose = false)  # warmup\nt_pijcv10 = @elapsed result_pijcv10 = select_smoothing_parameters(model, SplinePenalty(); \n                                             method = :pijcv10, verbose = false)\ntimings[\"PIJCV10\"] = t_pijcv10\nprintln(\"  PIJCV10 λ = $(round(result_pijcv10.lambda[1], digits=2)), EDF = $(round(result_pijcv10.edf.total, digits=2)), time = $(round(t_pijcv10, digits=3))s\")\n\n# PIJCV20 (20-fold) - Newton-approximated\nprintln(\"\\nFitting with PIJCV20 (20-fold) method...\")\nselect_smoothing_parameters(model, SplinePenalty(); method = :pijcv20, verbose = false)  # warmup\nt_pijcv20 = @elapsed result_pijcv20 = select_smoothing_parameters(model, SplinePenalty(); \n                                             method = :pijcv20, verbose = false)\ntimings[\"PIJCV20\"] = t_pijcv20\nprintln(\"  PIJCV20 λ = $(round(result_pijcv20.lambda[1], digits=2)), EDF = $(round(result_pijcv20.edf.total, digits=2)), time = $(round(t_pijcv20, digits=3))s\")\n\n# EFS\nprintln(\"\\nFitting with EFS method...\")\nselect_smoothing_parameters(model, SplinePenalty(); method = :efs, verbose = false)  # warmup\nt_efs = @elapsed result_efs = select_smoothing_parameters(model, SplinePenalty(); \n                                         method = :efs, verbose = false)\ntimings[\"EFS\"] = t_efs\nprintln(\"  EFS λ = $(round(result_efs.lambda[1], digits=2)), EDF = $(round(result_efs.edf.total, digits=2)), time = $(round(t_efs, digits=3))s\")\n\n# LOOCV (exact) - expensive\nprintln(\"\\nFitting with LOOCV (exact) method...\")\nselect_smoothing_parameters(model, SplinePenalty(); method = :loocv, verbose = false)  # warmup\nt_loocv = @elapsed result_loocv = select_smoothing_parameters(model, SplinePenalty(); \n                                           method = :loocv, verbose = false)\ntimings[\"LOOCV\"] = t_loocv\nprintln(\"  LOOCV λ = $(round(result_loocv.lambda[1], digits=2)), EDF = $(round(result_loocv.edf.total, digits=2)), time = $(round(t_loocv, digits=3))s\")\n\n# CV5 (exact 5-fold)\nprintln(\"\\nFitting with 5-fold CV (exact) method...\")\nselect_smoothing_parameters(model, SplinePenalty(); method = :cv5, verbose = false)  # warmup\nt_cv5 = @elapsed result_cv5 = select_smoothing_parameters(model, SplinePenalty(); \n                                         method = :cv5, verbose = false)\ntimings[\"CV5\"] = t_cv5\nprintln(\"  CV5 λ = $(round(result_cv5.lambda[1], digits=2)), EDF = $(round(result_cv5.edf.total, digits=2)), time = $(round(t_cv5, digits=3))s\")\n\n# CV10 (exact 10-fold)\nprintln(\"\\nFitting with 10-fold CV (exact) method...\")\nselect_smoothing_parameters(model, SplinePenalty(); method = :cv10, verbose = false)  # warmup\nt_cv10 = @elapsed result_cv10 = select_smoothing_parameters(model, SplinePenalty(); \n                                          method = :cv10, verbose = false)\ntimings[\"CV10\"] = t_cv10\nprintln(\"  CV10 λ = $(round(result_cv10.lambda[1], digits=2)), EDF = $(round(result_cv10.edf.total, digits=2)), time = $(round(t_cv10, digits=3))s\")\n\n# CV20 (exact 20-fold)\nprintln(\"\\nFitting with 20-fold CV (exact) method...\")\nselect_smoothing_parameters(model, SplinePenalty(); method = :cv20, verbose = false)  # warmup\nt_cv20 = @elapsed result_cv20 = select_smoothing_parameters(model, SplinePenalty(); \n                                          method = :cv20, verbose = false)\ntimings[\"CV20\"] = t_cv20\nprintln(\"  CV20 λ = $(round(result_cv20.lambda[1], digits=2)), EDF = $(round(result_cv20.edf.total, digits=2)), time = $(round(t_cv20, digits=3))s\")\n\n# Evaluation grid\neval_times = collect(range(0.01, max_time, length=200))\n\n# Function to evaluate hazard at a grid of times\nfunction evaluate_curves(model, beta, eval_times)\n    haz = model.hazards[1]\n    \n    # Use hazard_fn and cumhaz_fn (the callable functions)\n    hazard_vals = [haz.hazard_fn(t, beta, ()) for t in eval_times]\n    cumhaz_vals = [haz.cumhaz_fn(0.0, t, beta, ()) for t in eval_times]\n    survival_vals = exp.(-cumhaz_vals)\n    \n    return (hazard = hazard_vals, cumhaz = cumhaz_vals, survival = survival_vals)\nend\n\n# Compute curves for each method\ncurves_pijcv = evaluate_curves(model, result_pijcv.beta, eval_times)\ncurves_pijcv5 = evaluate_curves(model, result_pijcv5.beta, eval_times)\ncurves_pijcv10 = evaluate_curves(model, result_pijcv10.beta, eval_times)\ncurves_pijcv20 = evaluate_curves(model, result_pijcv20.beta, eval_times)\ncurves_efs = evaluate_curves(model, result_efs.beta, eval_times)\ncurves_loocv = evaluate_curves(model, result_loocv.beta, eval_times)\ncurves_cv5 = evaluate_curves(model, result_cv5.beta, eval_times)\ncurves_cv10 = evaluate_curves(model, result_cv10.beta, eval_times)\ncurves_cv20 = evaluate_curves(model, result_cv20.beta, eval_times)\n\n# Compute unpenalized log-likelihoods using ExactData\nsamplepaths = MultistateModels.extract_paths(model)\nexact_data = MultistateModels.ExactData(model, samplepaths)\nloglik_pijcv = MultistateModels.loglik_exact(result_pijcv.beta, exact_data; neg=false)\nloglik_pijcv5 = MultistateModels.loglik_exact(result_pijcv5.beta, exact_data; neg=false)\nloglik_pijcv10 = MultistateModels.loglik_exact(result_pijcv10.beta, exact_data; neg=false)\nloglik_pijcv20 = MultistateModels.loglik_exact(result_pijcv20.beta, exact_data; neg=false)\nloglik_efs = MultistateModels.loglik_exact(result_efs.beta, exact_data; neg=false)\nloglik_loocv = MultistateModels.loglik_exact(result_loocv.beta, exact_data; neg=false)\nloglik_cv5 = MultistateModels.loglik_exact(result_cv5.beta, exact_data; neg=false)\nloglik_cv10 = MultistateModels.loglik_exact(result_cv10.beta, exact_data; neg=false)\nloglik_cv20 = MultistateModels.loglik_exact(result_cv20.beta, exact_data; neg=false)\n\n# Save Julia results for R plotting\njulia_results = DataFrame(\n    time = repeat(eval_times, 9),\n    hazard = vcat(curves_pijcv.hazard, curves_pijcv5.hazard, curves_pijcv10.hazard, curves_pijcv20.hazard,\n                  curves_efs.hazard, curves_loocv.hazard, \n                  curves_cv5.hazard, curves_cv10.hazard, curves_cv20.hazard),\n    cumhaz = vcat(curves_pijcv.cumhaz, curves_pijcv5.cumhaz, curves_pijcv10.cumhaz, curves_pijcv20.cumhaz,\n                  curves_efs.cumhaz, curves_loocv.cumhaz, \n                  curves_cv5.cumhaz, curves_cv10.cumhaz, curves_cv20.cumhaz),\n    survival = vcat(curves_pijcv.survival, curves_pijcv5.survival, curves_pijcv10.survival, curves_pijcv20.survival,\n                    curves_efs.survival, curves_loocv.survival, \n                    curves_cv5.survival, curves_cv10.survival, curves_cv20.survival),\n    method = repeat([\"Julia PIJCV\", \"Julia PIJCV5\", \"Julia PIJCV10\", \"Julia PIJCV20\",\n                     \"Julia EFS\", \"Julia LOOCV\", \n                     \"Julia CV5\", \"Julia CV10\", \"Julia CV20\"], inner=length(eval_times))\n)\nCSV.write(\"MultistateModelsTests/reports/_julia_curves.csv\", julia_results)\n\n# Save summary stats with unpenalized log-likelihoods and timing\njulia_summary = DataFrame(\n    method = [\"PIJCV\", \"PIJCV5\", \"PIJCV10\", \"PIJCV20\", \"EFS\", \"LOOCV\", \"CV5\", \"CV10\", \"CV20\"],\n    lambda = [result_pijcv.lambda[1], result_pijcv5.lambda[1], result_pijcv10.lambda[1], result_pijcv20.lambda[1],\n              result_efs.lambda[1], result_loocv.lambda[1], \n              result_cv5.lambda[1], result_cv10.lambda[1], result_cv20.lambda[1]],\n    edf = [result_pijcv.edf.total, result_pijcv5.edf.total, result_pijcv10.edf.total, result_pijcv20.edf.total,\n           result_efs.edf.total, result_loocv.edf.total, \n           result_cv5.edf.total, result_cv10.edf.total, result_cv20.edf.total],\n    loglik = [loglik_pijcv, loglik_pijcv5, loglik_pijcv10, loglik_pijcv20,\n              loglik_efs, loglik_loocv, loglik_cv5, loglik_cv10, loglik_cv20],\n    runtime_sec = [timings[\"PIJCV\"], timings[\"PIJCV5\"], timings[\"PIJCV10\"], timings[\"PIJCV20\"],\n                   timings[\"EFS\"], timings[\"LOOCV\"], \n                   timings[\"CV5\"], timings[\"CV10\"], timings[\"CV20\"]]\n)\nCSV.write(\"MultistateModelsTests/reports/_julia_summary.csv\", julia_summary)\n\nprintln(\"\\n=== Runtime Summary ===\")\nprintln(\"Newton-approximated CV methods:\")\nprintln(\"  PIJCV (LOO): $(round(timings[\"PIJCV\"], digits=3))s\")\nprintln(\"  PIJCV5:      $(round(timings[\"PIJCV5\"], digits=3))s\")\nprintln(\"  PIJCV10:     $(round(timings[\"PIJCV10\"], digits=3))s\")\nprintln(\"  PIJCV20:     $(round(timings[\"PIJCV20\"], digits=3))s\")\nprintln(\"Other analytical methods:\")\nprintln(\"  EFS:         $(round(timings[\"EFS\"], digits=3))s\")\nprintln(\"Exact CV methods:\")\nprintln(\"  LOOCV:       $(round(timings[\"LOOCV\"], digits=3))s\")\nprintln(\"  CV5:         $(round(timings[\"CV5\"], digits=3))s\")\nprintln(\"  CV10:        $(round(timings[\"CV10\"], digits=3))s\")\nprintln(\"  CV20:        $(round(timings[\"CV20\"], digits=3))s\")\n\nprintln(\"\\nJulia curves computed and saved.\")\n'"
  },
  {
    "objectID": "spline_comparison_benchmark.html#illness-death-model",
    "href": "spline_comparison_benchmark.html#illness-death-model",
    "title": "Spline Methods Comparison",
    "section": "Illness-Death Model",
    "text": "Illness-Death Model\nWe consider a three-state illness-death model without recovery:\n\nState 1: Healthy (initial state)\nState 2: Illness (transient state)\nState 3: Death (absorbing state)\n\nTransitions:\n\n\\(1 \\to 2\\): Healthy to Illness (incidence)\n\\(1 \\to 3\\): Healthy to Death (direct mortality)\n\\(2 \\to 3\\): Illness to Death (disease-related mortality)"
  },
  {
    "objectID": "spline_comparison_benchmark.html#true-hazard-functions",
    "href": "spline_comparison_benchmark.html#true-hazard-functions",
    "title": "Spline Methods Comparison",
    "section": "True Hazard Functions",
    "text": "True Hazard Functions\nThe data are simulated using Weibull hazard functions with the rate parameterization:\n\\[h_{rs}(t) = \\kappa_{rs} \\cdot \\lambda_{rs} \\cdot t^{\\kappa_{rs} - 1}\\]\nwhere \\(\\kappa_{rs} &gt; 0\\) is the shape parameter and \\(\\lambda_{rs} &gt; 0\\) is the rate parameter.\nThe cumulative hazard is: \\[H_{rs}(t) = \\lambda_{rs} \\cdot t^{\\kappa_{rs}}\\]\nTrue Parameter Values:\n\n\n\n\n\n\n\n\n\nTransition\nShape (\\(\\kappa\\))\nRate (\\(\\lambda\\))\nInterpretation\n\n\n\n\n\\(h_{12}\\) (Healthy to Illness)\n1.3\n0.04\nIncreasing hazard\n\n\n\\(h_{13}\\) (Healthy to Death)\n1.2\n0.015\nMildly increasing\n\n\n\\(h_{23}\\) (Illness to Death)\n1.4\n0.08\nHigher mortality after illness"
  },
  {
    "objectID": "spline_comparison_benchmark.html#transition-probability-matrix",
    "href": "spline_comparison_benchmark.html#transition-probability-matrix",
    "title": "Spline Methods Comparison",
    "section": "Transition Probability Matrix",
    "text": "Transition Probability Matrix\nFor a time-homogeneous Markov model, the transition probability matrix \\(\\mathbf{P}(s, t)\\) satisfies the Kolmogorov forward equation:\n\\[\\frac{\\partial}{\\partial t}\\mathbf{P}(s,t) = \\mathbf{P}(s,t) \\cdot \\mathbf{Q}(t)\\]\nwhere \\(\\mathbf{Q}(t)\\) is the transition intensity (generator) matrix:\n\\[\\mathbf{Q}(t) = \\begin{pmatrix}\n-(h_{12}(t) + h_{13}(t)) & h_{12}(t) & h_{13}(t) \\\\\n0 & -h_{23}(t) & h_{23}(t) \\\\\n0 & 0 & 0\n\\end{pmatrix}\\]\nThe solution is computed via the product integral: \\[\\mathbf{P}(0, t) = \\prod_{s=0}^{t} \\exp\\left(\\mathbf{Q}(s) ds\\right)\\]"
  },
  {
    "objectID": "spline_comparison_benchmark.html#state-prevalence",
    "href": "spline_comparison_benchmark.html#state-prevalence",
    "title": "Spline Methods Comparison",
    "section": "State Prevalence",
    "text": "State Prevalence\nState prevalence at time \\(t\\) for subjects starting in state 1:\n\n\\(P_1(t) = P_{11}(0, t)\\) - Probability of remaining healthy\n\\(P_2(t) = P_{12}(0, t)\\) - Probability of being in illness state\n\\(P_3(t) = P_{13}(0, t)\\) - Probability of having died"
  },
  {
    "objectID": "spline_comparison_benchmark.html#cumulative-incidence-functions",
    "href": "spline_comparison_benchmark.html#cumulative-incidence-functions",
    "title": "Spline Methods Comparison",
    "section": "Cumulative Incidence Functions",
    "text": "Cumulative Incidence Functions\nThe cause-specific cumulative incidence function for transition \\(1 \\to r\\) is:\n\\[F_{1r}(t) = \\int_0^t P_{11}(0, s) \\cdot h_{1r}(s) \\, ds\\]\nThis represents the probability of experiencing transition \\(1 \\to r\\) by time \\(t\\)."
  },
  {
    "objectID": "spline_comparison_benchmark.html#loading-simulated-data",
    "href": "spline_comparison_benchmark.html#loading-simulated-data",
    "title": "Spline Methods Comparison",
    "section": "Loading Simulated Data",
    "text": "Loading Simulated Data\n\n\nShow code\n# Load data generated by MultistateModels.jl\ndata_path &lt;- \"../fixtures/illness_death_data.csv\"\nmeta_path &lt;- \"../fixtures/illness_death_metadata.json\"\n\ndat &lt;- read.csv(data_path)\nmeta &lt;- fromJSON(meta_path)\n\n# Display metadata\ncat(\"Sample Size:\", meta$n_subjects, \"\\n\")\n\n\nSample Size: 1000 \n\n\nShow code\ncat(\"Maximum Follow-up Time:\", meta$max_time, \"\\n\")\n\n\nMaximum Follow-up Time: 20 \n\n\nShow code\ncat(\"\\nTrue Parameters:\\n\")\n\n\n\nTrue Parameters:\n\n\nShow code\ncat(\"  h12: shape =\", meta$true_params$h12$shape, \", rate =\", meta$true_params$h12$rate, \"\\n\")\n\n\n  h12: shape = 1.3 , rate = 0.04 \n\n\nShow code\ncat(\"  h13: shape =\", meta$true_params$h13$shape, \", rate =\", meta$true_params$h13$rate, \"\\n\")\n\n\n  h13: shape = 1.2 , rate = 0.015 \n\n\nShow code\ncat(\"  h23: shape =\", meta$true_params$h23$shape, \", rate =\", meta$true_params$h23$rate, \"\\n\")\n\n\n  h23: shape = 1.4 , rate = 0.08"
  },
  {
    "objectID": "spline_comparison_benchmark.html#data-summary",
    "href": "spline_comparison_benchmark.html#data-summary",
    "title": "Spline Methods Comparison",
    "section": "Data Summary",
    "text": "Data Summary\n\n\nShow code\n# Transition counts\ntrans_counts &lt;- dat %&gt;%\n  filter(status == 1) %&gt;%\n  count(from, to) %&gt;%\n  mutate(transition = paste0(from, \" -&gt; \", to))\n\nkable(trans_counts, caption = \"Observed Transition Counts\") %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n\n\n\nObserved Transition Counts\n\n\nfrom\nto\nn\ntransition\n\n\n\n\n1\n2\n711\n1 -&gt; 2\n\n\n1\n3\n215\n1 -&gt; 3\n\n\n2\n3\n595\n2 -&gt; 3\n\n\n\n\n\nShow code\n# Final state distribution\nfinal_states &lt;- dat %&gt;%\n  group_by(id) %&gt;%\n  slice_tail(n = 1) %&gt;%\n  ungroup() %&gt;%\n  count(to) %&gt;%\n  mutate(\n    state_name = case_when(\n      to == 1 ~ \"Healthy\",\n      to == 2 ~ \"Illness\", \n      to == 3 ~ \"Death\"\n    ),\n    pct = round(100 * n / sum(n), 1)\n  )\n\nkable(final_states, caption = \"Final State Distribution\") %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n\n\n\nFinal State Distribution\n\n\nto\nn\nstate_name\npct\n\n\n\n\n1\n74\nHealthy\n7.4\n\n\n2\n116\nIllness\n11.6\n\n\n3\n810\nDeath\n81.0"
  },
  {
    "objectID": "spline_comparison_benchmark.html#event-time-distribution",
    "href": "spline_comparison_benchmark.html#event-time-distribution",
    "title": "Spline Methods Comparison",
    "section": "Event Time Distribution",
    "text": "Event Time Distribution\n\n\nShow code\n# Plot event time distributions\nevents &lt;- dat %&gt;%\n  filter(status == 1) %&gt;%\n  mutate(transition = factor(paste0(from, \" -&gt; \", to),\n                            levels = c(\"1 -&gt; 2\", \"1 -&gt; 3\", \"2 -&gt; 3\")))\n\nggplot(events, aes(x = tstop)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 30, fill = \"steelblue\", alpha = 0.7) +\n  geom_density(color = \"darkblue\", linewidth = 1) +\n  facet_wrap(~ transition, scales = \"free_y\") +\n  labs(\n    title = \"Distribution of Event Times by Transition\",\n    x = \"Time\",\n    y = \"Density\"\n  )"
  },
  {
    "objectID": "spline_comparison_benchmark.html#true-hazard-functions-1",
    "href": "spline_comparison_benchmark.html#true-hazard-functions-1",
    "title": "Spline Methods Comparison",
    "section": "True Hazard Functions",
    "text": "True Hazard Functions\n\n\nShow code\n# Define true hazard functions\ntrue_hazard &lt;- function(t, shape, rate) {\n  shape * rate * t^(shape - 1)\n}\n\ntrue_cumhaz &lt;- function(t, shape, rate) {\n  rate * t^shape\n}\n\n# True hazards\nh12_true &lt;- function(t) true_hazard(t, meta$true_params$h12$shape, meta$true_params$h12$rate)\nh13_true &lt;- function(t) true_hazard(t, meta$true_params$h13$shape, meta$true_params$h13$rate)\nh23_true &lt;- function(t) true_hazard(t, meta$true_params$h23$shape, meta$true_params$h23$rate)"
  },
  {
    "objectID": "spline_comparison_benchmark.html#method-1-pammtoolsmgcv-pam",
    "href": "spline_comparison_benchmark.html#method-1-pammtoolsmgcv-pam",
    "title": "Spline Methods Comparison",
    "section": "Method 1: pammtools/mgcv (PAM)",
    "text": "Method 1: pammtools/mgcv (PAM)\nThe piecewise-exponential additive model (PAM) transforms survival data into a Poisson regression framework. Following Bender et al. (2018) and the pammtools documentation:\nData Transformation:\n\nSplit follow-up time into intervals using a set of cut points\nFor each subject-interval combination, create a pseudo-observation with:\n\nExposure time (offset): \\(\\log(\\text{time at risk in interval})\\)\nEvent indicator: 1 if event occurred in interval, 0 otherwise\n\n\nModel:\n\\[\\log(E[d_{ij}]) = \\log(t_{ij}) + f(t_j) + \\mathbf{x}_i'\\boldsymbol{\\beta}\\]\nwhere \\(d_{ij}\\) is the event indicator for subject \\(i\\) in interval \\(j\\), \\(t_{ij}\\) is the exposure time, and \\(f(t)\\) is a smooth function of time.\nSpline specification: We use a cubic regression spline with the same knots as Julia. The mgcv::gam function uses penalized splines, but we fix the knot locations to match.\n\n\nShow code\n# Create cut points for PAM\nn_intervals &lt;- 30\nmax_t &lt;- max(dat$tstop)\ncut_points &lt;- seq(0, max_t * 1.01, length.out = n_intervals + 1)\n\n# Function to create PAM data for a specific transition\ncreate_pam_data &lt;- function(dat, from_state, to_state, cuts) {\n  # Filter to subjects at risk from this state\n  trans_dat &lt;- dat[dat$from == from_state, ]\n  \n  pam_rows &lt;- list()\n  \n  for (i in 1:nrow(trans_dat)) {\n    row &lt;- trans_dat[i, ]\n    t_start &lt;- row$tstart\n    t_end &lt;- row$tstop\n    is_event &lt;- (row$status == 1) && (row$to == to_state)\n    \n    for (j in 1:(length(cuts)-1)) {\n      int_start &lt;- cuts[j]\n      int_end &lt;- cuts[j+1]\n      \n      if (int_end &lt;= t_start) next\n      if (int_start &gt;= t_end) break\n      \n      risk_start &lt;- max(int_start, t_start)\n      risk_end &lt;- min(int_end, t_end)\n      offset_val &lt;- log(risk_end - risk_start)\n      \n      event_in_interval &lt;- is_event && (t_end &lt;= int_end) && (t_end &gt; int_start)\n      \n      pam_rows[[length(pam_rows) + 1]] &lt;- data.frame(\n        id = row$id,\n        interval = j,\n        t_mid = (risk_start + risk_end) / 2,\n        t_start = risk_start,\n        t_end = risk_end,\n        offset = offset_val,\n        event = as.integer(event_in_interval)\n      )\n    }\n  }\n  \n  do.call(rbind, pam_rows)\n}\n\n# Create PAM datasets\npam_12 &lt;- create_pam_data(dat, 1, 2, cut_points)\npam_13 &lt;- create_pam_data(dat, 1, 3, cut_points)\npam_23 &lt;- create_pam_data(dat, 2, 3, cut_points)\n\ncat(\"PAM Data Created:\\n\")\n\n\nPAM Data Created:\n\n\nShow code\ncat(\"  Transition 1-&gt;2:\", nrow(pam_12), \"rows,\", sum(pam_12$event), \"events\\n\")\n\n\n  Transition 1-&gt;2: 13011 rows, 711 events\n\n\nShow code\ncat(\"  Transition 1-&gt;3:\", nrow(pam_13), \"rows,\", sum(pam_13$event), \"events\\n\")\n\n\n  Transition 1-&gt;3: 13011 rows, 215 events\n\n\nShow code\ncat(\"  Transition 2-&gt;3:\", nrow(pam_23), \"rows,\", sum(pam_23$event), \"events\\n\")\n\n\n  Transition 2-&gt;3: 6004 rows, 595 events\n\n\n\n\nShow code\n# Fit GAM models using cubic regression splines with FIXED knot locations\n# to match Julia's specification exactly\nt_start_pam &lt;- Sys.time()\n\n# For mgcv with bs=\"cr\" (cubic regression spline):\n# When supplying knots, k = number of knots supplied\n# The knots argument specifies ALL knots (not just interior)\nk_mgcv &lt;- n_interior_knots\n\nfit_pam_12 &lt;- gam(event ~ s(t_mid, bs = \"cr\", k = k_mgcv), \n                   family = poisson(), \n                   offset = offset,\n                   data = pam_12,\n                   knots = list(t_mid = interior_knots),\n                   method = \"REML\")\n\nfit_pam_13 &lt;- gam(event ~ s(t_mid, bs = \"cr\", k = k_mgcv), \n                   family = poisson(), \n                   offset = offset,\n                   data = pam_13,\n                   knots = list(t_mid = interior_knots),\n                   method = \"REML\")\n\nfit_pam_23 &lt;- gam(event ~ s(t_mid, bs = \"cr\", k = k_mgcv), \n                   family = poisson(), \n                   offset = offset,\n                   data = pam_23,\n                   knots = list(t_mid = interior_knots),\n                   method = \"REML\")\n\nt_pam &lt;- as.numeric(Sys.time() - t_start_pam, units = \"secs\")\n\ncat(\"PAM Fit Time:\", round(t_pam, 2), \"seconds\\n\")\n\n\nPAM Fit Time: 0.42 seconds\n\n\nShow code\ncat(\"\\nEffective Degrees of Freedom (after penalization):\\n\")\n\n\n\nEffective Degrees of Freedom (after penalization):\n\n\nShow code\ncat(\"  h12:\", round(sum(fit_pam_12$edf), 2), \"\\n\")\n\n\n  h12: 3.1 \n\n\nShow code\ncat(\"  h13:\", round(sum(fit_pam_13$edf), 2), \"\\n\")\n\n\n  h13: 2 \n\n\nShow code\ncat(\"  h23:\", round(sum(fit_pam_23$edf), 2), \"\\n\")\n\n\n  h23: 3.8 \n\n\nShow code\ncat(\"\\nKnots used by mgcv:\\n\")\n\n\n\nKnots used by mgcv:\n\n\nShow code\ncat(\"  Interior knots:\", round(interior_knots, 3), \"\\n\")\n\n\n  Interior knots: 2.196 3.972 5.714 7.094 8.695 10.289 11.994 13.923 16.38"
  },
  {
    "objectID": "spline_comparison_benchmark.html#method-2-flexsurv",
    "href": "spline_comparison_benchmark.html#method-2-flexsurv",
    "title": "Spline Methods Comparison",
    "section": "Method 2: flexsurv",
    "text": "Method 2: flexsurv\nThe flexsurv package implements flexible parametric survival models using cubic splines on the log cumulative hazard or log hazard scale (Royston-Parmar models).\n\n\nShow code\n# Prepare data for flexsurv (one row per transition)\n# For multistate models, we need to create separate datasets\n\n# Transition 1-&gt;2: at risk while in state 1, event if goes to state 2\nflex_12 &lt;- dat %&gt;%\n  filter(from == 1) %&gt;%\n  mutate(\n    time = tstop - tstart,\n    status = as.integer(status == 1 & to == 2)\n  ) %&gt;%\n  select(id, time, status)\n\n# Transition 1-&gt;3: at risk while in state 1, event if goes to state 3  \nflex_13 &lt;- dat %&gt;%\n  filter(from == 1) %&gt;%\n  mutate(\n    time = tstop - tstart,\n    status = as.integer(status == 1 & to == 3)\n  ) %&gt;%\n  select(id, time, status)\n\n# Transition 2-&gt;3: at risk while in state 2, event if goes to state 3\nflex_23 &lt;- dat %&gt;%\n  filter(from == 2) %&gt;%\n  mutate(\n    time = tstop - tstart,\n    status = as.integer(status == 1 & to == 3)\n  ) %&gt;%\n  select(id, time, status)\n\ncat(\"flexsurv Data:\\n\")\n\n\nflexsurv Data:\n\n\nShow code\ncat(\"  Transition 1-&gt;2:\", nrow(flex_12), \"observations,\", sum(flex_12$status), \"events\\n\")\n\n\n  Transition 1-&gt;2: 1000 observations, 711 events\n\n\nShow code\ncat(\"  Transition 1-&gt;3:\", nrow(flex_13), \"observations,\", sum(flex_13$status), \"events\\n\")\n\n\n  Transition 1-&gt;3: 1000 observations, 215 events\n\n\nShow code\ncat(\"  Transition 2-&gt;3:\", nrow(flex_23), \"observations,\", sum(flex_23$status), \"events\\n\")\n\n\n  Transition 2-&gt;3: 711 observations, 595 events\n\n\n\n\nShow code\n# Fit flexible parametric models with splines on log cumulative hazard\n# Using FIXED knot locations to match Julia's specification\n\n# flexsurv places knots on the LOG time scale\n# It automatically adds boundary knots at min and max event times\n# We need to specify internal knots on log scale\nlog_interior_knots &lt;- log(interior_knots)\n\nt_start_flex &lt;- Sys.time()\n\nfit_flex_12 &lt;- flexsurvspline(Surv(time, status) ~ 1, \n                               data = flex_12, \n                               knots = log_interior_knots,\n                               scale = \"hazard\")\n\nfit_flex_13 &lt;- flexsurvspline(Surv(time, status) ~ 1, \n                               data = flex_13, \n                               knots = log_interior_knots,\n                               scale = \"hazard\")\n\nfit_flex_23 &lt;- flexsurvspline(Surv(time, status) ~ 1, \n                               data = flex_23, \n                               knots = log_interior_knots,\n                               scale = \"hazard\")\n\nt_flex &lt;- as.numeric(Sys.time() - t_start_flex, units = \"secs\")\n\ncat(\"flexsurv Fit Time:\", round(t_flex, 2), \"seconds\\n\")\n\n\nflexsurv Fit Time: 0.71 seconds\n\n\nShow code\ncat(\"\\nInterior knots (original scale):\\n\")\n\n\n\nInterior knots (original scale):\n\n\nShow code\ncat(\"  \", round(interior_knots, 3), \"\\n\")\n\n\n   2.196 3.972 5.714 7.094 8.695 10.289 11.994 13.923 16.38 \n\n\nShow code\ncat(\"\\nInterior knots (log scale for flexsurv):\\n\")\n\n\n\nInterior knots (log scale for flexsurv):\n\n\nShow code\ncat(\"  \", round(log_interior_knots, 3), \"\\n\")\n\n\n   0.787 1.379 1.743 1.959 2.163 2.331 2.484 2.634 2.796"
  },
  {
    "objectID": "spline_comparison_benchmark.html#method-3-multistatemodels.jl-julia",
    "href": "spline_comparison_benchmark.html#method-3-multistatemodels.jl-julia",
    "title": "Spline Methods Comparison",
    "section": "Method 3: MultistateModels.jl (Julia)",
    "text": "Method 3: MultistateModels.jl (Julia)\nMultistateModels.jl fits all transition hazards jointly via maximum likelihood with natural cubic spline baseline hazards. Results are loaded from pre-computed fits.\n\n\nShow code\n# Load Julia predictions (julia_results already loaded in knot-setup chunk)\njulia_pred &lt;- fromJSON(\"../fixtures/illness_death_julia_predictions.json\")\n\ncat(\"Julia Fit Time:\", round(julia_results$julia_fit$fit_time_seconds, 2), \"seconds\\n\")\n\n\nJulia Fit Time: 13.22 seconds\n\n\nShow code\ncat(\"Interior Knots:\", paste(round(julia_results$julia_fit$interior_knots, 2), collapse = \", \"), \"\\n\")\n\n\nInterior Knots: 2.2, 3.97, 5.71, 7.09, 8.69, 10.29, 11.99, 13.92, 16.38"
  },
  {
    "objectID": "spline_comparison_benchmark.html#predicted-hazards",
    "href": "spline_comparison_benchmark.html#predicted-hazards",
    "title": "Spline Methods Comparison",
    "section": "Predicted Hazards",
    "text": "Predicted Hazards\n\n\nShow code\n# Evaluation times\neval_times &lt;- seq(0.5, 20, by = 0.5)\n\n# True hazards\nh12_true_vec &lt;- sapply(eval_times, h12_true)\nh13_true_vec &lt;- sapply(eval_times, h13_true)\nh23_true_vec &lt;- sapply(eval_times, h23_true)\n\n# PAM predictions\npred_data &lt;- data.frame(t_mid = eval_times, offset = 0)\nh12_pam &lt;- exp(predict(fit_pam_12, newdata = pred_data, type = \"link\"))\nh13_pam &lt;- exp(predict(fit_pam_13, newdata = pred_data, type = \"link\"))\nh23_pam &lt;- exp(predict(fit_pam_23, newdata = pred_data, type = \"link\"))\n\n# flexsurv predictions\nh12_flex &lt;- summary(fit_flex_12, t = eval_times, type = \"hazard\")[[1]]$est\nh13_flex &lt;- summary(fit_flex_13, t = eval_times, type = \"hazard\")[[1]]$est\nh23_flex &lt;- summary(fit_flex_23, t = eval_times, type = \"hazard\")[[1]]$est\n\n# Julia predictions (from loaded file)\nh12_julia &lt;- julia_pred$hazards$h12_julia\nh13_julia &lt;- julia_pred$hazards$h13_julia\nh23_julia &lt;- julia_pred$hazards$h23_julia\n\n# Combine into data frame\nhazard_df &lt;- data.frame(\n  time = rep(eval_times, 12),\n  hazard = c(h12_true_vec, h12_julia, h12_pam, h12_flex,\n             h13_true_vec, h13_julia, h13_pam, h13_flex,\n             h23_true_vec, h23_julia, h23_pam, h23_flex),\n  method = rep(rep(c(\"True\", \"Julia\", \"PAM (mgcv)\", \"flexsurv\"), each = length(eval_times)), 3),\n  transition = rep(c(\"h12 (Healthy -&gt; Illness)\", \n                     \"h13 (Healthy -&gt; Death)\",\n                     \"h23 (Illness -&gt; Death)\"), each = 4 * length(eval_times))\n)"
  },
  {
    "objectID": "spline_comparison_benchmark.html#hazard-plots",
    "href": "spline_comparison_benchmark.html#hazard-plots",
    "title": "Spline Methods Comparison",
    "section": "Hazard Plots",
    "text": "Hazard Plots\n\n\nShow code\nggplot(hazard_df, aes(x = time, y = hazard, color = method, linetype = method)) +\n  geom_line(linewidth = 1) +\n  scale_color_manual(values = c(\"True\" = \"black\", \"Julia\" = \"#E69F00\", \n                                 \"PAM (mgcv)\" = \"#56B4E9\", \"flexsurv\" = \"#009E73\")) +\n  scale_linetype_manual(values = c(\"True\" = \"solid\", \"Julia\" = \"dashed\", \n                                    \"PAM (mgcv)\" = \"dotted\", \"flexsurv\" = \"twodash\")) +\n  facet_wrap(~ transition, scales = \"free_y\", ncol = 1) +\n  labs(\n    title = \"Estimated vs True Hazard Functions\",\n    x = \"Time\",\n    y = \"Hazard Rate h(t)\",\n    color = \"Method\",\n    linetype = \"Method\"\n  ) +\n  theme(legend.position = \"bottom\")"
  },
  {
    "objectID": "spline_comparison_benchmark.html#hazard-rmse",
    "href": "spline_comparison_benchmark.html#hazard-rmse",
    "title": "Spline Methods Comparison",
    "section": "Hazard RMSE",
    "text": "Hazard RMSE\n\n\nShow code\nrmse &lt;- function(a, b) sqrt(mean((a - b)^2))\n\nhazard_rmse &lt;- data.frame(\n  Transition = c(\"h12\", \"h13\", \"h23\"),\n  Julia = c(rmse(h12_julia, h12_true_vec),\n            rmse(h13_julia, h13_true_vec),\n            rmse(h23_julia, h23_true_vec)),\n  PAM_mgcv = c(rmse(h12_pam, h12_true_vec),\n                   rmse(h13_pam, h13_true_vec),\n                   rmse(h23_pam, h23_true_vec)),\n  flexsurv = c(rmse(h12_flex, h12_true_vec),\n               rmse(h13_flex, h13_true_vec),\n               rmse(h23_flex, h23_true_vec))\n)\n\nkable(hazard_rmse, digits = 5, \n      caption = \"Hazard RMSE (vs True)\") %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n\n\n\nHazard RMSE (vs True)\n\n\nTransition\nJulia\nPAM_mgcv\nflexsurv\n\n\n\n\nh12\n0.01358\n0.00645\n0.00998\n\n\nh13\n0.00429\n0.00163\n0.00491\n\n\nh23\n0.13832\n0.11949\n0.22306"
  },
  {
    "objectID": "spline_comparison_benchmark.html#computing-transition-probabilities",
    "href": "spline_comparison_benchmark.html#computing-transition-probabilities",
    "title": "Spline Methods Comparison",
    "section": "Computing Transition Probabilities",
    "text": "Computing Transition Probabilities\n\n\nShow code\n# Compute transition probability matrix via product integral\ncompute_tpm &lt;- function(t, h12_fn, h13_fn, h23_fn, dt = 0.01) {\n  if (t &lt;= 0) return(diag(3))\n  \n  n_steps &lt;- max(1, ceiling(t / dt))\n  actual_dt &lt;- t / n_steps\n  \n  P &lt;- diag(3)\n  \n  for (i in 1:n_steps) {\n    s &lt;- (i - 0.5) * actual_dt\n    \n    h12 &lt;- h12_fn(s)\n    h13 &lt;- h13_fn(s)\n    h23 &lt;- h23_fn(s)\n    \n    Q &lt;- matrix(c(-(h12 + h13), h12, h13,\n                  0, -h23, h23,\n                  0, 0, 0), nrow = 3, byrow = TRUE)\n    \n    dP &lt;- expm(Q * actual_dt)\n    P &lt;- P %*% dP\n  }\n  \n  return(P)\n}\n\n# Create interpolation functions for each method\nmake_interp &lt;- function(times, values) {\n  approxfun(times, values, rule = 2)\n}\n\nh12_pam_fn &lt;- make_interp(eval_times, h12_pam)\nh13_pam_fn &lt;- make_interp(eval_times, h13_pam)\nh23_pam_fn &lt;- make_interp(eval_times, h23_pam)\n\nh12_flex_fn &lt;- make_interp(eval_times, h12_flex)\nh13_flex_fn &lt;- make_interp(eval_times, h13_flex)\nh23_flex_fn &lt;- make_interp(eval_times, h23_flex)\n\nh12_julia_fn &lt;- make_interp(eval_times, h12_julia)\nh13_julia_fn &lt;- make_interp(eval_times, h13_julia)\nh23_julia_fn &lt;- make_interp(eval_times, h23_julia)\n\n\n\n\nShow code\n# Compute state prevalence for each method\nprev_true &lt;- matrix(0, nrow = length(eval_times), ncol = 3)\nprev_julia &lt;- matrix(0, nrow = length(eval_times), ncol = 3)\nprev_pam &lt;- matrix(0, nrow = length(eval_times), ncol = 3)\nprev_flex &lt;- matrix(0, nrow = length(eval_times), ncol = 3)\n\nfor (i in seq_along(eval_times)) {\n  t &lt;- eval_times[i]\n  \n  P_true &lt;- compute_tpm(t, h12_true, h13_true, h23_true)\n  prev_true[i, ] &lt;- P_true[1, ]\n  \n  P_julia &lt;- compute_tpm(t, h12_julia_fn, h13_julia_fn, h23_julia_fn)\n  prev_julia[i, ] &lt;- P_julia[1, ]\n  \n  P_pam &lt;- compute_tpm(t, h12_pam_fn, h13_pam_fn, h23_pam_fn)\n  prev_pam[i, ] &lt;- P_pam[1, ]\n  \n  P_flex &lt;- compute_tpm(t, h12_flex_fn, h13_flex_fn, h23_flex_fn)\n  prev_flex[i, ] &lt;- P_flex[1, ]\n}\n\n# Empirical prevalence from data\nprev_emp &lt;- julia_results$empirical"
  },
  {
    "objectID": "spline_comparison_benchmark.html#prevalence-plots",
    "href": "spline_comparison_benchmark.html#prevalence-plots",
    "title": "Spline Methods Comparison",
    "section": "Prevalence Plots",
    "text": "Prevalence Plots\n\n\nShow code\nprev_df &lt;- data.frame(\n  time = rep(eval_times, 15),\n  prevalence = c(\n    prev_true[,1], prev_julia[,1], prev_pam[,1], prev_flex[,1], prev_emp$prevalence_healthy,\n    prev_true[,2], prev_julia[,2], prev_pam[,2], prev_flex[,2], prev_emp$prevalence_illness,\n    prev_true[,3], prev_julia[,3], prev_pam[,3], prev_flex[,3], prev_emp$prevalence_death\n  ),\n  method = rep(rep(c(\"True\", \"Julia\", \"PAM (mgcv)\", \"flexsurv\", \"Empirical\"), \n                   each = length(eval_times)), 3),\n  state = rep(c(\"P1(t): Healthy\", \"P2(t): Illness\", \"P3(t): Death\"), \n              each = 5 * length(eval_times))\n)\n\nggplot(prev_df, aes(x = time, y = prevalence, color = method, linetype = method)) +\n  geom_line(linewidth = 1) +\n  scale_color_manual(values = c(\"True\" = \"black\", \"Julia\" = \"#E69F00\", \n                                 \"PAM (mgcv)\" = \"#56B4E9\", \"flexsurv\" = \"#009E73\",\n                                 \"Empirical\" = \"grey50\")) +\n  scale_linetype_manual(values = c(\"True\" = \"solid\", \"Julia\" = \"dashed\", \n                                    \"PAM (mgcv)\" = \"dotted\", \"flexsurv\" = \"twodash\",\n                                    \"Empirical\" = \"dotdash\")) +\n  facet_wrap(~ state, scales = \"free_y\", ncol = 1) +\n  labs(\n    title = \"State Prevalence: Estimated vs True\",\n    subtitle = \"Starting from State 1 (Healthy)\",\n    x = \"Time\",\n    y = \"Probability\",\n    color = \"Method\",\n    linetype = \"Method\"\n  ) +\n  theme(legend.position = \"bottom\")"
  },
  {
    "objectID": "spline_comparison_benchmark.html#prevalence-rmse",
    "href": "spline_comparison_benchmark.html#prevalence-rmse",
    "title": "Spline Methods Comparison",
    "section": "Prevalence RMSE",
    "text": "Prevalence RMSE\n\n\nShow code\nprev_rmse &lt;- data.frame(\n  State = c(\"P1 (Healthy)\", \"P2 (Illness)\", \"P3 (Death)\"),\n  Empirical = c(rmse(prev_true[,1], prev_emp$prevalence_healthy),\n                rmse(prev_true[,2], prev_emp$prevalence_illness),\n                rmse(prev_true[,3], prev_emp$prevalence_death)),\n  Julia = c(rmse(prev_true[,1], prev_julia[,1]),\n            rmse(prev_true[,2], prev_julia[,2]),\n            rmse(prev_true[,3], prev_julia[,3])),\n  PAM_mgcv = c(rmse(prev_true[,1], prev_pam[,1]),\n                   rmse(prev_true[,2], prev_pam[,2]),\n                   rmse(prev_true[,3], prev_pam[,3])),\n  flexsurv = c(rmse(prev_true[,1], prev_flex[,1]),\n               rmse(prev_true[,2], prev_flex[,2]),\n               rmse(prev_true[,3], prev_flex[,3]))\n)\n\nkable(prev_rmse, digits = 5,\n      caption = \"State Prevalence RMSE (vs True)\") %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n\n\n\nState Prevalence RMSE (vs True)\n\n\nState\nEmpirical\nJulia\nPAM_mgcv\nflexsurv\n\n\n\n\nP1 (Healthy)\n0.00839\n0.00790\n0.01080\n0.00803\n\n\nP2 (Illness)\n0.06081\n0.01633\n0.05858\n0.01752\n\n\nP3 (Death)\n0.05591\n0.02269\n0.05474\n0.02337"
  },
  {
    "objectID": "spline_comparison_benchmark.html#computing-cumulative-incidence",
    "href": "spline_comparison_benchmark.html#computing-cumulative-incidence",
    "title": "Spline Methods Comparison",
    "section": "Computing Cumulative Incidence",
    "text": "Computing Cumulative Incidence\n\n\nShow code\n# Compute cause-specific cumulative incidence\n# CI_1r(t) = integral_0^t P11(s) * h1r(s) ds\ncompute_ci &lt;- function(times, h_fn, h12_all_fn, h13_all_fn, h23_all_fn, dt = 0.05) {\n  ci &lt;- numeric(length(times))\n  \n  for (i in seq_along(times)) {\n    t &lt;- times[i]\n    if (t &lt;= 0) {\n      ci[i] &lt;- 0\n      next\n    }\n    \n    n_steps &lt;- max(1, ceiling(t / dt))\n    actual_dt &lt;- t / n_steps\n    \n    integral &lt;- 0\n    for (j in 1:n_steps) {\n      s &lt;- (j - 0.5) * actual_dt\n      P &lt;- compute_tpm(s, h12_all_fn, h13_all_fn, h23_all_fn, dt = 0.05)\n      P11 &lt;- P[1, 1]\n      h &lt;- h_fn(s)\n      integral &lt;- integral + P11 * h * actual_dt\n    }\n    ci[i] &lt;- integral\n  }\n  \n  return(ci)\n}\n\n\n\n\nShow code\n# True cumulative incidence\nci_12_true &lt;- compute_ci(eval_times, h12_true, h12_true, h13_true, h23_true)\nci_13_true &lt;- compute_ci(eval_times, h13_true, h12_true, h13_true, h23_true)\n\n# Julia CI\nci_12_julia &lt;- compute_ci(eval_times, h12_julia_fn, h12_julia_fn, h13_julia_fn, h23_julia_fn)\nci_13_julia &lt;- compute_ci(eval_times, h13_julia_fn, h12_julia_fn, h13_julia_fn, h23_julia_fn)\n\n# PAM CI\nci_12_pam &lt;- compute_ci(eval_times, h12_pam_fn, h12_pam_fn, h13_pam_fn, h23_pam_fn)\nci_13_pam &lt;- compute_ci(eval_times, h13_pam_fn, h12_pam_fn, h13_pam_fn, h23_pam_fn)\n\n# flexsurv CI\nci_12_flex &lt;- compute_ci(eval_times, h12_flex_fn, h12_flex_fn, h13_flex_fn, h23_flex_fn)\nci_13_flex &lt;- compute_ci(eval_times, h13_flex_fn, h12_flex_fn, h13_flex_fn, h23_flex_fn)\n\n# Total death CI = P(state 3)\nci_death_true &lt;- prev_true[, 3]\nci_death_julia &lt;- prev_julia[, 3]\nci_death_pam &lt;- prev_pam[, 3]\nci_death_flex &lt;- prev_flex[, 3]"
  },
  {
    "objectID": "spline_comparison_benchmark.html#cumulative-incidence-plots",
    "href": "spline_comparison_benchmark.html#cumulative-incidence-plots",
    "title": "Spline Methods Comparison",
    "section": "Cumulative Incidence Plots",
    "text": "Cumulative Incidence Plots\n\n\nShow code\nci_df &lt;- data.frame(\n  time = rep(eval_times, 12),\n  ci = c(\n    ci_12_true, ci_12_julia, ci_12_pam, ci_12_flex,\n    ci_13_true, ci_13_julia, ci_13_pam, ci_13_flex,\n    ci_death_true, ci_death_julia, ci_death_pam, ci_death_flex\n  ),\n  method = rep(rep(c(\"True\", \"Julia\", \"PAM (mgcv)\", \"flexsurv\"), each = length(eval_times)), 3),\n  event = rep(c(\"CI12: Illness\", \"CI13: Direct Death\", \"CI Total Death\"), \n              each = 4 * length(eval_times))\n)\n\nggplot(ci_df, aes(x = time, y = ci, color = method, linetype = method)) +\n  geom_line(linewidth = 1) +\n  scale_color_manual(values = c(\"True\" = \"black\", \"Julia\" = \"#E69F00\", \n                                 \"PAM (mgcv)\" = \"#56B4E9\", \"flexsurv\" = \"#009E73\")) +\n  scale_linetype_manual(values = c(\"True\" = \"solid\", \"Julia\" = \"dashed\", \n                                    \"PAM (mgcv)\" = \"dotted\", \"flexsurv\" = \"twodash\")) +\n  facet_wrap(~ event, scales = \"free_y\", ncol = 1) +\n  labs(\n    title = \"Cumulative Incidence Functions\",\n    subtitle = \"Starting from State 1 (Healthy)\",\n    x = \"Time\",\n    y = \"Cumulative Incidence\",\n    color = \"Method\",\n    linetype = \"Method\"\n  ) +\n  theme(legend.position = \"bottom\")"
  },
  {
    "objectID": "spline_comparison_benchmark.html#cumulative-incidence-rmse",
    "href": "spline_comparison_benchmark.html#cumulative-incidence-rmse",
    "title": "Spline Methods Comparison",
    "section": "Cumulative Incidence RMSE",
    "text": "Cumulative Incidence RMSE\n\n\nShow code\nci_rmse &lt;- data.frame(\n  Cumulative_Incidence = c(\"CI12 (Illness)\", \"CI13 (Direct Death)\", \"CI Total Death\"),\n  Julia = c(rmse(ci_12_true, ci_12_julia),\n            rmse(ci_13_true, ci_13_julia),\n            rmse(ci_death_true, ci_death_julia)),\n  PAM_mgcv = c(rmse(ci_12_true, ci_12_pam),\n                   rmse(ci_13_true, ci_13_pam),\n                   rmse(ci_death_true, ci_death_pam)),\n  flexsurv = c(rmse(ci_12_true, ci_12_flex),\n               rmse(ci_13_true, ci_13_flex),\n               rmse(ci_death_true, ci_death_flex))\n)\n\nkable(ci_rmse, digits = 5,\n      caption = \"Cumulative Incidence RMSE (vs True)\") %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n\n\n\nCumulative Incidence RMSE (vs True)\n\n\nCumulative_Incidence\nJulia\nPAM_mgcv\nflexsurv\n\n\n\n\nCI12 (Illness)\n0.00762\n0.00720\n0.00793\n\n\nCI13 (Direct Death)\n0.00911\n0.00791\n0.00948\n\n\nCI Total Death\n0.02269\n0.05474\n0.02337"
  },
  {
    "objectID": "spline_comparison_benchmark.html#overall-comparison",
    "href": "spline_comparison_benchmark.html#overall-comparison",
    "title": "Spline Methods Comparison",
    "section": "Overall Comparison",
    "text": "Overall Comparison\n\n\nShow code\n# Create summary\nsummary_df &lt;- data.frame(\n  Category = c(\"Hazard h12\", \"Hazard h13\", \"Hazard h23\",\n               \"Prevalence P1\", \"Prevalence P2\", \"Prevalence P3\",\n               \"CI Illness\", \"CI Direct Death\", \"CI Total Death\"),\n  Julia = c(hazard_rmse$Julia, prev_rmse$Julia, ci_rmse$Julia),\n  PAM_mgcv = c(hazard_rmse$PAM_mgcv, prev_rmse$PAM_mgcv, ci_rmse$PAM_mgcv),\n  flexsurv = c(hazard_rmse$flexsurv, prev_rmse$flexsurv, ci_rmse$flexsurv)\n)\n\n# Add winner column\nsummary_df$Winner &lt;- apply(summary_df[, 2:4], 1, function(x) {\n  methods &lt;- c(\"Julia\", \"PAM (mgcv)\", \"flexsurv\")\n  methods[which.min(x)]\n})\n\nkable(summary_df, digits = 5,\n      caption = \"Summary: RMSE by Method and Metric\") %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\")) %&gt;%\n  column_spec(5, bold = TRUE)\n\n\n\nSummary: RMSE by Method and Metric\n\n\nCategory\nJulia\nPAM_mgcv\nflexsurv\nWinner\n\n\n\n\nHazard h12\n0.01358\n0.00645\n0.00998\nPAM (mgcv)\n\n\nHazard h13\n0.00429\n0.00163\n0.00491\nPAM (mgcv)\n\n\nHazard h23\n0.13832\n0.11949\n0.22306\nPAM (mgcv)\n\n\nPrevalence P1\n0.00790\n0.01080\n0.00803\nJulia\n\n\nPrevalence P2\n0.01633\n0.05858\n0.01752\nJulia\n\n\nPrevalence P3\n0.02269\n0.05474\n0.02337\nJulia\n\n\nCI Illness\n0.00762\n0.00720\n0.00793\nPAM (mgcv)\n\n\nCI Direct Death\n0.00911\n0.00791\n0.00948\nPAM (mgcv)\n\n\nCI Total Death\n0.02269\n0.05474\n0.02337\nJulia"
  },
  {
    "objectID": "spline_comparison_benchmark.html#computation-time",
    "href": "spline_comparison_benchmark.html#computation-time",
    "title": "Spline Methods Comparison",
    "section": "Computation Time",
    "text": "Computation Time\n\n\nShow code\ntiming_df &lt;- data.frame(\n  Method = c(\"MultistateModels.jl (Julia)\", \"PAM (mgcv)\", \"flexsurv\"),\n  Fit_Time_s = c(julia_results$julia_fit$fit_time_seconds, t_pam, t_flex),\n  Approach = c(\"Joint likelihood (all transitions)\", \n               \"Separate GAMs (independent)\", \n               \"Separate MLE (independent)\")\n)\n\nkable(timing_df, digits = 2,\n      caption = \"Computation Time Comparison\") %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n\n\n\nComputation Time Comparison\n\n\nMethod\nFit_Time_s\nApproach\n\n\n\n\nMultistateModels.jl (Julia)\n13.22\nJoint likelihood (all transitions)\n\n\nPAM (mgcv)\n0.42\nSeparate GAMs (independent)\n\n\nflexsurv\n0.71\nSeparate MLE (independent)"
  },
  {
    "objectID": "spline_comparison_benchmark.html#conclusions",
    "href": "spline_comparison_benchmark.html#conclusions",
    "title": "Spline Methods Comparison",
    "section": "Conclusions",
    "text": "Conclusions\n\n\nShow code\n# Count wins\nwins &lt;- table(summary_df$Winner)\ncat(\"Method Wins (out of 9 metrics):\\n\")\n\n\nMethod Wins (out of 9 metrics):\n\n\nShow code\nprint(wins)\n\n\n\n     Julia PAM (mgcv) \n         4          5 \n\n\n\nKey Findings\n\nMultistateModels.jl uses joint likelihood estimation, fitting all transition hazards simultaneously. This captures the multistate structure correctly.\npammtools/mgcv fits each transition independently using GAMs with NCV smoothing parameter selection. While computationally efficient, it ignores cross-transition dependencies.\nflexsurv provides flexible parametric models with excellent hazard estimation but also fits transitions independently.\nFor state prevalence and cumulative incidence estimation, joint modeling (Julia) tends to outperform independent fitting approaches because it correctly accounts for competing risks.\n\n\n\nRecommendations\n\nFor exploratory analysis of individual hazard shapes: Any method works well\nFor accurate prevalence/cumulative incidence prediction: Joint likelihood (Julia) preferred\nFor large datasets with complex covariate structures: Consider pammtools for flexibility"
  },
  {
    "objectID": "spline_comparison_benchmark.html#standardized-knot-placement",
    "href": "spline_comparison_benchmark.html#standardized-knot-placement",
    "title": "Spline Methods Comparison",
    "section": "Standardized Knot Placement",
    "text": "Standardized Knot Placement\nAll three methods use the same interior knots: 9 knots placed at the decile quantiles (0.1, 0.2, …, 0.9) of the observed event times from the simulation.\n\n\nShow code\n# Load Julia results early to get standardized knots\njulia_results &lt;- fromJSON(\"../fixtures/illness_death_results.json\")\n\n# Get the standardized interior knots from Julia fit\ninterior_knots &lt;- julia_results$julia_fit$interior_knots\nn_interior_knots &lt;- length(interior_knots)\n\n# Boundary knots (min and max event times)\nevent_times &lt;- dat$tstop[dat$status == 1]\nboundary_knots &lt;- c(min(event_times), max(event_times))\n\ncat(\"Standardized Knot Specification:\\n\")\n\n\nStandardized Knot Specification:\n\n\nShow code\ncat(\"  Number of interior knots:\", n_interior_knots, \"\\n\")\n\n\n  Number of interior knots: 9 \n\n\nShow code\ncat(\"  Interior knots (decile quantiles):\\n\")\n\n\n  Interior knots (decile quantiles):\n\n\nShow code\nfor (i in seq_along(interior_knots)) {\n  cat(sprintf(\"    Q%d: %.3f\\n\", i * 10, interior_knots[i]))\n}\n\n\n    Q10: 2.196\n    Q20: 3.972\n    Q30: 5.714\n    Q40: 7.094\n    Q50: 8.695\n    Q60: 10.289\n    Q70: 11.994\n    Q80: 13.923\n    Q90: 16.380\n\n\nShow code\ncat(\"  Boundary knots:\", round(boundary_knots, 3), \"\\n\")\n\n\n  Boundary knots: 0.018 19.979 \n\n\nShow code\ncat(\"  Total spline df:\", n_interior_knots + 2, \"(interior + 2 for natural spline)\\n\")\n\n\n  Total spline df: 11 (interior + 2 for natural spline)"
  },
  {
    "objectID": "spline_comparison_benchmark.html#comparison-overview",
    "href": "spline_comparison_benchmark.html#comparison-overview",
    "title": "Spline Methods Comparison",
    "section": "Comparison Overview",
    "text": "Comparison Overview\nPackages:\n\nMultistateModels.jl (Julia): Penalized likelihood with P-splines using the General P-Spline (GPS) penalty from Li & Cao (2022), which correctly handles non-uniform knot spacing via weighted differences\nmgcv (R): Generalized additive models via piecewise-exponential/Poisson\nflexsurv (R): Flexible parametric survival models with spline hazards\n\nSmoothing Parameter Selection Methods:\n\n\n\n\n\n\n\n\n\nPackage\nMethod\nDescription\nReference\n\n\n\n\nMultistateModels.jl\nPIJCV\nNewton-approx LOO CV\nWood (2024)\n\n\nMultistateModels.jl\nPIJCV5\nNewton-approx 5-fold CV\nExtended from Wood (2024)\n\n\nMultistateModels.jl\nPIJCV10\nNewton-approx 10-fold CV\nExtended from Wood (2024)\n\n\nMultistateModels.jl\nPIJCV20\nNewton-approx 20-fold CV\nExtended from Wood (2024)\n\n\nMultistateModels.jl\nEFS\nExtended Fellner-Schall\nWood & Fasiolo (2017)\n\n\nMultistateModels.jl\nLOOCV\nExact Leave-One-Out CV\n(refits n times)\n\n\nMultistateModels.jl\nCV5\nExact 5-Fold CV\n(refits 5 times)\n\n\nMultistateModels.jl\nCV10\nExact 10-Fold CV\n(refits 10 times)\n\n\nMultistateModels.jl\nCV20\nExact 20-Fold CV\n(refits 20 times)\n\n\nmgcv\nGCV.Cp\nGeneralized CV via Poisson GAM\nWood (2017)\n\n\nmgcv\nREML\nRestricted ML\nWood (2011)"
  },
  {
    "objectID": "spline_comparison_benchmark.html#true-model-specification",
    "href": "spline_comparison_benchmark.html#true-model-specification",
    "title": "Spline Methods Comparison",
    "section": "True Model Specification",
    "text": "True Model Specification\nData are simulated from a Weibull hazard with:\n\nShape (\\(\\kappa\\)): 1.5 (increasing hazard)\nRate (\\(\\lambda\\)): 0.3\nSample size: 100\n\n\\[h(t) = \\kappa \\cdot \\lambda \\cdot t^{\\kappa - 1} = 1.5 \\times 0.3 \\times t^{0.5} = 0.45 \\sqrt{t}\\]\n\\[H(t) = \\lambda \\cdot t^{\\kappa} = 0.3 \\cdot t^{1.5}\\]\n\\[S(t) = \\exp(-H(t)) = \\exp(-0.3 \\cdot t^{1.5})\\]"
  },
  {
    "objectID": "spline_comparison_benchmark.html#load-julia-reference-data",
    "href": "spline_comparison_benchmark.html#load-julia-reference-data",
    "title": "Spline Methods Comparison",
    "section": "Load Julia Reference Data",
    "text": "Load Julia Reference Data\n\n\nShow code\n# Load reference data generated by Julia (all four smoothing methods)\njulia_ref_path &lt;- \"../fixtures/simple_benchmark_all_methods.json\"\njulia_ref &lt;- fromJSON(julia_ref_path)\n\n# Extract config\nn &lt;- julia_ref$config$n\ntrue_shape &lt;- julia_ref$config$true_shape\ntrue_rate &lt;- julia_ref$config$true_rate\nmax_time &lt;- julia_ref$config$max_time\n\n# Survival data\nsurv_data &lt;- data.frame(\n  time = julia_ref$data$time,\n  status = julia_ref$data$status\n)\n\ncat(\"=== Simple Survival Example ===\\n\")\n\n\n=== Simple Survival Example ===\n\n\nShow code\ncat(\"Sample size:\", n, \"\\n\")\n\n\nSample size: 100 \n\n\nShow code\ncat(\"True hazard: Weibull(shape =\", true_shape, \", rate =\", true_rate, \")\\n\")\n\n\nTrue hazard: Weibull(shape = 1.5 , rate = 0.3 )\n\n\nShow code\ncat(\"Events:\", sum(surv_data$status), \"\\n\")\n\n\nEvents: 96 \n\n\nShow code\ncat(\"Censored:\", sum(1 - surv_data$status), \"\\n\")\n\n\nCensored: 4 \n\n\nShow code\ncat(\"Time range: [\", round(min(surv_data$time), 3), \",\", round(max(surv_data$time), 3), \"]\\n\")\n\n\nTime range: [ 0.128 , 5 ]"
  },
  {
    "objectID": "spline_comparison_benchmark.html#true-hazard-and-survival-functions",
    "href": "spline_comparison_benchmark.html#true-hazard-and-survival-functions",
    "title": "Spline Methods Comparison",
    "section": "True Hazard and Survival Functions",
    "text": "True Hazard and Survival Functions\n\n\nShow code\n# True hazard function (Weibull with rate parameterization)\ntrue_hazard &lt;- function(t, shape = true_shape, rate = true_rate) {\n  shape * rate * t^(shape - 1)\n}\n\n# True cumulative hazard\ntrue_cumhaz &lt;- function(t, shape = true_shape, rate = true_rate) {\n  rate * t^shape\n}\n\n# True survival function\ntrue_surv &lt;- function(t, shape = true_shape, rate = true_rate) {\n  exp(-true_cumhaz(t, shape, rate))\n}\n\n# True CDF (cumulative incidence for single transition)\ntrue_cdf &lt;- function(t, shape = true_shape, rate = true_rate) {\n  1 - true_surv(t, shape, rate)\n}"
  },
  {
    "objectID": "spline_comparison_benchmark.html#julia-multistatemodels.jl-results",
    "href": "spline_comparison_benchmark.html#julia-multistatemodels.jl-results",
    "title": "Spline Methods Comparison",
    "section": "Julia MultistateModels.jl Results",
    "text": "Julia MultistateModels.jl Results\n\n\nShow code\n# Extract Julia results for all five methods\njulia_pijcv &lt;- julia_ref$results$PIJCV\njulia_gcv &lt;- julia_ref$results$GCV\njulia_perf &lt;- julia_ref$results$PERF\njulia_efs &lt;- julia_ref$results$EFS\njulia_loocv &lt;- julia_ref$results$LOOCV\n\ncat(\"=== Julia MultistateModels.jl Results ===\\n\")\n\n\n=== Julia MultistateModels.jl Results ===\n\n\nShow code\ncat(\"\\nPIJCV (Wood 2024 - Approximate LOOCV):\\n\")\n\n\n\nPIJCV (Wood 2024 - Approximate LOOCV):\n\n\nShow code\ncat(\"  λ =\", round(julia_pijcv$lambda, 3), \", EDF =\", round(julia_pijcv$edf, 2), \"\\n\")\n\n\n  λ = 14.88 , EDF = 2.09 \n\n\nShow code\ncat(\"\\nGCV (Wood 2017):\\n\")\n\n\n\nGCV (Wood 2017):\n\n\nShow code\ncat(\"  λ =\", round(julia_gcv$lambda, 3), \", EDF =\", round(julia_gcv$edf, 2), \"\\n\")\n\n\n  λ = 40.447 , EDF = 1.76 \n\n\nShow code\ncat(\"\\nPERF (Marra & Radice 2020):\\n\")\n\n\n\nPERF (Marra & Radice 2020):\n\n\nShow code\ncat(\"  λ =\", round(julia_perf$lambda, 3), \", EDF =\", round(julia_perf$edf, 2), \"\\n\")\n\n\n  λ = 20.086 , EDF = 1.99 \n\n\nShow code\ncat(\"\\nEFS (Wood & Fasiolo 2017):\\n\")\n\n\n\nEFS (Wood & Fasiolo 2017):\n\n\nShow code\ncat(\"  λ =\", round(julia_efs$lambda, 3), \", EDF =\", round(julia_efs$edf, 2), \"\\n\")\n\n\n  λ = 7.389 , EDF = 2.34 \n\n\nShow code\ncat(\"\\nLOOCV (Exact Leave-One-Out CV):\\n\")\n\n\n\nLOOCV (Exact Leave-One-Out CV):\n\n\nShow code\ncat(\"  λ =\", round(julia_loocv$lambda, 3), \", EDF =\", round(julia_loocv$edf, 2), \"\\n\")\n\n\n  λ = 13.464 , EDF = 2.12"
  },
  {
    "objectID": "spline_comparison_benchmark.html#mgcv-pam-fit",
    "href": "spline_comparison_benchmark.html#mgcv-pam-fit",
    "title": "Spline Methods Comparison",
    "section": "mgcv PAM Fit",
    "text": "mgcv PAM Fit\nWe fit a piecewise-exponential additive model (PAM) using mgcv::gam with Poisson likelihood. This transforms the survival problem into a Poisson regression. mgcv uses the exact same knots as Julia via manual knot specification for P-splines.\n\n\nShow code\n# Create Surv object\nsurv_obj &lt;- Surv(surv_data$time, surv_data$status)\n\n# Add id column if not present\nsurv_data_ped &lt;- surv_data %&gt;% mutate(id = row_number())\n\n# Use pammtools to create piecewise-exponential data (PED)\n# This handles the data transformation properly\nped &lt;- as_ped(\n  formula = Surv(time, status) ~ 1,\n  data = surv_data_ped,\n  id = \"id\"\n)\n\ncat(\"PED data structure (via pammtools):\\n\")\ncat(\"  Total pseudo-observations:\", nrow(ped), \"\\n\")\ncat(\"  Events in PED:\", sum(ped$ped_status), \"\\n\")\n\n# For mgcv P-splines with manual knots:\n# - k is the basis dimension\n# - m is the spline order (m=2 for cubic, with 2nd order difference penalty)\n# - Need k + m + 2 knots total\n# - The middle k - m knots must span the data range\n# - P-splines require EVENLY SPACED knots for proper penalty behavior\n\n# Julia uses 5 interior knots + 2 boundary = 7 middle knots\n# So k - m = 7, and with m = 2, we have k = 9\nk_mgcv &lt;- length(interior_knots) + 4  # 5 + 4 = 9\nm_order &lt;- 2\n\n# Build the full knot sequence for P-splines\n# Middle knots: [boundary_lower, interior_knots, boundary_upper]\nmiddle_knots &lt;- c(boundary_lower, interior_knots, boundary_upper)\n\n# Need (k + m + 2) - (k - m) = 2m + 2 = 6 padding knots (3 on each side)\n# P-splines require evenly spaced knots - use average spacing for padding\n# Note: Padding knots extend below 0 but this is just for basis construction;\n# the hazard is never evaluated at negative times\ndelta &lt;- mean(diff(middle_knots))\npadding_lower &lt;- boundary_lower - (3:1) * delta\npadding_upper &lt;- boundary_upper + (1:3) * delta\n\n# Full knot sequence\nmgcv_knots &lt;- c(padding_lower, middle_knots, padding_upper)\n\ncat(\"\\n=== Knot Configuration ===\\n\")\ncat(\"Julia interior knots:\", round(interior_knots, 3), \"\\n\")\ncat(\"Middle knots (k-m =\", length(middle_knots), \"):\", round(middle_knots, 3), \"\\n\")\ncat(\"Full P-spline knots (k+m+2 =\", length(mgcv_knots), \"):\", round(mgcv_knots, 3), \"\\n\")\ncat(\"Average knot spacing (delta):\", round(delta, 3), \"\\n\")\ncat(\"mgcv k =\", k_mgcv, \", m =\", m_order, \"\\n\")\n\n# Fit PAM with GCV using P-splines and manual knots\nfit_gcv &lt;- pamm(\n  ped_status ~ s(tend, bs = \"ps\", k = k_mgcv, m = c(m_order, m_order)),\n  data = ped,\n  method = \"GCV.Cp\",\n  knots = list(tend = mgcv_knots)\n)\n\n# Fit PAM with REML\nfit_reml &lt;- pamm(\n  ped_status ~ s(tend, bs = \"ps\", k = k_mgcv, m = c(m_order, m_order)),\n  data = ped,\n  method = \"REML\",\n  knots = list(tend = mgcv_knots)\n)\n\ncat(\"\\n=== mgcv/pammtools Results (P-splines with Julia knots) ===\\n\")\ncat(\"k =\", k_mgcv, \", m =\", m_order, \"\\n\")\ncat(\"Manual knots used:\", round(mgcv_knots, 3), \"\\n\")\n\ncat(\"\\nGCV.Cp:\\n\")\ncat(\"  sp =\", round(fit_gcv$sp, 6), \"\\n\")\ncat(\"  EDF =\", round(sum(fit_gcv$edf), 4), \"\\n\")\n\ncat(\"\\nREML:\\n\")\ncat(\"  sp =\", round(fit_reml$sp, 6), \"\\n\")\ncat(\"  EDF =\", round(sum(fit_reml$edf), 4), \"\\n\")"
  },
  {
    "objectID": "spline_comparison_benchmark.html#flexsurv-fit",
    "href": "spline_comparison_benchmark.html#flexsurv-fit",
    "title": "Spline Methods Comparison",
    "section": "flexsurv Fit",
    "text": "flexsurv Fit\n\n\nShow code\n# flexsurv uses knots on log(time) scale, so we need to transform\n# But we can specify explicit knots via the knots argument\n# flexsurv's \"knots\" argument takes the interior knots on the log scale\n\n# Transform interior knots to log scale for flexsurv\n# Note: flexsurv interprets knots as on log(time) scale\nlog_interior_knots &lt;- log(interior_knots)\n\ncat(\"Using same interior knots as Julia (transformed to log scale for flexsurv):\\n\")\ncat(\"  Original knots:\", round(interior_knots, 3), \"\\n\")\ncat(\"  Log-scale knots:\", round(log_interior_knots, 3), \"\\n\")\n\n# Fit flexsurv spline model with the same knots\nfit_flex &lt;- flexsurvspline(\n  Surv(time, status) ~ 1,\n  data = surv_data,\n  knots = log_interior_knots,  # Interior knots on log scale\n  scale = \"hazard\"\n)\n\n# Also fit true Weibull for reference\nfit_weibull &lt;- flexsurvreg(\n  Surv(time, status) ~ 1,\n  data = surv_data,\n  dist = \"weibullPH\"\n)\n\ncat(\"\\n=== flexsurv Results ===\\n\")\ncat(\"\\nSpline model (\", length(interior_knots), \" interior knots):\\n\", sep=\"\")\ncat(\"  AIC =\", round(AIC(fit_flex), 2), \"\\n\")\n\ncat(\"\\nWeibull fit (for reference):\\n\")\ncat(\"  Estimated shape:\", round(exp(fit_weibull$res[\"shape\", \"est\"]), 3), \"\\n\")\ncat(\"  Estimated scale:\", round(exp(fit_weibull$res[\"scale\", \"est\"]), 3), \"\\n\")\ncat(\"  True shape:\", true_shape, \"\\n\")\ncat(\"  True rate:\", true_rate, \"\\n\")"
  },
  {
    "objectID": "spline_comparison_benchmark.html#smoothing-parameter-summary",
    "href": "spline_comparison_benchmark.html#smoothing-parameter-summary",
    "title": "Spline Methods Comparison",
    "section": "Smoothing Parameter Summary",
    "text": "Smoothing Parameter Summary\n\n\nShow code\n# Collect all smoothing parameter results\nsmoothing_summary &lt;- data.frame(\n  Package = c(\"MultistateModels.jl\", \"MultistateModels.jl\", \"MultistateModels.jl\", \n              \"MultistateModels.jl\", \"mgcv\", \"mgcv\", \"flexsurv\"),\n  Method = c(\"PIJCV\", \"GCV\", \"PERF\", \"EFS\", \"GCV.Cp\", \"REML\", \"ML\"),\n  Lambda_or_sp = c(\n    julia_pijcv$lambda,\n    julia_gcv$lambda,\n    julia_perf$lambda,\n    julia_efs$lambda,\n    fit_gcv$sp,\n    fit_reml$sp,\n    NA  # flexsurv uses ML, no explicit smoothing parameter\n  ),\n  Log_Lambda = c(\n    julia_pijcv$log_lambda,\n    julia_gcv$log_lambda,\n    julia_perf$log_lambda,\n    julia_efs$log_lambda,\n    log(fit_gcv$sp),\n    log(fit_reml$sp),\n    NA\n  )\n)\n\nkable(smoothing_summary, digits = 3,\n      caption = \"Smoothing Parameter Estimates by Method\",\n      col.names = c(\"Package\", \"Method\", \"λ or sp\", \"log(λ)\")) %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n\n\n\nSmoothing Parameter Estimates by Method\n\n\nPackage\nMethod\nλ or sp\nlog(λ)\n\n\n\n\nMultistateModels.jl\nPIJCV\n20.086\n3.000\n\n\nMultistateModels.jl\nGCV\n54.598\n4.000\n\n\nMultistateModels.jl\nPERF\n20.086\n3.000\n\n\nMultistateModels.jl\nEFS\n9.974\n2.300\n\n\nmgcv\nGCV.Cp\n1930957.087\n14.474\n\n\nmgcv\nREML\n1133016.646\n13.940\n\n\nflexsurv\nML\nNA\nNA"
  },
  {
    "objectID": "spline_comparison_benchmark.html#hazard-function-comparison",
    "href": "spline_comparison_benchmark.html#hazard-function-comparison",
    "title": "Spline Methods Comparison",
    "section": "Hazard Function Comparison",
    "text": "Hazard Function Comparison\n\n\nShow code\n# Evaluation grid\neval_times &lt;- seq(0.01, max_time, length.out = 200)\n\n# True hazard\nh_true &lt;- true_hazard(eval_times)\n\n# mgcv/pammtools predictions - use pammtools helper\nnewdata_mgcv &lt;- data.frame(tend = eval_times)\nh_mgcv_gcv &lt;- predict(fit_gcv, newdata = newdata_mgcv, type = \"response\") / \n              mean(diff(ped$tend[1:2]))  # Hazard = rate / interval_length\nh_mgcv_reml &lt;- predict(fit_reml, newdata = newdata_mgcv, type = \"response\") /\n               mean(diff(ped$tend[1:2]))\n\n# Simpler: use pammtools add_hazard for proper hazard extraction\nhazard_mgcv_gcv &lt;- add_hazard(newdata_mgcv, fit_gcv)\nhazard_mgcv_reml &lt;- add_hazard(newdata_mgcv, fit_reml)\n\n# flexsurv hazard\nh_flex &lt;- summary(fit_flex, t = eval_times, type = \"hazard\")[[1]]$est\n\n# Julia curves from CSV (methods: PIJCV, EFS, LOOCV, CV10)\njulia_h &lt;- julia_curves %&gt;% filter(method == \"Julia PIJCV\") %&gt;% pull(hazard)\njulia_h_efs &lt;- julia_curves %&gt;% filter(method == \"Julia EFS\") %&gt;% pull(hazard)\njulia_h_loocv &lt;- julia_curves %&gt;% filter(method == \"Julia LOOCV\") %&gt;% pull(hazard)\njulia_h_cv10 &lt;- julia_curves %&gt;% filter(method == \"Julia CV10\") %&gt;% pull(hazard)\n\n# Combine for plotting\nhazard_df &lt;- data.frame(\n  time = rep(eval_times, 7),\n  hazard = c(h_true, julia_h, julia_h_efs, julia_h_loocv, julia_h_cv10,\n             hazard_mgcv_gcv$hazard, h_flex),\n  method = factor(rep(c(\"True (Weibull)\", \"Julia PIJCV\", \"Julia EFS\", \"Julia LOOCV\", \"Julia CV10\",\n                        \"mgcv GCV\", \"flexsurv\"), \n                      each = length(eval_times)),\n                  levels = c(\"True (Weibull)\", \"Julia PIJCV\", \"Julia EFS\", \"Julia LOOCV\", \"Julia CV10\",\n                             \"mgcv GCV\", \"flexsurv\"))\n)\n\nggplot(hazard_df, aes(x = time, y = hazard, color = method, linetype = method)) +\n  geom_line(linewidth = 1) +\n  geom_rug(data = surv_data %&gt;% filter(status == 1), \n           aes(x = time), inherit.aes = FALSE, \n           color = \"gray30\", alpha = 0.5, sides = \"b\") +\n  scale_color_manual(values = c(\"True (Weibull)\" = \"black\", \n                                 \"Julia PIJCV\" = \"#D55E00\",\n                                 \"Julia EFS\" = \"#56B4E9\",\n                                 \"Julia LOOCV\" = \"#0072B2\",\n                                 \"Julia CV10\" = \"#F0E442\",\n                                 \"mgcv GCV\" = \"#E69F00\",\n                                 \"flexsurv\" = \"#009E73\")) +\n  scale_linetype_manual(values = c(\"True (Weibull)\" = \"solid\",\n                                    \"Julia PIJCV\" = \"dashed\",\n                                    \"Julia EFS\" = \"twodash\",\n                                    \"Julia LOOCV\" = \"longdash\",\n                                    \"Julia CV10\" = \"dashed\",\n                                    \"mgcv GCV\" = \"dotdash\",\n                                    \"flexsurv\" = \"solid\")) +\n  labs(\n    title = \"Hazard Function Estimates\",\n    subtitle = paste0(\"True: Weibull(shape=\", true_shape, \", rate=\", true_rate, \"); rug = event times\"),\n    x = \"Time\",\n    y = \"Hazard h(t)\",\n    color = \"Method\",\n    linetype = \"Method\"\n  ) +\n  theme(legend.position = \"bottom\") +\n  guides(color = guide_legend(nrow = 2), linetype = guide_legend(nrow = 2))"
  },
  {
    "objectID": "spline_comparison_benchmark.html#cumulative-hazard-comparison",
    "href": "spline_comparison_benchmark.html#cumulative-hazard-comparison",
    "title": "Spline Methods Comparison",
    "section": "Cumulative Hazard Comparison",
    "text": "Cumulative Hazard Comparison\n\n\nShow code\n# True cumulative hazard\nH_true &lt;- true_cumhaz(eval_times)\n\n# Julia cumulative hazard from CSV (methods: PIJCV, EFS, LOOCV, CV10)\njulia_H &lt;- julia_curves %&gt;% filter(method == \"Julia PIJCV\") %&gt;% pull(cumhaz)\njulia_H_efs &lt;- julia_curves %&gt;% filter(method == \"Julia EFS\") %&gt;% pull(cumhaz)\njulia_H_loocv &lt;- julia_curves %&gt;% filter(method == \"Julia LOOCV\") %&gt;% pull(cumhaz)\njulia_H_cv10 &lt;- julia_curves %&gt;% filter(method == \"Julia CV10\") %&gt;% pull(cumhaz)\n\n# mgcv cumulative hazard - compute by numerical integration of hazard\nH_mgcv_gcv &lt;- cumsum(hazard_mgcv_gcv$hazard) * diff(eval_times)[1]\n\n# flexsurv cumulative hazard\nH_flex &lt;- summary(fit_flex, t = eval_times, type = \"cumhaz\")[[1]]$est\n\n# Combine for plotting\ncumhaz_df &lt;- data.frame(\n  time = rep(eval_times, 7),\n  cumhaz = c(H_true, julia_H, julia_H_efs, julia_H_loocv, julia_H_cv10,\n             H_mgcv_gcv, H_flex),\n  method = factor(rep(c(\"True (Weibull)\", \"Julia PIJCV\", \"Julia EFS\", \"Julia LOOCV\", \"Julia CV10\",\n                        \"mgcv GCV\", \"flexsurv\"), \n                      each = length(eval_times)),\n                  levels = c(\"True (Weibull)\", \"Julia PIJCV\", \"Julia EFS\", \"Julia LOOCV\", \"Julia CV10\",\n                             \"mgcv GCV\", \"flexsurv\"))\n)\n\nggplot(cumhaz_df, aes(x = time, y = cumhaz, color = method, linetype = method)) +\n  geom_line(linewidth = 1) +\n  scale_color_manual(values = c(\"True (Weibull)\" = \"black\", \n                                 \"Julia PIJCV\" = \"#D55E00\",\n                                 \"Julia EFS\" = \"#56B4E9\",\n                                 \"Julia LOOCV\" = \"#0072B2\",\n                                 \"Julia CV10\" = \"#F0E442\",\n                                 \"mgcv GCV\" = \"#E69F00\",\n                                 \"flexsurv\" = \"#009E73\")) +\n  scale_linetype_manual(values = c(\"True (Weibull)\" = \"solid\",\n                                    \"Julia PIJCV\" = \"dashed\",\n                                    \"Julia EFS\" = \"twodash\",\n                                    \"Julia LOOCV\" = \"longdash\",\n                                    \"Julia CV10\" = \"dashed\",\n                                    \"mgcv GCV\" = \"dotdash\",\n                                    \"flexsurv\" = \"solid\")) +\n  labs(\n    title = \"Cumulative Hazard Estimates\",\n    x = \"Time\",\n    y = \"Cumulative Hazard H(t)\",\n    color = \"Method\",\n    linetype = \"Method\"\n  ) +\n  theme(legend.position = \"bottom\") +\n  guides(color = guide_legend(nrow = 2), linetype = guide_legend(nrow = 2))"
  },
  {
    "objectID": "spline_comparison_benchmark.html#survival-and-cumulative-incidence-curves",
    "href": "spline_comparison_benchmark.html#survival-and-cumulative-incidence-curves",
    "title": "Spline Methods Comparison",
    "section": "Survival and Cumulative Incidence Curves",
    "text": "Survival and Cumulative Incidence Curves\n\n\nShow code\n# True survival/CIF\nS_true &lt;- true_surv(eval_times)\nF_true &lt;- true_cdf(eval_times)\n\n# Julia survival from CSV (methods: PIJCV, EFS, LOOCV, CV10)\njulia_S &lt;- julia_curves %&gt;% filter(method == \"Julia PIJCV\") %&gt;% pull(survival)\njulia_S_efs &lt;- julia_curves %&gt;% filter(method == \"Julia EFS\") %&gt;% pull(survival)\njulia_S_loocv &lt;- julia_curves %&gt;% filter(method == \"Julia LOOCV\") %&gt;% pull(survival)\njulia_S_cv10 &lt;- julia_curves %&gt;% filter(method == \"Julia CV10\") %&gt;% pull(survival)\n\n# Julia CIF\nF_julia &lt;- 1 - julia_S\nF_julia_efs &lt;- 1 - julia_S_efs\nF_julia_loocv &lt;- 1 - julia_S_loocv\nF_julia_cv10 &lt;- 1 - julia_S_cv10\n\n# mgcv survival - compute from cumulative hazard (S = exp(-H))\nS_mgcv_gcv &lt;- exp(-H_mgcv_gcv)\nF_mgcv_gcv &lt;- 1 - S_mgcv_gcv\n\n# flexsurv survival\nS_flex &lt;- summary(fit_flex, t = eval_times, type = \"survival\")[[1]]$est\nF_flex &lt;- 1 - S_flex\n\n# Color palette for all methods\nmethod_colors &lt;- c(\"True (Weibull)\" = \"black\", \n                   \"Julia PIJCV\" = \"#D55E00\",\n                   \"Julia EFS\" = \"#56B4E9\",\n                   \"Julia LOOCV\" = \"#0072B2\",\n                   \"Julia CV10\" = \"#F0E442\",\n                   \"mgcv GCV\" = \"#E69F00\",\n                   \"flexsurv\" = \"#009E73\")\n\nmethod_linetypes &lt;- c(\"True (Weibull)\" = \"solid\",\n                      \"Julia PIJCV\" = \"dashed\",\n                      \"Julia EFS\" = \"twodash\",\n                      \"Julia LOOCV\" = \"longdash\",\n                      \"Julia CV10\" = \"dashed\",\n                      \"mgcv GCV\" = \"dotdash\",\n                      \"flexsurv\" = \"solid\")\n\nmethod_levels &lt;- c(\"True (Weibull)\", \"Julia PIJCV\", \"Julia EFS\", \"Julia LOOCV\", \"Julia CV10\",\n                   \"mgcv GCV\", \"flexsurv\")\n\n# Combine survival curves\nsurv_df &lt;- data.frame(\n  time = rep(eval_times, 7),\n  survival = c(S_true, julia_S, julia_S_efs, julia_S_loocv, julia_S_cv10,\n               S_mgcv_gcv, S_flex),\n  method = factor(rep(method_levels, each = length(eval_times)), levels = method_levels)\n)\n\n# Combine CIF curves\ncif_df &lt;- data.frame(\n  time = rep(eval_times, 7),\n  cif = c(F_true, F_julia, F_julia_efs, F_julia_loocv, F_julia_cv10,\n          F_mgcv_gcv, F_flex),\n  method = factor(rep(method_levels, each = length(eval_times)), levels = method_levels)\n)\n\n# Kaplan-Meier for reference\nkm_fit &lt;- survfit(Surv(time, status) ~ 1, data = surv_data)\n\n# Plot survival\np_surv &lt;- ggplot(surv_df, aes(x = time, y = survival, color = method, linetype = method)) +\n  geom_line(linewidth = 1) +\n  geom_step(data = data.frame(time = km_fit$time, survival = km_fit$surv),\n            aes(x = time, y = survival), \n            inherit.aes = FALSE, color = \"gray50\", alpha = 0.5, linewidth = 0.8) +\n  scale_color_manual(values = method_colors) +\n  scale_linetype_manual(values = method_linetypes) +\n  labs(\n    title = \"Survival Function S(t)\",\n    subtitle = \"Gray step function = Kaplan-Meier estimate\",\n    x = \"Time\",\n    y = \"S(t)\",\n    color = \"Method\",\n    linetype = \"Method\"\n  ) +\n  theme(legend.position = \"bottom\") +\n  guides(color = guide_legend(nrow = 2), linetype = guide_legend(nrow = 2))\n\n# Plot CIF\np_cif &lt;- ggplot(cif_df, aes(x = time, y = cif, color = method, linetype = method)) +\n  geom_line(linewidth = 1) +\n  geom_step(data = data.frame(time = km_fit$time, cif = 1 - km_fit$surv),\n            aes(x = time, y = cif), \n            inherit.aes = FALSE, color = \"gray50\", alpha = 0.5, linewidth = 0.8) +\n  geom_rug(data = surv_data %&gt;% filter(status == 1), \n           aes(x = time), inherit.aes = FALSE, \n           color = \"gray30\", alpha = 0.5, sides = \"b\") +\n  scale_color_manual(values = method_colors) +\n  scale_linetype_manual(values = method_linetypes) +\n  labs(\n    title = \"Cumulative Incidence F(t) = 1 - S(t)\",\n    subtitle = \"Gray step function = 1 - Kaplan-Meier; rug = event times\",\n    x = \"Time\",\n    y = \"F(t)\",\n    color = \"Method\",\n    linetype = \"Method\"\n  ) +\n  theme(legend.position = \"bottom\") +\n  guides(color = guide_legend(nrow = 2), linetype = guide_legend(nrow = 2))\n\np_surv / p_cif"
  },
  {
    "objectID": "spline_comparison_benchmark.html#accuracy-metrics",
    "href": "spline_comparison_benchmark.html#accuracy-metrics",
    "title": "Spline Methods Comparison",
    "section": "Accuracy Metrics",
    "text": "Accuracy Metrics\n\n\nShow code\n# RMSE function\nrmse &lt;- function(true, est) sqrt(mean((true - est)^2))\n\n# Get all Julia methods from CSV\njulia_methods &lt;- unique(julia_curves$method)\n\n# Calculate RMSE for all Julia methods\njulia_metrics &lt;- lapply(julia_methods, function(m) {\n  h &lt;- julia_curves %&gt;% filter(method == m) %&gt;% pull(hazard)\n  H &lt;- julia_curves %&gt;% filter(method == m) %&gt;% pull(cumhaz)\n  S &lt;- julia_curves %&gt;% filter(method == m) %&gt;% pull(survival)\n  \n  data.frame(\n    Package = \"MultistateModels.jl\",\n    Method = gsub(\"Julia \", \"\", m),\n    Hazard_RMSE = rmse(h_true, h),\n    CumHaz_RMSE = rmse(H_true, H),\n    Survival_RMSE = rmse(S_true, S)\n  )\n}) %&gt;% bind_rows()\n\n# Add R package results\nr_metrics &lt;- data.frame(\n  Package = c(\"mgcv\", \"flexsurv\"),\n  Method = c(\"GCV.Cp\", \"spline\"),\n  Hazard_RMSE = c(rmse(h_true, hazard_mgcv_gcv$hazard), rmse(h_true, h_flex)),\n  CumHaz_RMSE = c(rmse(H_true, H_mgcv_gcv), rmse(H_true, H_flex)),\n  Survival_RMSE = c(rmse(S_true, S_mgcv_gcv), rmse(S_true, S_flex))\n)\n\n# Combine and order\nmetrics_df &lt;- rbind(julia_metrics, r_metrics)\n\n# Order Julia methods logically (no GCV)\njulia_order &lt;- c(\"PIJCV\", \"PIJCV5\", \"PIJCV10\", \"PIJCV20\", \n                 \"EFS\", \"LOOCV\", \"CV5\", \"CV10\", \"CV20\")\nmetrics_df$Method &lt;- factor(metrics_df$Method, \n                            levels = c(julia_order, \"GCV.Cp\", \"spline\"))\nmetrics_df &lt;- metrics_df %&gt;% arrange(Method)\n\n# Dynamically determine row indices\nn_julia &lt;- nrow(julia_metrics)\nn_r &lt;- nrow(r_metrics)\n\nkable(metrics_df, digits = 5,\n      caption = \"RMSE vs True Weibull Functions\",\n      col.names = c(\"Package\", \"Method\", \"Hazard\", \"Cum. Hazard\", \"Survival\")) %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\")) %&gt;%\n  pack_rows(\"MultistateModels.jl\", 1, n_julia) %&gt;%\n  pack_rows(\"R\", n_julia + 1, n_julia + n_r)\n\n\n\nRMSE vs True Weibull Functions\n\n\nPackage\nMethod\nHazard\nCum. Hazard\nSurvival\n\n\n\n\nMultistateModels.jl\n\n\nMultistateModels.jl\nPIJCV\n0.10004\n0.19374\n0.03596\n\n\nMultistateModels.jl\nPIJCV5\n0.10004\n0.19374\n0.03596\n\n\nMultistateModels.jl\nPIJCV10\n0.10004\n0.19374\n0.03596\n\n\nMultistateModels.jl\nPIJCV20\n0.10004\n0.19374\n0.03596\n\n\nMultistateModels.jl\nEFS\n0.09035\n0.18065\n0.03499\n\n\nMultistateModels.jl\nLOOCV\n0.10004\n0.19374\n0.03596\n\n\nMultistateModels.jl\nCV5\n0.10004\n0.19374\n0.03596\n\n\nMultistateModels.jl\nCV10\n0.10004\n0.19374\n0.03596\n\n\nMultistateModels.jl\nCV20\n0.10004\n0.19374\n0.03596\n\n\nR\n\n\nmgcv\nGCV.Cp\n0.08143\n0.17682\n0.03317\n\n\nflexsurv\nspline\n0.09084\n0.15412\n0.02948"
  },
  {
    "objectID": "spline_comparison_benchmark.html#notes-on-julia-vs-r-smoothing-parameters",
    "href": "spline_comparison_benchmark.html#notes-on-julia-vs-r-smoothing-parameters",
    "title": "Spline Methods Comparison",
    "section": "Notes on Julia vs R Smoothing Parameters",
    "text": "Notes on Julia vs R Smoothing Parameters\nThe Julia MultistateModels.jl package uses exact survival likelihood (not PAM/Poisson approximation), which leads to different smoothing parameter scales:\nJulia (exact likelihood):\n\nPIJCV: λ ≈ 20.1 (log λ ≈ 3)\nGCV: λ ≈ 54.6 (log λ ≈ 4)\nPERF: λ ≈ 20.1 (log λ ≈ 3)\nEFS: λ ≈ 10 (log λ ≈ 2.3)\n\nmgcv (PAM/Poisson):\n\nGCV: sp ≈ 1.9309571^{6} (log sp ≈ 14.5)\nREML: sp ≈ 1.1330166^{6} (log sp ≈ 13.9)\n\nThe difference in optimal smoothing parameter scales is expected due to:\n\nDifferent likelihood formulations (exact vs pseudo-likelihood)\nDifferent penalty matrix scaling conventions\nDifferent effective sample sizes (n subjects vs n×k pseudo-observations)\n\nBoth approaches produce valid smoothing; the raw λ values are not directly comparable."
  },
  {
    "objectID": "spline_comparison_benchmark.html#effective-degrees-of-freedom-comparison",
    "href": "spline_comparison_benchmark.html#effective-degrees-of-freedom-comparison",
    "title": "Spline Methods Comparison",
    "section": "Effective Degrees of Freedom Comparison",
    "text": "Effective Degrees of Freedom Comparison\nThe effective degrees of freedom (EDF) is the proper metric for comparing smoothing across different software packages. EDF measures how many parameters the smooth effectively uses, independent of λ scaling conventions.\n\n\nShow code\n# Collect EDF results - this is the key comparison metric\nedf_summary &lt;- rbind(\n  julia_summary %&gt;% \n    mutate(Package = \"MultistateModels.jl\") %&gt;%\n    select(Package, Method = method, EDF = edf, Lambda_or_sp = lambda),\n  data.frame(\n    Package = c(\"mgcv\", \"mgcv\"),\n    Method = c(\"GCV.Cp\", \"REML\"),\n    EDF = c(sum(fit_gcv$edf), sum(fit_reml$edf)),\n    Lambda_or_sp = c(fit_gcv$sp, fit_reml$sp)\n  )\n)\n\nkable(edf_summary, digits = 4,\n      caption = \"Effective Degrees of Freedom by Method (Key Comparison)\",\n      col.names = c(\"Package\", \"Method\", \"EDF\", \"λ or sp\")) %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\")) %&gt;%\n  column_spec(3, bold = TRUE, background = \"#f0f9e8\")\n\n\n\nEffective Degrees of Freedom by Method (Key Comparison)\n\n\nPackage\nMethod\nEDF\nλ or sp\n\n\n\n\nMultistateModels.jl\nPIJCV\n2.2110\n9.9742\n\n\nMultistateModels.jl\nPIJCV5\n2.2110\n9.9742\n\n\nMultistateModels.jl\nPIJCV10\n2.2110\n9.9742\n\n\nMultistateModels.jl\nPIJCV20\n2.2110\n9.9742\n\n\nMultistateModels.jl\nEFS\n2.4619\n5.4739\n\n\nMultistateModels.jl\nLOOCV\n2.2110\n9.9742\n\n\nMultistateModels.jl\nCV5\n2.2110\n9.9742\n\n\nMultistateModels.jl\nCV10\n2.2110\n9.9742\n\n\nMultistateModels.jl\nCV20\n2.2110\n9.9742\n\n\nmgcv\nGCV.Cp\n2.0023\n312141.0244\n\n\nmgcv\nREML\n2.0005\n1541837.6019"
  },
  {
    "objectID": "spline_comparison_benchmark.html#notes-on-comparison",
    "href": "spline_comparison_benchmark.html#notes-on-comparison",
    "title": "Spline Methods Comparison",
    "section": "Notes on Comparison",
    "text": "Notes on Comparison\n\nPenalty Matrix Comparison\nUsing the gratia package, we can extract the penalty matrix from mgcv and compare it directly to the Julia implementation. Both use second-order difference penalties (D’D).\n\n\nShow code\nlibrary(gratia)\n\n# Extract penalty matrix from mgcv smooth\nmgcv_penalty_df &lt;- penalty(fit_gcv)\n\n# Reshape to matrix form\nS_mgcv &lt;- mgcv_penalty_df %&gt;%\n  select(.row, .col, .value) %&gt;%\n  pivot_wider(names_from = .col, values_from = .value) %&gt;%\n  select(-.row) %&gt;%\n  as.matrix()\n\n# Load Julia penalty matrix (already a matrix from jsonlite)\nS_julia &lt;- julia_ref$penalty_matrix$S\n\ncat(\"=== Penalty Matrix Comparison ===\\n\\n\")\n\n\n=== Penalty Matrix Comparison ===\n\n\nShow code\ncat(\"mgcv penalty matrix dimensions:\", dim(S_mgcv), \"\\n\")\n\n\nmgcv penalty matrix dimensions: 9 9 \n\n\nShow code\ncat(\"Julia penalty matrix dimensions:\", dim(S_julia), \"\\n\")\n\n\nJulia penalty matrix dimensions: 5 5 \n\n\nShow code\n# Note: dimensions may differ due to different basis sizes\n# mgcv k=10 gives 9 basis functions after identifiability constraints\n# Julia uses 7 basis functions - 3 fixed (intercept + 2 boundary) = 4 penalized\n\n# Normalize for comparison (scale by maximum entry)\nS_mgcv_norm &lt;- S_mgcv / max(abs(S_mgcv))\nS_julia_norm &lt;- S_julia / max(abs(S_julia))\n\n# Both are second-order difference penalties (D'D), so normalized structure \n# should show similar banded pattern\n\ncat(\"\\n=== Normalized Penalty Matrices ===\\n\")\n\n\n\n=== Normalized Penalty Matrices ===\n\n\nShow code\ncat(\"\\nmgcv (normalized):\\n\")\n\n\n\nmgcv (normalized):\n\n\nShow code\nprint(round(S_mgcv_norm, 3))\n\n\n          F1     F2     F3     F4     F5     F6     F7     F8     F9\n [1,]  1.000 -0.472  0.333  0.121  0.078  0.051  0.026  0.014  0.000\n [2,] -0.472  0.668 -0.642  0.102 -0.035 -0.016 -0.018 -0.001 -0.002\n [3,]  0.333 -0.642  0.961 -0.558  0.170  0.017  0.004  0.006 -0.001\n [4,]  0.121  0.102 -0.558  0.912 -0.585  0.158  0.001  0.004 -0.001\n [5,]  0.078 -0.035  0.170 -0.585  0.898 -0.590  0.149  0.002 -0.001\n [6,]  0.051 -0.016  0.017  0.158 -0.590  0.897 -0.594  0.150  0.000\n [7,]  0.026 -0.018  0.004  0.001  0.149 -0.594  0.892 -0.595  0.149\n [8,]  0.014 -0.001  0.006  0.004  0.002  0.150 -0.595  0.745 -0.298\n [9,]  0.000 -0.002 -0.001 -0.001 -0.001  0.000  0.149 -0.298  0.149\n\n\nShow code\ncat(\"\\nJulia (normalized):\\n\")\n\n\n\nJulia (normalized):\n\n\nShow code\nprint(round(S_julia_norm, 3))\n\n\n       [,1]   [,2]   [,3]   [,4]   [,5]\n[1,]  0.692 -0.785  0.092  0.000  0.000\n[2,] -0.785  1.000 -0.262  0.046  0.000\n[3,]  0.092 -0.262  0.265 -0.117  0.021\n[4,]  0.000  0.046 -0.117  0.180 -0.109\n[5,]  0.000  0.000  0.021 -0.109  0.089\n\n\nShow code\n# Check structure: both should have banded structure from D'D\ncat(\"\\n=== Eigenvalue Analysis ===\\n\")\n\n\n\n=== Eigenvalue Analysis ===\n\n\nShow code\ncat(\"\\nmgcv penalty eigenvalues:\\n\")\n\n\n\nmgcv penalty eigenvalues:\n\n\nShow code\nprint(round(eigen(S_mgcv)$values, 4))\n\n\n[1] 0.9441 0.7916 0.5848 0.3726 0.1965 0.0789 0.0198 0.0028 0.0000\n\n\nShow code\ncat(\"\\nJulia penalty eigenvalues:\\n\")\n\n\n\nJulia penalty eigenvalues:\n\n\nShow code\nprint(round(eigen(S_julia)$values, 4))\n\n\n[1] 27.5534  5.8664  2.6143  0.1464  0.0000\n\n\nShow code\n# Key insight: the SCALE of the eigenvalues differs, but both are valid D'D penalties\ncat(\"\\n=== Scaling Metrics ===\\n\")\n\n\n\n=== Scaling Metrics ===\n\n\nShow code\ncat(\"mgcv penalty Frobenius norm:\", round(norm(S_mgcv, \"F\"), 4), \"\\n\")\n\n\nmgcv penalty Frobenius norm: 1.4297 \n\n\nShow code\ncat(\"Julia penalty Frobenius norm:\", round(norm(S_julia, \"F\"), 4), \"\\n\")\n\n\nJulia penalty Frobenius norm: 28.2925 \n\n\nShow code\ncat(\"\\nRatio (mgcv/Julia):\", round(norm(S_mgcv, \"F\") / norm(S_julia, \"F\"), 2), \"\\n\")\n\n\n\nRatio (mgcv/Julia): 0.05 \n\n\n\n\nVisualize Penalty Matrices\n\n\nShow code\nlibrary(reshape2)\n\n# Prepare data for plotting\nplot_penalty &lt;- function(S, title) {\n  S_df &lt;- melt(S)\n  colnames(S_df) &lt;- c(\"Row\", \"Col\", \"Value\")\n  \n  ggplot(S_df, aes(x = Col, y = Row, fill = Value)) +\n    geom_tile() +\n    scale_fill_gradient2(low = \"blue\", mid = \"white\", high = \"red\", midpoint = 0) +\n    scale_y_reverse() +\n    coord_equal() +\n    labs(title = title, x = \"Column\", y = \"Row\") +\n    theme_minimal()\n}\n\np_mgcv &lt;- plot_penalty(S_mgcv_norm, \"mgcv Penalty (normalized)\")\np_julia &lt;- plot_penalty(S_julia_norm, \"Julia Penalty (normalized)\")\n\np_mgcv + p_julia + plot_layout(guides = \"collect\")\n\n\n\n\n\n\n\n\n\n\n\nEDF vs λ Scaling\nThe effective degrees of freedom (EDF) is the proper metric for comparing smoothing across packages. Despite the ~3 orders of magnitude difference in raw λ values:\n\n\n\nPackage\nMethod\nEDF\nλ or sp\n\n\n\n\nJulia\nPIJCV\n2.09\n14.9\n\n\nJulia\nGCV\n1.76\n40.4\n\n\nJulia\nPERF\n1.99\n20.1\n\n\nJulia\nEFS\n2.34\n7.4\n\n\nJulia\nLOOCV\n2.12\n13.5\n\n\nmgcv\nGCV.Cp\n2\n1.9309571^{6}\n\n\nmgcv\nREML\n2\n1.1330166^{6}\n\n\nmgcv\nNCV/LOOCV\n2\n5.9910362^{5}\n\n\n\nThe EDF values are in excellent agreement (1.5-2.5), confirming that both approaches select similar model complexity despite different λ scales.\nNCV (Neighbourhood Cross-Validation) in mgcv with nei=NULL (the default) is exactly leave-one-out cross-validation (LOOCV). This is the same criterion as PIJCV (Wood 2024), which uses an approximate LOOCV formula based on a Laplace approximation. Julia’s LOOCV method provides the exact LOOCV criterion for direct comparison.\nThe scale difference arises from:\n\nEffective sample size: Julia uses n=100 subjects; mgcv’s PAM uses ~1200 pseudo-observations\nPenalty matrix normalization: Different scaling conventions\nLikelihood formulation: Exact survival vs Poisson pseudo-likelihood\n\n\n\nSoftware Packages Compared\n\n\n\n\n\n\n\n\nPackage\nApproach\nNotes\n\n\n\n\nMultistateModels.jl\nExact penalized likelihood with P-splines\nAll 5 smoothing methods (PIJCV, GCV, PERF, EFS, LOOCV)\n\n\nmgcv\nPAM (Poisson GAM on piecewise-exponential data)\nGCV.Cp, REML, and NCV/LOOCV for smoothing selection\n\n\nflexsurv\nSpline hazard via ML (no explicit smoothing parameter)\nUses natural splines, not penalized\n\n\nflexmsm\nIntensity-based multistate with GAM smooths\nSupports exact times via living.exact; requires 3+ state models\n\n\n\nNote on flexmsm: While flexmsm does support exactly observed transition times (via the living.exact argument), the package is designed for illness-death and more complex multistate models. Simple two-state survival models are not directly supported."
  },
  {
    "objectID": "spline_comparison_benchmark.html#simulate-data-in-julia",
    "href": "spline_comparison_benchmark.html#simulate-data-in-julia",
    "title": "Spline Methods Comparison",
    "section": "Simulate Data in Julia",
    "text": "Simulate Data in Julia\n\n\nShow code\n# Configuration\nn = 100\ntrue_shape = 1.5\ntrue_rate = 0.3\nmax_time = 5.0\nseed = 12345\n\nRandom.seed!(seed)\n\n# Simulate Weibull survival data\nE = -log.(rand(n))\nevent_times = (E ./ true_rate) .^ (1 / true_shape)\nobs_times = min.(event_times, max_time)\nstatus = Int.(event_times .&lt;= max_time)\n\nprintln(\"=== Simple Survival Data ===\")\nprintln(\"n = $n\")\nprintln(\"Events: $(sum(status))\")\nprintln(\"Censored: $(n - sum(status))\")\nprintln(\"Time range: [$(round(minimum(obs_times), digits=3)), $(round(maximum(obs_times), digits=3))]\")\n\n# Create multistate model data\nsurv_data = DataFrame(\n    id = 1:n,\n    tstart = zeros(n),\n    tstop = obs_times,\n    statefrom = ones(Int, n),\n    stateto = ifelse.(status .== 1, 2, 1),\n    obstype = ones(Int, n)\n)\n\n# Save to CSV for R to read\nCSV.write(\"_surv_data.csv\", DataFrame(time = obs_times, status = status))\n\n\n=== Simple Survival Data ===\nn = 100\nEvents: 96\nCensored: 4\nTime range: [0.128, 5.0]\n\n\n\"_surv_data.csv\""
  },
  {
    "objectID": "spline_comparison_benchmark.html#fit-multistatemodels.jl-splines",
    "href": "spline_comparison_benchmark.html#fit-multistatemodels.jl-splines",
    "title": "Spline Methods Comparison",
    "section": "Fit MultistateModels.jl Splines",
    "text": "Fit MultistateModels.jl Splines\n\n\nShow code\n# Define model with spline hazard\nh12 = Hazard(@formula(0 ~ 1), \"sp\", 1, 2;\n             degree = 3,\n             knots = [1.0, 2.0, 3.0],\n             boundaryknots = [0.0, 5.0],\n             natural_spline = true)\nmodel = multistatemodel(h12; data=surv_data)\n\n# Fit with each smoothing method\nprintln(\"\\nFitting with PIJCV method...\")\nresult_pijcv = select_smoothing_parameters(model, SplinePenalty(); \n                                           method = :pijcv, verbose = false)\nprintln(\"  PIJCV λ = $(round(result_pijcv.lambda[1], digits=2)), EDF = $(round(result_pijcv.edf.total, digits=2))\")\n\nprintln(\"\\nFitting with GCV method...\")\nresult_gcv = select_smoothing_parameters(model, SplinePenalty(); \n                                         method = :gcv, verbose = false)\nprintln(\"  GCV λ = $(round(result_gcv.lambda[1], digits=2)), EDF = $(round(result_gcv.edf.total, digits=2))\")\n\nprintln(\"\\nFitting with LOOCV method...\")\nresult_loocv = select_smoothing_parameters(model, SplinePenalty(); \n                                           method = :loocv, verbose = false)\nprintln(\"  LOOCV λ = $(round(result_loocv.lambda[1], digits=2)), EDF = $(round(result_loocv.edf.total, digits=2))\")\n\n\n\n******************************************************************************\nThis program contains Ipopt, a library for large-scale nonlinear optimization.\n Ipopt is released as open source code under the Eclipse Public License (EPL).\n         For more information visit https://github.com/coin-or/Ipopt\n******************************************************************************\n\n\nFitting with PIJCV method...\n  PIJCV λ = 14.88, EDF = 2.09\n\nFitting with GCV method...\n  GCV λ = 40.45, EDF = 1.76\n\nFitting with LOOCV method...\n  LOOCV λ = 13.46, EDF = 2.12"
  },
  {
    "objectID": "spline_comparison_benchmark.html#compute-julia-hazard-curves",
    "href": "spline_comparison_benchmark.html#compute-julia-hazard-curves",
    "title": "Spline Methods Comparison",
    "section": "Compute Julia Hazard Curves",
    "text": "Compute Julia Hazard Curves\n\n\nShow code\n# Evaluation grid\neval_times = collect(range(0.01, max_time, length=200))\n\n# Function to evaluate hazard at a grid of times\nfunction evaluate_curves(model, beta, eval_times)\n    haz = model.hazards[1]\n    \n    # Use hazard_fn and cumhaz_fn (the callable functions)\n    hazard_vals = [haz.hazard_fn(t, beta, ()) for t in eval_times]\n    cumhaz_vals = [haz.cumhaz_fn(0.0, t, beta, ()) for t in eval_times]\n    survival_vals = exp.(-cumhaz_vals)\n    \n    return (hazard = hazard_vals, cumhaz = cumhaz_vals, survival = survival_vals)\nend\n\n# Compute curves for each method\ncurves_pijcv = evaluate_curves(model, result_pijcv.beta, eval_times)\ncurves_gcv = evaluate_curves(model, result_gcv.beta, eval_times)\ncurves_loocv = evaluate_curves(model, result_loocv.beta, eval_times)\n\n# Save Julia results for R plotting\njulia_results = DataFrame(\n    time = repeat(eval_times, 3),\n    hazard = vcat(curves_pijcv.hazard, curves_gcv.hazard, curves_loocv.hazard),\n    cumhaz = vcat(curves_pijcv.cumhaz, curves_gcv.cumhaz, curves_loocv.cumhaz),\n    survival = vcat(curves_pijcv.survival, curves_gcv.survival, curves_loocv.survival),\n    method = repeat([\"Julia PIJCV\", \"Julia GCV\", \"Julia LOOCV\"], inner=length(eval_times))\n)\nCSV.write(\"_julia_curves.csv\", julia_results)\n\n# Save summary stats\njulia_summary = DataFrame(\n    method = [\"PIJCV\", \"GCV\", \"LOOCV\"],\n    lambda = [result_pijcv.lambda[1], result_gcv.lambda[1], result_loocv.lambda[1]],\n    edf = [result_pijcv.edf.total, result_gcv.edf.total, result_loocv.edf.total]\n)\nCSV.write(\"_julia_summary.csv\", julia_summary)\n\nprintln(\"Julia curves computed and saved.\")\n\n\nJulia curves computed and saved."
  },
  {
    "objectID": "spline_comparison_benchmark.html#load-julia-results-in-r",
    "href": "spline_comparison_benchmark.html#load-julia-results-in-r",
    "title": "Spline Methods Comparison",
    "section": "Load Julia Results in R",
    "text": "Load Julia Results in R\n\n\nShow code\n# Load simulated data\nsurv_data &lt;- read.csv(\"_surv_data.csv\")\nn &lt;- nrow(surv_data)\ntrue_shape &lt;- 1.5\ntrue_rate &lt;- 0.3\nmax_time &lt;- 5.0\n\n# Load Julia curves\njulia_curves &lt;- read.csv(\"_julia_curves.csv\")\njulia_summary &lt;- read.csv(\"_julia_summary.csv\")\n\n# Load knots calibrated by Julia (from event time quantiles)\nknots_df &lt;- read.csv(\"_knots.csv\")\ninterior_knots &lt;- knots_df$interior_knots\nboundary_lower &lt;- knots_df$boundary_lower[1]\nboundary_upper &lt;- knots_df$boundary_upper[1]\n\ncat(\"=== Julia MultistateModels.jl Results ===\\n\")\nprint(julia_summary)\n\ncat(\"\\n=== Knot Configuration (shared across all methods) ===\\n\")\ncat(\"Boundary knots: [\", boundary_lower, \",\", boundary_upper, \"]\\n\")\ncat(\"Interior knots:\", round(interior_knots, 3), \"\\n\")\ncat(\"Number of interior knots:\", length(interior_knots), \"\\n\")"
  },
  {
    "objectID": "spline_comparison_benchmark.html#discussion",
    "href": "spline_comparison_benchmark.html#discussion",
    "title": "Spline Methods Comparison",
    "section": "Discussion",
    "text": "Discussion\n\nEDF vs λ Scaling\nThe effective degrees of freedom (EDF) is the proper metric for comparing smoothing across packages. Despite significant differences in raw λ values between Julia and mgcv, the EDF values are in good agreement, confirming that both approaches select similar model complexity.\nThe scale difference arises from:\n\nEffective sample size: Julia uses n=100 subjects; mgcv’s PAM uses many pseudo-observations\nPenalty matrix normalization: Different scaling conventions\nLikelihood formulation: Exact survival vs Poisson pseudo-likelihood\n\n\n\nSoftware Packages Compared\n\n\n\n\n\n\n\n\nPackage\nApproach\nNotes\n\n\n\n\nMultistateModels.jl\nExact penalized likelihood with P-splines\nMultiple smoothing methods (PIJCV, EFS, LOOCV, etc.)\n\n\nmgcv/pammtools\nPAM (Poisson GAM on piecewise-exponential data)\nGCV.Cp, REML for smoothing selection\n\n\nflexsurv\nSpline hazard via ML (no explicit smoothing parameter)\nUses natural splines, not penalized"
  },
  {
    "objectID": "spline_comparison_benchmark.html#model-selection-criteria-aicbic",
    "href": "spline_comparison_benchmark.html#model-selection-criteria-aicbic",
    "title": "Spline Methods Comparison",
    "section": "Model Selection Criteria (AIC/BIC)",
    "text": "Model Selection Criteria (AIC/BIC)\nFor model comparison, we compute AIC and BIC based on the penalized log-likelihood and effective degrees of freedom:\n\nAIC = \\(-2 \\cdot \\ell + 2 \\cdot \\text{EDF}\\)\nBIC = \\(-2 \\cdot \\ell + \\log(n) \\cdot \\text{EDF}\\)\n\n\n\nShow code\nn_obs &lt;- nrow(surv_data)\n\n# Julia model selection criteria\njulia_aic_bic &lt;- julia_summary %&gt;%\n  mutate(\n    Package = \"MultistateModels.jl\",\n    AIC = -2 * loglik + 2 * edf,\n    BIC = -2 * loglik + log(n_obs) * edf\n  ) %&gt;%\n  select(Package, Method = method, EDF = edf, LogLik = loglik, AIC, BIC)\n\n# For mgcv: The Poisson pseudo-likelihood differs from survival likelihood by\n# an offset correction. The relationship is:\n#   ℓ_Poisson = ℓ_Survival + Σ_i δ_i * offset_i\n# where offset_i = log(interval_width) for the event interval.\n# Therefore: ℓ_Survival = ℓ_Poisson - Σ_i δ_i * offset_i\n\ncompute_surv_loglik_mgcv &lt;- function(fit_gam, ped) {\n  # Get Poisson log-likelihood\n  mu_hat &lt;- fitted(fit_gam)\n  y &lt;- ped$ped_status\n  poisson_ll &lt;- sum(y * log(mu_hat) - mu_hat)\n  \n  # Correction: subtract sum of offsets for event pseudo-observations\n  event_offsets &lt;- ped$offset[ped$ped_status == 1]\n  offset_correction &lt;- sum(event_offsets)\n  \n  # Survival log-likelihood\n  surv_ll &lt;- poisson_ll - offset_correction\n  return(surv_ll)\n}\n\n# Compute survival log-likelihoods for mgcv models\nloglik_mgcv_gcv &lt;- compute_surv_loglik_mgcv(fit_gcv, ped)\nloglik_mgcv_reml &lt;- compute_surv_loglik_mgcv(fit_reml, ped)\n\n# mgcv model selection using survival log-likelihood\nmgcv_aic_bic &lt;- data.frame(\n  Package = c(\"mgcv\", \"mgcv\"),\n  Method = c(\"GCV.Cp\", \"REML\"),\n  EDF = c(sum(fit_gcv$edf), sum(fit_reml$edf)),\n  LogLik = c(loglik_mgcv_gcv, loglik_mgcv_reml),\n  AIC = c(-2 * loglik_mgcv_gcv + 2 * sum(fit_gcv$edf),\n          -2 * loglik_mgcv_reml + 2 * sum(fit_reml$edf)),\n  BIC = c(-2 * loglik_mgcv_gcv + log(n_obs) * sum(fit_gcv$edf),\n          -2 * loglik_mgcv_reml + log(n_obs) * sum(fit_reml$edf))\n)\n\n# flexsurv model selection\nflex_aic_bic &lt;- data.frame(\n  Package = \"flexsurv\",\n  Method = \"spline\",\n  EDF = length(coef(fit_flex)),\n  LogLik = fit_flex$loglik,\n  AIC = AIC(fit_flex),\n  BIC = BIC(fit_flex)\n)\n\naic_bic_summary &lt;- rbind(julia_aic_bic, mgcv_aic_bic, flex_aic_bic)\n\nn_julia_methods &lt;- nrow(julia_aic_bic)\nkable(aic_bic_summary, digits = 2,\n      caption = \"Model Selection Criteria by Method (Survival Log-Likelihood)\") %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\")) %&gt;%\n  pack_rows(\"MultistateModels.jl\", 1, n_julia_methods) %&gt;%\n  pack_rows(\"mgcv\", n_julia_methods + 1, n_julia_methods + 2) %&gt;%\n  pack_rows(\"flexsurv\", n_julia_methods + 3, n_julia_methods + 3)\n\n\n\nModel Selection Criteria by Method (Survival Log-Likelihood)\n\n\nPackage\nMethod\nEDF\nLogLik\nAIC\nBIC\n\n\n\n\nMultistateModels.jl\n\n\nMultistateModels.jl\nPIJCV\n2.21\n-164.08\n332.58\n338.34\n\n\nMultistateModels.jl\nPIJCV5\n2.21\n-164.08\n332.58\n338.34\n\n\nMultistateModels.jl\nPIJCV10\n2.21\n-164.08\n332.58\n338.34\n\n\nMultistateModels.jl\nPIJCV20\n2.21\n-164.08\n332.58\n338.34\n\n\nMultistateModels.jl\nEFS\n2.46\n-163.85\n332.63\n339.04\n\n\nMultistateModels.jl\nLOOCV\n2.21\n-164.08\n332.58\n338.34\n\n\nMultistateModels.jl\nCV5\n2.21\n-164.08\n332.58\n338.34\n\n\nMultistateModels.jl\nCV10\n2.21\n-164.08\n332.58\n338.34\n\n\nMultistateModels.jl\nCV20\n2.21\n-164.08\n332.58\n338.34\n\n\nmgcv\n\n\nmgcv\nGCV.Cp\n2.00\n-164.08\n332.16\n337.37\n\n\nmgcv\nREML\n2.00\n-164.08\n332.16\n337.37\n\n\nflexsurv\n\n\nflexsurv\nspline\n7.00\n-160.31\n334.62\n352.85\n\n\n\n\n\nNote on mgcv log-likelihood: The mgcv package reports Poisson pseudo-likelihood values, not survival log-likelihood. We convert using the relationship: \\(\\ell_{\\text{survival}} = \\ell_{\\text{Poisson}} - \\sum_i \\delta_i \\cdot \\text{offset}_i\\), where \\(\\text{offset}_i = \\log(\\text{interval width})\\) for each event’s interval.\nKey observations:\n\nAll methods produce similar log-likelihoods (within ~2-3 units), validating correctness\nEDF values are in the range 2-3, indicating similar effective smoothness across methods\nJulia’s exact likelihood and mgcv’s PAM/Poisson approach agree well"
  },
  {
    "objectID": "spline_comparison_benchmark.html#true-model-specification-illness-death",
    "href": "spline_comparison_benchmark.html#true-model-specification-illness-death",
    "title": "Spline Methods Comparison",
    "section": "True Model Specification (Illness-Death)",
    "text": "True Model Specification (Illness-Death)\nData are simulated from Weibull hazards with transition-specific parameters:\n\n\n\nTransition\nShape (\\(\\kappa\\))\nRate (\\(\\lambda\\))\nHazard Pattern\n\n\n\n\n1→2\n1.3\n0.25\nModerately increasing\n\n\n1→3\n0.8\n0.15\nDecreasing (competing risk)\n\n\n2→3\n1.5\n0.35\nStrongly increasing\n\n\n\n\\[h_{12}(t) = 1.3 \\times 0.25 \\times t^{0.3} = 0.325 t^{0.3}\\] \\[h_{13}(t) = 0.8 \\times 0.15 \\times t^{-0.2} = 0.12 t^{-0.2}\\] \\[h_{23}(t) = 1.5 \\times 0.35 \\times t^{0.5} = 0.525 t^{0.5}\\]"
  },
  {
    "objectID": "spline_comparison_benchmark.html#illness-death-data-simulation-and-julia-fitting",
    "href": "spline_comparison_benchmark.html#illness-death-data-simulation-and-julia-fitting",
    "title": "Spline Methods Comparison",
    "section": "Illness-Death Data Simulation and Julia Fitting",
    "text": "Illness-Death Data Simulation and Julia Fitting\n\n\nShow code\ncd ../..\njulia --project=. -e '\nusing MultistateModels\nusing Random\nusing DataFrames\nusing CSV\nusing Printf\nusing Distributions\n\n# Configuration\nn = 200\nmax_time = 6.0\nseed = 12345\n\n# True Weibull parameters (shape, rate) for each transition\n# Using MultistateModels convention: h(t) = shape * rate * t^(shape-1)\ntrue_params = (\n    h12 = (shape = 1.3, rate = 0.25),  # Moderately increasing\n    h13 = (shape = 0.8, rate = 0.15),  # Decreasing (competing risk)\n    h23 = (shape = 1.5, rate = 0.35)   # Strongly increasing\n)\n\nRandom.seed!(seed)\n\n# Simulate illness-death model\n# For each subject, we need to simulate the competing process\n\nfunction weibull_cdf(t, shape, rate)\n    return 1.0 - exp(-rate * t^shape)\nend\n\nfunction weibull_quantile(p, shape, rate)\n    return (-log(1.0 - p) / rate)^(1.0 / shape)\nend\n\n# Simulate event times\nsurvival_data = DataFrame[]\n\nfor i in 1:n\n    # Generate latent event times from state 1\n    U12 = rand()\n    U13 = rand()\n    \n    # Weibull event times from state 1\n    T12 = weibull_quantile(U12, true_params.h12.shape, true_params.h12.rate)\n    T13 = weibull_quantile(U13, true_params.h13.shape, true_params.h13.rate)\n    \n    # Determine first event from state 1\n    if min(T12, T13) &gt;= max_time\n        # Administrative censoring in state 1\n        push!(survival_data, DataFrame(\n            id = i,\n            tstart = 0.0,\n            tstop = max_time,\n            statefrom = 1,\n            stateto = 1,\n            obstype = 1\n        ))\n    elseif T12 &lt; T13\n        # Transition to illness (state 2)\n        t_illness = T12\n        \n        # Now generate death time from state 2\n        # Time to death from illness follows Weibull with params h23\n        U23 = rand()\n        T23_residual = weibull_quantile(U23, true_params.h23.shape, true_params.h23.rate)\n        T_death = t_illness + T23_residual\n        \n        if T_death &gt;= max_time\n            # Illness then administrative censoring\n            push!(survival_data, DataFrame(\n                id = i,\n                tstart = 0.0,\n                tstop = t_illness,\n                statefrom = 1,\n                stateto = 2,\n                obstype = 1\n            ))\n            push!(survival_data, DataFrame(\n                id = i,\n                tstart = t_illness,\n                tstop = max_time,\n                statefrom = 2,\n                stateto = 2,\n                obstype = 1\n            ))\n        else\n            # Illness then death\n            push!(survival_data, DataFrame(\n                id = i,\n                tstart = 0.0,\n                tstop = t_illness,\n                statefrom = 1,\n                stateto = 2,\n                obstype = 1\n            ))\n            push!(survival_data, DataFrame(\n                id = i,\n                tstart = t_illness,\n                tstop = T_death,\n                statefrom = 2,\n                stateto = 3,\n                obstype = 1\n            ))\n        end\n    else\n        # Direct death from state 1 (h13)\n        push!(survival_data, DataFrame(\n            id = i,\n            tstart = 0.0,\n            tstop = T13,\n            statefrom = 1,\n            stateto = 3,\n            obstype = 1\n        ))\n    end\nend\n\nsurv_data = vcat(survival_data...)\n\n# Count transitions\nn_12 = sum((surv_data.statefrom .== 1) .& (surv_data.stateto .== 2))\nn_13 = sum((surv_data.statefrom .== 1) .& (surv_data.stateto .== 3))\nn_23 = sum((surv_data.statefrom .== 2) .& (surv_data.stateto .== 3))\nn_cens_1 = sum((surv_data.statefrom .== 1) .& (surv_data.stateto .== 1))\nn_cens_2 = sum((surv_data.statefrom .== 2) .& (surv_data.stateto .== 2))\n\nprintln(\"=== Illness-Death Data ===\")\nprintln(\"n = $n subjects\")\nprintln(\"Transitions 1→2 (illness): $n_12\")\nprintln(\"Transitions 1→3 (direct death): $n_13\")\nprintln(\"Transitions 2→3 (death after illness): $n_23\")\nprintln(\"Censored in state 1: $n_cens_1\")\nprintln(\"Censored in state 2: $n_cens_2\")\n\n# Extract event times for each transition\nevent_times_12 = surv_data[(surv_data.statefrom .== 1) .& (surv_data.stateto .== 2), :tstop]\nevent_times_13 = surv_data[(surv_data.statefrom .== 1) .& (surv_data.stateto .== 3), :tstop]\nevent_times_23 = surv_data[(surv_data.statefrom .== 2) .& (surv_data.stateto .== 3), :tstop] .- \n                 surv_data[(surv_data.statefrom .== 2) .& (surv_data.stateto .== 3), :tstart]\n\n# For R export, we need the raw survival data\n# Convert to standard multistate format\nCSV.write(\"MultistateModelsTests/reports/_id_surv_data.csv\", surv_data)\n\n# Define model with spline hazards\nh12 = Hazard(@formula(0 ~ 1), \"sp\", 1, 2;\n             degree = 3,\n             knots = Float64[],\n             boundaryknots = [0.0, max_time],\n             natural_spline = true)\nh13 = Hazard(@formula(0 ~ 1), \"sp\", 1, 3;\n             degree = 3,\n             knots = Float64[],\n             boundaryknots = [0.0, max_time],\n             natural_spline = true)\nh23 = Hazard(@formula(0 ~ 1), \"sp\", 2, 3;\n             degree = 3,\n             knots = Float64[],\n             boundaryknots = [0.0, max_time],\n             natural_spline = true)\n\nmodel = multistatemodel(h12, h13, h23; data=surv_data)\n\n# Calibrate knots based on event times\nprintln(\"\\nCalibrating spline knots...\")\nknot_result = calibrate_splines!(model; nknots=5, verbose=true)\n\n# Extract knots for each hazard\nknots_12 = knot_result.h12\nknots_13 = knot_result.h13\nknots_23 = knot_result.h23\n\nprintln(\"\\n=== Knot Configuration ===\")\nprintln(\"h12: boundary=$(knots_12.boundary_knots), interior=$(round.(knots_12.interior_knots, digits=3))\")\nprintln(\"h13: boundary=$(knots_13.boundary_knots), interior=$(round.(knots_13.interior_knots, digits=3))\")\nprintln(\"h23: boundary=$(knots_23.boundary_knots), interior=$(round.(knots_23.interior_knots, digits=3))\")\n\n# Save knots for R\nknots_df = DataFrame(\n    transition = repeat([\"h12\", \"h13\", \"h23\"], inner=5),\n    interior_knot_idx = repeat(1:5, 3),\n    interior_knot = vcat(knots_12.interior_knots, knots_13.interior_knots, knots_23.interior_knots),\n    boundary_lower = fill(0.0, 15),\n    boundary_upper = fill(max_time, 15)\n)\nCSV.write(\"MultistateModelsTests/reports/_id_knots.csv\", knots_df)\n\n# Fit with each smoothing method\nprintln(\"\\n=== Fitting with smoothing methods ===\")\n\nprintln(\"\\nFitting with PIJCV method...\")\nresult_pijcv = select_smoothing_parameters(model, SplinePenalty(); \n                                           method = :pijcv, verbose = false)\nprintln(\"  PIJCV λ = $(round.(result_pijcv.lambda, digits=2)), EDF = $(round(result_pijcv.edf.total, digits=2))\")\n\nprintln(\"\\nFitting with EFS method...\")\nresult_efs = select_smoothing_parameters(model, SplinePenalty(); \n                                         method = :efs, verbose = false)\nprintln(\"  EFS λ = $(round.(result_efs.lambda, digits=2)), EDF = $(round(result_efs.edf.total, digits=2))\")\n\nprintln(\"\\nFitting with LOOCV method...\")\nresult_loocv = select_smoothing_parameters(model, SplinePenalty(); \n                                           method = :loocv, verbose = false)\nprintln(\"  LOOCV λ = $(round.(result_loocv.lambda, digits=2)), EDF = $(round(result_loocv.edf.total, digits=2))\")\n\nprintln(\"\\nFitting with 10-fold CV method...\")\nresult_cv10 = select_smoothing_parameters(model, SplinePenalty(); \n                                          method = :cv10, verbose = false)\nprintln(\"  CV10 λ = $(round.(result_cv10.lambda, digits=2)), EDF = $(round(result_cv10.edf.total, digits=2))\")\n\n# Evaluation grid\neval_times = collect(range(0.01, max_time, length=200))\n\n# Function to evaluate hazard curves for all transitions\nfunction evaluate_id_curves(model, beta, eval_times)\n    results = Dict{String, NamedTuple}()\n    \n    current_idx = 1\n    for (idx, haz) in enumerate(model.hazards)\n        trans_name = \"h$(haz.statefrom)$(haz.stateto)\"\n        \n        # Get parameter indices for this hazard\n        npars = length(haz.parnames)\n        start_idx = current_idx\n        end_idx = current_idx + npars - 1\n        beta_haz = beta[start_idx:end_idx]\n        current_idx = end_idx + 1\n        \n        hazard_vals = [haz.hazard_fn(t, beta_haz, ()) for t in eval_times]\n        cumhaz_vals = [haz.cumhaz_fn(0.0, t, beta_haz, ()) for t in eval_times]\n        \n        results[trans_name] = (hazard = hazard_vals, cumhaz = cumhaz_vals)\n    end\n    \n    return results\nend\n\n# Compute curves for each method\ncurves_pijcv = evaluate_id_curves(model, result_pijcv.beta, eval_times)\ncurves_efs = evaluate_id_curves(model, result_efs.beta, eval_times)\ncurves_loocv = evaluate_id_curves(model, result_loocv.beta, eval_times)\ncurves_cv10 = evaluate_id_curves(model, result_cv10.beta, eval_times)\n\n# Compute unpenalized log-likelihoods\nsamplepaths = MultistateModels.extract_paths(model)\nexact_data = MultistateModels.ExactData(model, samplepaths)\nloglik_pijcv = MultistateModels.loglik_exact(result_pijcv.beta, exact_data; neg=false)\nloglik_efs = MultistateModels.loglik_exact(result_efs.beta, exact_data; neg=false)\nloglik_loocv = MultistateModels.loglik_exact(result_loocv.beta, exact_data; neg=false)\nloglik_cv10 = MultistateModels.loglik_exact(result_cv10.beta, exact_data; neg=false)\n\n# Save curves to CSV\ncurves_list = DataFrame[]\nfor (method_name, curves) in [(\"Julia PIJCV\", curves_pijcv), \n                               (\"Julia EFS\", curves_efs), (\"Julia LOOCV\", curves_loocv), \n                               (\"Julia CV10\", curves_cv10)]\n    for trans in [\"h12\", \"h13\", \"h23\"]\n        push!(curves_list, DataFrame(\n            time = eval_times,\n            hazard = curves[trans].hazard,\n            cumhaz = curves[trans].cumhaz,\n            transition = trans,\n            method = method_name\n        ))\n    end\nend\njulia_curves = vcat(curves_list...)\nCSV.write(\"MultistateModelsTests/reports/_id_julia_curves.csv\", julia_curves)\n\n# Save summary with per-transition EDF\njulia_summary = DataFrame(\n    method = [\"PIJCV\", \"EFS\", \"LOOCV\", \"CV10\"],\n    lambda = [result_pijcv.lambda[1], result_efs.lambda[1], \n              result_loocv.lambda[1], result_cv10.lambda[1]],\n    edf_total = [result_pijcv.edf.total, result_efs.edf.total, \n                 result_loocv.edf.total, result_cv10.edf.total],\n    loglik = [loglik_pijcv, loglik_efs, loglik_loocv, loglik_cv10]\n)\nCSV.write(\"MultistateModelsTests/reports/_id_julia_summary.csv\", julia_summary)\n\n# Save event times for rug plots\nevent_times_df = DataFrame(\n    time = Float64[],\n    transition = String[]\n)\nfor (times, trans) in [(event_times_12, \"h12\"), (event_times_13, \"h13\")]\n    append!(event_times_df, DataFrame(time = times, transition = fill(trans, length(times))))\nend\n# For h23, use the absolute death times (not duration in state 2)\ndeath_times_23 = surv_data[(surv_data.statefrom .== 2) .& (surv_data.stateto .== 3), :tstop]\nappend!(event_times_df, DataFrame(time = death_times_23, transition = fill(\"h23\", length(death_times_23))))\nCSV.write(\"MultistateModelsTests/reports/_id_event_times.csv\", event_times_df)\n\nprintln(\"\\nIllness-death curves computed and saved.\")\n'"
  },
  {
    "objectID": "spline_comparison_benchmark.html#load-illness-death-results-in-r",
    "href": "spline_comparison_benchmark.html#load-illness-death-results-in-r",
    "title": "Spline Methods Comparison",
    "section": "Load Illness-Death Results in R",
    "text": "Load Illness-Death Results in R\n\n\nShow code\n# Load simulated data\nid_surv_data &lt;- read.csv(\"_id_surv_data.csv\")\n\n# Load Julia curves\nid_julia_curves &lt;- read.csv(\"_id_julia_curves.csv\")\nid_julia_summary &lt;- read.csv(\"_id_julia_summary.csv\")\n\n# Load knots\nid_knots_df &lt;- read.csv(\"_id_knots.csv\")\nid_knots &lt;- id_knots_df %&gt;%\n  group_by(transition) %&gt;%\n  summarise(\n    interior_knots = list(interior_knot),\n    boundary_lower = first(boundary_lower),\n    boundary_upper = first(boundary_upper),\n    .groups = \"drop\"\n  )\n\n# Load event times for rug plots\nid_event_times &lt;- read.csv(\"_id_event_times.csv\")\n\n# True parameters\nid_true_params &lt;- list(\n  h12 = list(shape = 1.3, rate = 0.25),\n  h13 = list(shape = 0.8, rate = 0.15),\n  h23 = list(shape = 1.5, rate = 0.35)\n)\n\nid_max_time &lt;- 6.0\nid_n &lt;- length(unique(id_surv_data$id))\n\ncat(\"=== Illness-Death Julia Results ===\\n\")\nprint(id_julia_summary)\n\ncat(\"\\n=== Knot Configuration ===\\n\")\nfor (trans in c(\"h12\", \"h13\", \"h23\")) {\n  knots_trans &lt;- id_knots %&gt;% filter(transition == trans)\n  cat(trans, \": interior = [\", paste(round(unlist(knots_trans$interior_knots), 3), collapse=\", \"), \"]\\n\")\n}"
  },
  {
    "objectID": "spline_comparison_benchmark.html#true-hazard-functions-illness-death",
    "href": "spline_comparison_benchmark.html#true-hazard-functions-illness-death",
    "title": "Spline Methods Comparison",
    "section": "True Hazard Functions (Illness-Death)",
    "text": "True Hazard Functions (Illness-Death)\n\n\nShow code\n# True hazard functions for each transition\nid_true_hazard &lt;- function(t, trans) {\n  params &lt;- id_true_params[[trans]]\n  params$shape * params$rate * t^(params$shape - 1)\n}\n\nid_true_cumhaz &lt;- function(t, trans) {\n  params &lt;- id_true_params[[trans]]\n  params$rate * t^params$shape\n}"
  },
  {
    "objectID": "spline_comparison_benchmark.html#mgcvpammtools-fits-illness-death",
    "href": "spline_comparison_benchmark.html#mgcvpammtools-fits-illness-death",
    "title": "Spline Methods Comparison",
    "section": "mgcv/pammtools Fits (Illness-Death)",
    "text": "mgcv/pammtools Fits (Illness-Death)\nFor the illness-death model, we fit separate PAM models for each transition using pammtools, ensuring the same knots as Julia for each transition.\n\n\nShow code\nlibrary(survival)\n\n# Create transition-specific datasets for PAM fitting\n# For multi-state models, we need to filter to relevant observations\n\n# h12: Observations starting in state 1\nid_data_h12 &lt;- id_surv_data %&gt;%\n  filter(statefrom == 1) %&gt;%\n  mutate(\n    time = tstop - tstart,\n    status = as.integer(stateto == 2),\n    id_row = row_number()\n  )\n\n# h13: Same observations, different event indicator\nid_data_h13 &lt;- id_surv_data %&gt;%\n  filter(statefrom == 1) %&gt;%\n  mutate(\n    time = tstop - tstart,\n    status = as.integer(stateto == 3),\n    id_row = row_number()\n  )\n\n# h23: Observations starting in state 2\nid_data_h23 &lt;- id_surv_data %&gt;%\n  filter(statefrom == 2) %&gt;%\n  mutate(\n    time = tstop - tstart,\n    status = as.integer(stateto == 3),\n    id_row = row_number()\n  )\n\ncat(\"h12 data: n =\", nrow(id_data_h12), \", events =\", sum(id_data_h12$status), \"\\n\")\ncat(\"h13 data: n =\", nrow(id_data_h13), \", events =\", sum(id_data_h13$status), \"\\n\")\ncat(\"h23 data: n =\", nrow(id_data_h23), \", events =\", sum(id_data_h23$status), \"\\n\")\n\n# Function to build mgcv knots from Julia interior knots\nbuild_mgcv_knots &lt;- function(interior_knots, boundary_lower, boundary_upper) {\n  k_mgcv &lt;- length(interior_knots) + 4\n  m_order &lt;- 2\n  middle_knots &lt;- c(boundary_lower, interior_knots, boundary_upper)\n  delta &lt;- mean(diff(middle_knots))\n  padding_lower &lt;- boundary_lower - (3:1) * delta\n  padding_upper &lt;- boundary_upper + (1:3) * delta\n  c(padding_lower, middle_knots, padding_upper)\n}\n\n# Build knot vectors for each transition\nid_mgcv_knots &lt;- list()\nfor (trans in c(\"h12\", \"h13\", \"h23\")) {\n  knots_trans &lt;- id_knots %&gt;% filter(transition == trans)\n  id_mgcv_knots[[trans]] &lt;- build_mgcv_knots(\n    unlist(knots_trans$interior_knots),\n    knots_trans$boundary_lower,\n    knots_trans$boundary_upper\n  )\n}\n\nk_mgcv &lt;- 9  # 5 interior + 4\nm_order &lt;- 2\n\n# Fit PAM for h12\nped_h12 &lt;- as_ped(\n  formula = Surv(time, status) ~ 1,\n  data = id_data_h12,\n  id = \"id_row\"\n)\n\nfit_h12_gcv &lt;- pamm(\n  ped_status ~ s(tend, bs = \"ps\", k = k_mgcv, m = c(m_order, m_order)),\n  data = ped_h12,\n  method = \"GCV.Cp\",\n  knots = list(tend = id_mgcv_knots[[\"h12\"]])\n)\n\ncat(\"\\nh12 mgcv fit: EDF =\", round(sum(fit_h12_gcv$edf), 2), \"\\n\")\n\n# Fit PAM for h13\nped_h13 &lt;- as_ped(\n  formula = Surv(time, status) ~ 1,\n  data = id_data_h13,\n  id = \"id_row\"\n)\n\nfit_h13_gcv &lt;- pamm(\n  ped_status ~ s(tend, bs = \"ps\", k = k_mgcv, m = c(m_order, m_order)),\n  data = ped_h13,\n  method = \"GCV.Cp\",\n  knots = list(tend = id_mgcv_knots[[\"h13\"]])\n)\n\ncat(\"h13 mgcv fit: EDF =\", round(sum(fit_h13_gcv$edf), 2), \"\\n\")\n\n# Fit PAM for h23\nped_h23 &lt;- as_ped(\n  formula = Surv(time, status) ~ 1,\n  data = id_data_h23,\n  id = \"id_row\"\n)\n\nfit_h23_gcv &lt;- pamm(\n  ped_status ~ s(tend, bs = \"ps\", k = k_mgcv, m = c(m_order, m_order)),\n  data = ped_h23,\n  method = \"GCV.Cp\",\n  knots = list(tend = id_mgcv_knots[[\"h23\"]])\n)\n\ncat(\"h23 mgcv fit: EDF =\", round(sum(fit_h23_gcv$edf), 2), \"\\n\")"
  },
  {
    "objectID": "spline_comparison_benchmark.html#effective-degrees-of-freedom-illness-death",
    "href": "spline_comparison_benchmark.html#effective-degrees-of-freedom-illness-death",
    "title": "Spline Methods Comparison",
    "section": "Effective Degrees of Freedom (Illness-Death)",
    "text": "Effective Degrees of Freedom (Illness-Death)\n\n\nShow code\n# Collect EDF results for illness-death model\nid_edf_summary &lt;- rbind(\n  id_julia_summary %&gt;%\n    mutate(Package = \"MultistateModels.jl\") %&gt;%\n    select(Package, Method = method, EDF = edf_total, Lambda = lambda),\n  data.frame(\n    Package = rep(\"mgcv\", 3),\n    Method = c(\"GCV h12\", \"GCV h13\", \"GCV h23\"),\n    EDF = c(sum(fit_h12_gcv$edf), sum(fit_h13_gcv$edf), sum(fit_h23_gcv$edf)),\n    Lambda = c(fit_h12_gcv$sp, fit_h13_gcv$sp, fit_h23_gcv$sp)\n  )\n)\n\nkable(id_edf_summary, digits = 4,\n      caption = \"Effective Degrees of Freedom - Illness-Death Model\",\n      col.names = c(\"Package\", \"Method\", \"EDF (total)\", \"λ\")) %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\")) %&gt;%\n  column_spec(3, bold = TRUE, background = \"#f0f9e8\")\n\n\n\nEffective Degrees of Freedom - Illness-Death Model\n\n\nPackage\nMethod\nEDF (total)\nλ\n\n\n\n\nMultistateModels.jl\nPIJCV\n19.7050\n0.0003\n\n\nMultistateModels.jl\nEFS\n6.3034\n14.8797\n\n\nMultistateModels.jl\nLOOCV\n5.6492\n27.1126\n\n\nMultistateModels.jl\nCV10\n5.2354\n40.4473\n\n\nmgcv\nGCV h12\n2.0159\n55576.6194\n\n\nmgcv\nGCV h13\n2.1753\n1449.0671\n\n\nmgcv\nGCV h23\n2.0024\n169676.9961"
  },
  {
    "objectID": "spline_comparison_benchmark.html#model-selection-criteria-illness-death",
    "href": "spline_comparison_benchmark.html#model-selection-criteria-illness-death",
    "title": "Spline Methods Comparison",
    "section": "Model Selection Criteria (Illness-Death)",
    "text": "Model Selection Criteria (Illness-Death)\n\n\nShow code\nid_n_obs &lt;- id_n\n\n# Julia AIC/BIC\nid_julia_aic_bic &lt;- id_julia_summary %&gt;%\n  mutate(\n    Package = \"MultistateModels.jl\",\n    AIC = -2 * loglik + 2 * edf_total,\n    BIC = -2 * loglik + log(id_n_obs) * edf_total\n  ) %&gt;%\n  select(Package, Method = method, EDF = edf_total, LogLik = loglik, AIC, BIC)\n\nkable(id_julia_aic_bic, digits = 2,\n      caption = \"Model Selection Criteria - Illness-Death Model\") %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n\n\n\nModel Selection Criteria - Illness-Death Model\n\n\nPackage\nMethod\nEDF\nLogLik\nAIC\nBIC\n\n\n\n\nMultistateModels.jl\nPIJCV\n19.70\n-621.04\n1281.48\n1346.48\n\n\nMultistateModels.jl\nEFS\n6.30\n-633.16\n1278.92\n1299.71\n\n\nMultistateModels.jl\nLOOCV\n5.65\n-633.91\n1279.13\n1297.76\n\n\nMultistateModels.jl\nCV10\n5.24\n-634.53\n1279.52\n1296.79"
  },
  {
    "objectID": "spline_comparison_benchmark.html#hazard-function-comparison-illness-death",
    "href": "spline_comparison_benchmark.html#hazard-function-comparison-illness-death",
    "title": "Spline Methods Comparison",
    "section": "Hazard Function Comparison (Illness-Death)",
    "text": "Hazard Function Comparison (Illness-Death)\n\n\nShow code\n# Evaluation grid\nid_eval_times &lt;- seq(0.01, id_max_time, length.out = 200)\n\n# Get mgcv hazard predictions\nid_newdata &lt;- data.frame(tend = id_eval_times)\n\nhazard_mgcv_h12 &lt;- add_hazard(id_newdata, fit_h12_gcv)\nhazard_mgcv_h13 &lt;- add_hazard(id_newdata, fit_h13_gcv)\nhazard_mgcv_h23 &lt;- add_hazard(id_newdata, fit_h23_gcv)\n\n# Color palette\nid_method_colors &lt;- c(\"True (Weibull)\" = \"black\",\n                      \"Julia PIJCV\" = \"#D55E00\",\n                      \"Julia EFS\" = \"#56B4E9\",\n                      \"Julia LOOCV\" = \"#0072B2\",\n                      \"Julia CV10\" = \"#F0E442\",\n                      \"mgcv GCV\" = \"#E69F00\")\n\nid_method_linetypes &lt;- c(\"True (Weibull)\" = \"solid\",\n                         \"Julia PIJCV\" = \"dashed\",\n                         \"Julia EFS\" = \"twodash\",\n                         \"Julia LOOCV\" = \"longdash\",\n                         \"Julia CV10\" = \"dashed\",\n                         \"mgcv GCV\" = \"dotdash\")\n\n# Create hazard plots for each transition\ncreate_hazard_plot &lt;- function(trans, trans_label) {\n  # True hazard\n  h_true &lt;- id_true_hazard(id_eval_times, trans)\n  \n  # Julia hazards\n  julia_methods &lt;- c(\"Julia PIJCV\", \"Julia EFS\", \"Julia LOOCV\", \"Julia CV10\")\n  julia_hazards &lt;- lapply(julia_methods, function(m) {\n    id_julia_curves %&gt;%\n      filter(transition == trans, method == m) %&gt;%\n      pull(hazard)\n  })\n  \n  # mgcv hazard\n  mgcv_haz &lt;- switch(trans,\n    h12 = hazard_mgcv_h12$hazard,\n    h13 = hazard_mgcv_h13$hazard,\n    h23 = hazard_mgcv_h23$hazard\n  )\n  \n  # Combine data\n  hazard_df &lt;- data.frame(\n    time = rep(id_eval_times, 6),\n    hazard = c(h_true, unlist(julia_hazards), mgcv_haz),\n    method = factor(rep(c(\"True (Weibull)\", julia_methods, \"mgcv GCV\"), each = length(id_eval_times)),\n                    levels = c(\"True (Weibull)\", julia_methods, \"mgcv GCV\"))\n  )\n  \n  # Event times for this transition\n  event_times_trans &lt;- id_event_times %&gt;% filter(transition == trans) %&gt;% pull(time)\n  \n  ggplot(hazard_df, aes(x = time, y = hazard, color = method, linetype = method)) +\n    geom_line(linewidth = 1) +\n    geom_rug(data = data.frame(time = event_times_trans),\n             aes(x = time), inherit.aes = FALSE,\n             color = \"gray30\", alpha = 0.5, sides = \"b\") +\n    scale_color_manual(values = id_method_colors) +\n    scale_linetype_manual(values = id_method_linetypes) +\n    labs(\n      title = paste0(\"Hazard: \", trans_label),\n      x = \"Time\",\n      y = \"h(t)\",\n      color = \"Method\",\n      linetype = \"Method\"\n    ) +\n    theme(legend.position = \"none\")\n}\n\np_h12 &lt;- create_hazard_plot(\"h12\", \"Healthy → Ill (h12)\")\np_h13 &lt;- create_hazard_plot(\"h13\", \"Healthy → Dead (h13)\")\np_h23 &lt;- create_hazard_plot(\"h23\", \"Ill → Dead (h23)\")\n\n# Combine with shared legend\n(p_h12 / p_h13 / p_h23) +\n  plot_layout(guides = \"collect\") &\n  theme(legend.position = \"bottom\") &\n  guides(color = guide_legend(nrow = 2), linetype = guide_legend(nrow = 2))"
  },
  {
    "objectID": "spline_comparison_benchmark.html#cumulative-hazard-comparison-illness-death",
    "href": "spline_comparison_benchmark.html#cumulative-hazard-comparison-illness-death",
    "title": "Spline Methods Comparison",
    "section": "Cumulative Hazard Comparison (Illness-Death)",
    "text": "Cumulative Hazard Comparison (Illness-Death)\n\n\nShow code\n# Create cumulative hazard plots for each transition\ncreate_cumhaz_plot &lt;- function(trans, trans_label) {\n  # True cumulative hazard\n  H_true &lt;- id_true_cumhaz(id_eval_times, trans)\n  \n  # Julia cumulative hazards\n  julia_methods &lt;- c(\"Julia PIJCV\", \"Julia EFS\", \"Julia LOOCV\", \"Julia CV10\")\n  julia_cumhaz &lt;- lapply(julia_methods, function(m) {\n    id_julia_curves %&gt;%\n      filter(transition == trans, method == m) %&gt;%\n      pull(cumhaz)\n  })\n  \n  # mgcv cumulative hazard (integrate hazard)\n  mgcv_haz &lt;- switch(trans,\n    h12 = hazard_mgcv_h12$hazard,\n    h13 = hazard_mgcv_h13$hazard,\n    h23 = hazard_mgcv_h23$hazard\n  )\n  mgcv_cumhaz &lt;- cumsum(mgcv_haz) * diff(id_eval_times)[1]\n  \n  # Combine data\n  cumhaz_df &lt;- data.frame(\n    time = rep(id_eval_times, 6),\n    cumhaz = c(H_true, unlist(julia_cumhaz), mgcv_cumhaz),\n    method = factor(rep(c(\"True (Weibull)\", julia_methods, \"mgcv GCV\"), each = length(id_eval_times)),\n                    levels = c(\"True (Weibull)\", julia_methods, \"mgcv GCV\"))\n  )\n  \n  ggplot(cumhaz_df, aes(x = time, y = cumhaz, color = method, linetype = method)) +\n    geom_line(linewidth = 1) +\n    scale_color_manual(values = id_method_colors) +\n    scale_linetype_manual(values = id_method_linetypes) +\n    labs(\n      title = paste0(\"Cumulative Hazard: \", trans_label),\n      x = \"Time\",\n      y = \"H(t)\",\n      color = \"Method\",\n      linetype = \"Method\"\n    ) +\n    theme(legend.position = \"none\")\n}\n\np_H12 &lt;- create_cumhaz_plot(\"h12\", \"Healthy → Ill (h12)\")\np_H13 &lt;- create_cumhaz_plot(\"h13\", \"Healthy → Dead (h13)\")\np_H23 &lt;- create_cumhaz_plot(\"h23\", \"Ill → Dead (h23)\")\n\n(p_H12 / p_H13 / p_H23) +\n  plot_layout(guides = \"collect\") &\n  theme(legend.position = \"bottom\") &\n  guides(color = guide_legend(nrow = 2), linetype = guide_legend(nrow = 2))"
  },
  {
    "objectID": "spline_comparison_benchmark.html#accuracy-metrics-illness-death",
    "href": "spline_comparison_benchmark.html#accuracy-metrics-illness-death",
    "title": "Spline Methods Comparison",
    "section": "Accuracy Metrics (Illness-Death)",
    "text": "Accuracy Metrics (Illness-Death)\n\n\nShow code\n# RMSE function\nrmse &lt;- function(true, est) sqrt(mean((true - est)^2, na.rm = TRUE))\n\n# Calculate metrics for each transition and method\nid_metrics_list &lt;- list()\n\nfor (trans in c(\"h12\", \"h13\", \"h23\")) {\n  h_true &lt;- id_true_hazard(id_eval_times, trans)\n  H_true &lt;- id_true_cumhaz(id_eval_times, trans)\n  \n  # Julia methods (no GCV - only PIJCV, EFS, LOOCV, CV10)\n  for (method in c(\"PIJCV\", \"EFS\", \"LOOCV\", \"CV10\")) {\n    julia_method &lt;- paste0(\"Julia \", method)\n    h_julia &lt;- id_julia_curves %&gt;%\n      filter(transition == trans, method == julia_method) %&gt;%\n      pull(hazard)\n    H_julia &lt;- id_julia_curves %&gt;%\n      filter(transition == trans, method == julia_method) %&gt;%\n      pull(cumhaz)\n    \n    id_metrics_list[[paste(trans, method)]] &lt;- data.frame(\n      Transition = trans,\n      Package = \"MultistateModels.jl\",\n      Method = method,\n      Hazard_RMSE = rmse(h_true, h_julia),\n      CumHaz_RMSE = rmse(H_true, H_julia)\n    )\n  }\n  \n  # mgcv\n  mgcv_haz &lt;- switch(trans,\n    h12 = hazard_mgcv_h12$hazard,\n    h13 = hazard_mgcv_h13$hazard,\n    h23 = hazard_mgcv_h23$hazard\n  )\n  mgcv_cumhaz &lt;- cumsum(mgcv_haz) * diff(id_eval_times)[1]\n  \n  id_metrics_list[[paste(trans, \"mgcv\")]] &lt;- data.frame(\n    Transition = trans,\n    Package = \"mgcv\",\n    Method = \"GCV.Cp\",\n    Hazard_RMSE = rmse(h_true, mgcv_haz),\n    CumHaz_RMSE = rmse(H_true, mgcv_cumhaz)\n  )\n}\n\nid_metrics_df &lt;- do.call(rbind, id_metrics_list)\n\nkable(id_metrics_df, digits = 5,\n      caption = \"RMSE vs True Weibull Functions - Illness-Death Model\",\n      col.names = c(\"Transition\", \"Package\", \"Method\", \"Hazard RMSE\", \"Cum. Hazard RMSE\")) %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\")) %&gt;%\n  pack_rows(\"h12: Healthy → Ill\", 1, 5) %&gt;%\n  pack_rows(\"h13: Healthy → Dead\", 6, 10) %&gt;%\n  pack_rows(\"h23: Ill → Dead\", 11, 15)\n\n\n\nRMSE vs True Weibull Functions - Illness-Death Model\n\n\n\nTransition\nPackage\nMethod\nHazard RMSE\nCum. Hazard RMSE\n\n\n\n\nh12: Healthy → Ill\n\n\nh12 PIJCV\nh12\nMultistateModels.jl\nPIJCV\n0.08090\n0.18076\n\n\nh12 EFS\nh12\nMultistateModels.jl\nEFS\n0.07463\n0.19951\n\n\nh12 LOOCV\nh12\nMultistateModels.jl\nLOOCV\n0.07888\n0.20635\n\n\nh12 CV10\nh12\nMultistateModels.jl\nCV10\n0.08317\n0.21240\n\n\nh12 mgcv\nh12\nmgcv\nGCV.Cp\n0.05755\n0.16779\n\n\nh13: Healthy → Dead\n\n\nh13 PIJCV\nh13\nMultistateModels.jl\nPIJCV\n0.02777\n0.01456\n\n\nh13 EFS\nh13\nMultistateModels.jl\nEFS\n0.01684\n0.02019\n\n\nh13 LOOCV\nh13\nMultistateModels.jl\nLOOCV\n0.01795\n0.02509\n\n\nh13 CV10\nh13\nMultistateModels.jl\nCV10\n0.01926\n0.02897\n\n\nh13 mgcv\nh13\nmgcv\nGCV.Cp\n0.02750\n0.03060\n\n\nh23: Ill → Dead\n\n\nh23 PIJCV\nh23\nMultistateModels.jl\nPIJCV\n0.51615\n0.66691\n\n\nh23 EFS\nh23\nMultistateModels.jl\nEFS\n0.20845\n0.43839\n\n\nh23 LOOCV\nh23\nMultistateModels.jl\nLOOCV\n0.24925\n0.51128\n\n\nh23 CV10\nh23\nMultistateModels.jl\nCV10\n0.28438\n0.57198\n\n\nh23 mgcv\nh23\nmgcv\nGCV.Cp\n0.21070\n0.41481"
  },
  {
    "objectID": "spline_comparison_benchmark.html#discussion-illness-death-model",
    "href": "spline_comparison_benchmark.html#discussion-illness-death-model",
    "title": "Spline Methods Comparison",
    "section": "Discussion (Illness-Death Model)",
    "text": "Discussion (Illness-Death Model)\nThe illness-death model presents additional challenges compared to simple survival:\n\nCompeting risks: From state 1, subjects can transition to either state 2 (illness) or state 3 (death), requiring proper handling of censoring for each transition.\nTransition-specific hazards: Each transition has its own hazard function with different shapes, testing the flexibility of spline smoothing.\nData sparsity: Some transitions may have fewer events, affecting the stability of smoothing parameter selection.\n\nKey observations:\n\nAll Julia smoothing methods (PIJCV, EFS, LOOCV, CV10) produce similar results\nEDF values are comparable between Julia and mgcv for each transition\nThe decreasing hazard (h13) is more challenging to capture than increasing hazards\nThe strongly increasing hazard (h23) is well-recovered by all methods"
  },
  {
    "objectID": "spline_comparison_benchmark.html#runtime-comparison",
    "href": "spline_comparison_benchmark.html#runtime-comparison",
    "title": "Spline Methods Comparison",
    "section": "Runtime Comparison",
    "text": "Runtime Comparison\nA key advantage of Newton-approximated cross-validation methods (PIJCV, PIJCV5, etc.) is computational efficiency. While exact k-fold CV requires refitting the model K times, the Newton approximation achieves similar results in a single optimization.\n\n\nShow code\n# Check if runtime data is available\nif (\"runtime_sec\" %in% names(julia_summary)) {\n  \n  # Categorize methods (no GCV)\n  julia_summary$category &lt;- case_when(\n    julia_summary$method %in% c(\"PIJCV\", \"PIJCV5\", \"PIJCV10\", \"PIJCV20\") ~ \"Newton-approximated CV\",\n    julia_summary$method %in% c(\"LOOCV\", \"CV5\", \"CV10\", \"CV20\") ~ \"Exact CV\",\n    TRUE ~ \"Other (EFS)\"\n  )\n  \n  # Order methods by category and folds (no GCV)\n  method_order &lt;- c(\"PIJCV\", \"PIJCV5\", \"PIJCV10\", \"PIJCV20\", \n                    \"EFS\",\n                    \"LOOCV\", \"CV5\", \"CV10\", \"CV20\")\n  julia_summary$method &lt;- factor(julia_summary$method, levels = method_order)\n  \n  # Create bar plot\n  p_runtime &lt;- ggplot(julia_summary, aes(x = method, y = runtime_sec, fill = category)) +\n    geom_col(width = 0.7) +\n    geom_text(aes(label = sprintf(\"%.2fs\", runtime_sec)), \n              vjust = -0.5, size = 3) +\n    scale_fill_manual(values = c(\n      \"Newton-approximated CV\" = \"#3498db\",\n      \"Exact CV\" = \"#e74c3c\",\n      \"Other (EFS)\" = \"#2ecc71\"\n    )) +\n    labs(\n      title = \"Runtime Comparison: Smoothing Parameter Selection Methods\",\n      subtitle = \"Single optimization vs. K refits (n=100 subjects, 5 interior knots)\",\n      x = \"Method\",\n      y = \"Runtime (seconds)\",\n      fill = \"Category\"\n    ) +\n    theme_minimal() +\n    theme(\n      axis.text.x = element_text(angle = 45, hjust = 1),\n      legend.position = \"bottom\"\n    )\n  \n  print(p_runtime)\n  \n  # Runtime summary table\n  runtime_summary &lt;- julia_summary %&gt;%\n    group_by(category) %&gt;%\n    summarise(\n      Methods = paste(method, collapse = \", \"),\n      Mean_Runtime = mean(runtime_sec),\n      Min_Runtime = min(runtime_sec),\n      Max_Runtime = max(runtime_sec),\n      .groups = \"drop\"\n    ) %&gt;%\n    arrange(Mean_Runtime)\n  \n  kable(runtime_summary, digits = 3,\n        caption = \"Runtime Summary by Method Category\",\n        col.names = c(\"Category\", \"Methods\", \"Mean (s)\", \"Min (s)\", \"Max (s)\")) %&gt;%\n    kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n  \n} else {\n  cat(\"Runtime data not available in julia_summary.\\n\")\n}\n\n\n\n\n\n\n\n\n\n\nRuntime Summary by Method Category\n\n\nCategory\nMethods\nMean (s)\nMin (s)\nMax (s)\n\n\n\n\nNewton-approximated CV\nPIJCV, PIJCV5, PIJCV10, PIJCV20\n0.476\n0.456\n0.503\n\n\nOther (EFS)\nEFS\n0.512\n0.512\n0.512\n\n\nExact CV\nLOOCV, CV5, CV10, CV20\n5.449\n1.118\n14.504\n\n\n\n\n\n\n\nShow code\nif (\"runtime_sec\" %in% names(julia_summary)) {\n  # Add category if not present (from previous chunk)\n  if (!\"category\" %in% names(julia_summary)) {\n    julia_summary$category &lt;- case_when(\n      julia_summary$method %in% c(\"PIJCV\", \"PIJCV5\", \"PIJCV10\", \"PIJCV20\") ~ \"Newton CV\",\n      julia_summary$method %in% c(\"LOOCV\", \"CV5\", \"CV10\", \"CV20\") ~ \"Exact CV\",\n      TRUE ~ \"Other\"\n    )\n  }\n  \n  # Full runtime table with all metrics\n  runtime_full &lt;- julia_summary %&gt;%\n    select(method, category, lambda, edf, loglik, runtime_sec) %&gt;%\n    arrange(runtime_sec)\n  \n  kable(runtime_full, digits = c(0, 0, 2, 2, 2, 3),\n        caption = \"Full Results: All Julia Smoothing Methods (sorted by runtime)\",\n        col.names = c(\"Method\", \"Category\", \"λ\", \"EDF\", \"Log-Lik\", \"Runtime (s)\")) %&gt;%\n    kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n}\n\n\n\nFull Results: All Julia Smoothing Methods (sorted by runtime)\n\n\nMethod\nCategory\nλ\nEDF\nLog-Lik\nRuntime (s)\n\n\n\n\nPIJCV10\nNewton-approximated CV\n9.97\n2.21\n-164.08\n0.456\n\n\nPIJCV5\nNewton-approximated CV\n9.97\n2.21\n-164.08\n0.471\n\n\nPIJCV20\nNewton-approximated CV\n9.97\n2.21\n-164.08\n0.475\n\n\nPIJCV\nNewton-approximated CV\n9.97\n2.21\n-164.08\n0.503\n\n\nEFS\nOther (EFS)\n5.47\n2.46\n-163.85\n0.512\n\n\nCV5\nExact CV\n9.97\n2.21\n-164.08\n1.118\n\n\nCV10\nExact CV\n9.97\n2.21\n-164.08\n2.275\n\n\nCV20\nExact CV\n9.97\n2.21\n-164.08\n3.900\n\n\nLOOCV\nExact CV\n9.97\n2.21\n-164.08\n14.504\n\n\n\n\n\nKey Runtime Observations:\n\nNewton-approximated methods (PIJCV, PIJCV5, PIJCV10, PIJCV20) achieve comparable accuracy to exact CV while requiring only a single model fit with analytical gradients\nExact k-fold CV methods (LOOCV, CV5, CV10, CV20) require K model refits, making them substantially slower\nGCV and EFS are the fastest as they use simple closed-form approximations\nThe computational advantage of Newton approximation grows with sample size and model complexity"
  }
]