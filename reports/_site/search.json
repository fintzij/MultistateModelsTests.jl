[
  {
    "objectID": "unit_tests.html",
    "href": "unit_tests.html",
    "title": "Unit Test Coverage",
    "section": "",
    "text": "This document provides a comprehensive summary of unit test coverage for MultistateModels.jl. Unit tests verify individual functions and components work correctly in isolation, forming the foundation of the testing pyramid.\n\n\nüü° Cache stale (d6ee7ab ‚Üí b1144da)\n\n\n**Branch:** `penalized_splines` | **Commit:** `b1144da`\n\n‚ö†Ô∏è Uncommitted changes in: scratch/future_features_todo.txt, scratch/per_transition_obstype_plan.md, src/construction/multistatemodel.jl...\n\n\n\n\n\n\n\n| Metric | Value |\n|--------|-------|\n| Total Passed | 1192 |\n| Total Failed | 0 |\n| Total Errors | 0 |\n| Categories Tested | 12 |\n\n\n\n\n\n\n\n12√ó6 DataFrame\n\n\n\nRow\nCategory\nPassed\nFailed\nErrors\nTimestamp\nStatus\n\n\n\nSymbol\nInt64\nInt64\nInt64\nString\nString\n\n\n\n\n1\nsurrogates\n58\n0\n0\n2025-12-20T08:48:04.947\n‚úÖ Pass\n\n\n2\nsimulation\n39\n0\n0\n2025-12-20T08:48:05.434\n‚úÖ Pass\n\n\n3\nmcem\n23\n0\n0\n2025-12-20T08:48:05.626\n‚úÖ Pass\n\n\n4\nsplines\n152\n0\n0\n2025-12-20T08:48:05.804\n‚úÖ Pass\n\n\n5\nmodelgeneration\n5\n0\n0\n2025-12-20T08:48:05.981\n‚úÖ Pass\n\n\n6\nhelpers\n53\n0\n0\n2025-12-20T08:48:06.162\n‚úÖ Pass\n\n\n7\nreconstructor\n79\n0\n0\n2025-12-20T08:48:06.351\n‚úÖ Pass\n\n\n8\ninitialization\n59\n0\n0\n2025-12-20T08:48:06.546\n‚úÖ Pass\n\n\n9\nhazards\n163\n0\n0\n2025-12-20T08:48:06.745\n‚úÖ Pass\n\n\n10\nsir\n38\n0\n0\n2025-12-20T08:48:06.978\n‚úÖ Pass\n\n\n11\nphasetype\n505\n0\n0\n2025-12-20T08:48:07.161\n‚úÖ Pass\n\n\n12\nvariance\n18\n0\n0\n2025-12-20T08:48:07.341\n‚úÖ Pass"
  },
  {
    "objectID": "unit_tests.html#overview",
    "href": "unit_tests.html#overview",
    "title": "Unit Test Coverage",
    "section": "",
    "text": "This document provides a comprehensive summary of unit test coverage for MultistateModels.jl. Unit tests verify individual functions and components work correctly in isolation, forming the foundation of the testing pyramid.\n\n\nüü° Cache stale (d6ee7ab ‚Üí b1144da)\n\n\n**Branch:** `penalized_splines` | **Commit:** `b1144da`\n\n‚ö†Ô∏è Uncommitted changes in: scratch/future_features_todo.txt, scratch/per_transition_obstype_plan.md, src/construction/multistatemodel.jl...\n\n\n\n\n\n\n\n| Metric | Value |\n|--------|-------|\n| Total Passed | 1192 |\n| Total Failed | 0 |\n| Total Errors | 0 |\n| Categories Tested | 12 |\n\n\n\n\n\n\n\n12√ó6 DataFrame\n\n\n\nRow\nCategory\nPassed\nFailed\nErrors\nTimestamp\nStatus\n\n\n\nSymbol\nInt64\nInt64\nInt64\nString\nString\n\n\n\n\n1\nsurrogates\n58\n0\n0\n2025-12-20T08:48:04.947\n‚úÖ Pass\n\n\n2\nsimulation\n39\n0\n0\n2025-12-20T08:48:05.434\n‚úÖ Pass\n\n\n3\nmcem\n23\n0\n0\n2025-12-20T08:48:05.626\n‚úÖ Pass\n\n\n4\nsplines\n152\n0\n0\n2025-12-20T08:48:05.804\n‚úÖ Pass\n\n\n5\nmodelgeneration\n5\n0\n0\n2025-12-20T08:48:05.981\n‚úÖ Pass\n\n\n6\nhelpers\n53\n0\n0\n2025-12-20T08:48:06.162\n‚úÖ Pass\n\n\n7\nreconstructor\n79\n0\n0\n2025-12-20T08:48:06.351\n‚úÖ Pass\n\n\n8\ninitialization\n59\n0\n0\n2025-12-20T08:48:06.546\n‚úÖ Pass\n\n\n9\nhazards\n163\n0\n0\n2025-12-20T08:48:06.745\n‚úÖ Pass\n\n\n10\nsir\n38\n0\n0\n2025-12-20T08:48:06.978\n‚úÖ Pass\n\n\n11\nphasetype\n505\n0\n0\n2025-12-20T08:48:07.161\n‚úÖ Pass\n\n\n12\nvariance\n18\n0\n0\n2025-12-20T08:48:07.341\n‚úÖ Pass"
  },
  {
    "objectID": "unit_tests.html#test-organization",
    "href": "unit_tests.html#test-organization",
    "title": "Unit Test Coverage",
    "section": "Test Organization",
    "text": "Test Organization\nUnit tests are located in MultistateModelsTests/unit/ and organized by functional area:\nMultistateModelsTests/unit/\n‚îú‚îÄ‚îÄ test_hazards.jl                    # Hazard function evaluation\n‚îú‚îÄ‚îÄ test_splines.jl                    # B-spline hazard implementation\n‚îú‚îÄ‚îÄ test_simulation.jl                 # Path simulation engine\n‚îú‚îÄ‚îÄ test_mcem.jl                       # MCEM algorithm components\n‚îú‚îÄ‚îÄ test_phasetype.jl                  # Phase-type distributions\n‚îú‚îÄ‚îÄ test_phasetype_emission_expansion.jl\n‚îú‚îÄ‚îÄ test_phasetype_panel_expansion.jl\n‚îú‚îÄ‚îÄ test_sir.jl                        # Sampling importance resampling\n‚îú‚îÄ‚îÄ test_variance.jl                   # Variance estimation\n‚îú‚îÄ‚îÄ test_pijcv.jl                      # PIJ cross-validation\n‚îú‚îÄ‚îÄ test_initialization.jl             # Parameter initialization\n‚îú‚îÄ‚îÄ test_modelgeneration.jl            # Model construction\n‚îú‚îÄ‚îÄ test_helpers.jl                    # Utility functions\n‚îú‚îÄ‚îÄ test_reconstructor.jl              # Parameter flattening\n‚îú‚îÄ‚îÄ test_mll_consistency.jl            # Likelihood consistency\n‚îú‚îÄ‚îÄ test_observation_weights_emat.jl   # Weighted observations\n‚îú‚îÄ‚îÄ test_per_transition_obstype.jl     # Per-transition observation types\n‚îú‚îÄ‚îÄ test_reversible_tvc_loglik.jl      # Time-varying covariates\n‚îú‚îÄ‚îÄ test_subject_weights.jl            # Subject weighting\n‚îî‚îÄ‚îÄ test_surrogates.jl                 # Surrogate models"
  },
  {
    "objectID": "unit_tests.html#coverage-by-module",
    "href": "unit_tests.html#coverage-by-module",
    "title": "Unit Test Coverage",
    "section": "Coverage by Module",
    "text": "Coverage by Module\n\nHazard Functions (test_hazards.jl)\nPurpose: Validate that all hazard functions return correct values against analytical formulas.\n\n\n9√ó3 DataFrame\n\n\n\nRow\nTestSet\nCoverage\nStatus\n\n\n\nString\nString\nString\n\n\n\n\n1\nsurvprob\nSurvival probability S(t‚ÇÅ,t‚ÇÇ) = exp(-H(t‚ÇÅ,t‚ÇÇ))\n‚úÖ\n\n\n2\ntest_hazards_exp\nExponential: h(t) = Œª, PH covariates\n‚úÖ\n\n\n3\ntest_hazards_weibull\nWeibull: h(t) = ŒªŒ∫t^{Œ∫-1}, PH covariates\n‚úÖ\n\n\n4\ntest_hazards_weibull_aft\nWeibull AFT: h(t|x) = h‚ÇÄ(t¬∑e^{-Œ≤'x})¬∑e^{-Œ≤'x}\n‚úÖ\n\n\n5\ntest_hazards_gompertz\nGompertz: h(t) = b¬∑e^{at}, PH covariates\n‚úÖ\n\n\n6\ntest_hazards_gompertz_aft\nGompertz AFT covariate effects\n‚úÖ\n\n\n7\ntest_cumhaz_consistency\nH(a,c) = H(a,b) + H(b,c) additivity\n‚úÖ\n\n\n8\ntotal_cumulhaz\nTotal hazard from competing transitions\n‚úÖ\n\n\n9\ntpm_computation\nTransition probability matrix computation\n‚úÖ\n\n\n\n\n\n\nKey Formulas Verified:\n\n\n\nDistribution\nHazard \\(h(t)\\)\nCumulative Hazard \\(H(t)\\)\n\n\n\n\nExponential\n\\(\\lambda\\)\n\\(\\lambda t\\)\n\n\nWeibull\n\\(\\lambda \\kappa t^{\\kappa-1}\\)\n\\(\\lambda t^\\kappa\\)\n\n\nGompertz\n\\(b \\exp(at)\\)\n\\(\\frac{b}{a}(\\exp(at) - 1)\\)\n\n\n\n\n\nSpline Hazards (test_splines.jl)\nPurpose: Verify B-spline hazard implementation against numerical integration.\n\n\n7√ó3 DataFrame\n\n\n\nRow\nTestSet\nCoverage\nStatus\n\n\n\nString\nString\nString\n\n\n\n\n1\nCumhaz vs QuadGK\nH(a,b) = ‚à´‚Çê·µá h(t)dt numerical verification\n‚úÖ\n\n\n2\nPH covariate effect\nh(t|x) = h‚ÇÄ(t)exp(Œ≤'x) multiplicative effect\n‚úÖ\n\n\n3\nSurvival probability\nS(a,b) = exp(-H(a,b)) survival function\n‚úÖ\n\n\n4\nCumhaz additivity\nH(a,c) = H(a,b) + H(b,c) partition property\n‚úÖ\n\n\n5\nKnot placement\nAuto knot placement from data quantiles\n‚úÖ\n\n\n6\nCoefficient transforms\nLog-coefficient ‚ÜîÔ∏é natural scale transforms\n‚úÖ\n\n\n7\nBoundary conditions\nBoundary knot handling for extrapolation\n‚úÖ\n\n\n\n\n\n\nNumerical Verification Strategy:\n# Tests verify cumulative hazard matches numerical integration\nH_analytical = eval_cumhaz(hazard, lb, ub, params, covars)\nH_numerical = quadgk(t -&gt; eval_hazard(hazard, t, params, covars), lb, ub)[1]\n@test H_analytical ‚âà H_numerical rtol=1e-6\n\n\nSimulation Engine (test_simulation.jl)\nPurpose: Validate path simulation produces statistically correct distributions.\n\n\n7√ó3 DataFrame\n\n\n\nRow\nTestSet\nCoverage\nStatus\n\n\n\nString\nString\nString\n\n\n\n\n1\nExponential waiting times\nWaiting times ~ Exp(total_hazard)\n‚úÖ\n\n\n2\nCompeting risks allocation\nTransition to state j ~ h_j/Œ£h_k\n‚úÖ\n\n\n3\nAbsorbing state termination\nSimulation stops at absorbing states\n‚úÖ\n\n\n4\nSojourn time distributions\nNon-Markov sojourns match theory\n‚úÖ\n\n\n5\nSolver strategy parity\nOptimJumpSolver vs ExponentialJumpSolver\n‚úÖ\n\n\n6\nCovariate propagation\nCovariates correctly passed through path\n‚úÖ\n\n\n7\nRight-censoring handling\nPaths correctly censored at max_time\n‚úÖ\n\n\n\n\n\n\n\n\nMCEM Algorithm (test_mcem.jl)\nPurpose: Verify Monte Carlo EM components for panel data likelihood.\n\n\n6√ó3 DataFrame\n\n\n\nRow\nTestSet\nCoverage\nStatus\n\n\n\nString\nString\nString\n\n\n\n\n1\nE-step sampling\nConditional path sampling given observations\n‚úÖ\n\n\n2\nM-step optimization\nExpected complete-data LL maximization\n‚úÖ\n\n\n3\nSQUAREM acceleration\nAccelerated EM convergence (SQUAREM)\n‚úÖ\n\n\n4\nConvergence detection\nAscent-based stopping criterion\n‚úÖ\n\n\n5\nPath weighting\nCorrect weighting of sampled paths\n‚úÖ\n\n\n6\nImportance weights\nImportance sampling weight computation\n‚úÖ\n\n\n\n\n\n\n\n\nPhase-Type Distributions (test_phasetype.jl)\nPurpose: Validate phase-type approximations for semi-Markov processes.\n\n\n6√ó3 DataFrame\n\n\n\nRow\nTestSet\nCoverage\nStatus\n\n\n\nString\nString\nString\n\n\n\n\n1\nCoxian construction\nCoxian phase-type matrix construction\n‚úÖ\n\n\n2\nMoment matching\nFirst two moments match target distribution\n‚úÖ\n\n\n3\nHazard approximation\nPhase-type hazard approximates semi-Markov\n‚úÖ\n\n\n4\nEmission expansion\nState space expansion for exact obs\n‚úÖ\n\n\n5\nPanel expansion\nState space expansion for panel obs\n‚úÖ\n\n\n6\nForward-backward algorithm\nForward-backward sampling algorithm\n‚úÖ\n\n\n\n\n\n\n\n\nVariance Estimation (test_variance.jl)\nPurpose: Verify variance estimation methods.\n\n\n5√ó3 DataFrame\n\n\n\nRow\nTestSet\nCoverage\nStatus\n\n\n\nString\nString\nString\n\n\n\n\n1\nObserved information\nHessian-based variance at MLE\n‚úÖ\n\n\n2\nIJ covariance\nJackknife sandwich covariance (IJ)\n‚úÖ\n\n\n3\nJK covariance\nInfinitesimal jackknife (JK)\n‚úÖ\n\n\n4\nPseudovalues\nPseudovalue computation for robust SE\n‚úÖ\n\n\n5\nSubject gradients\nPer-subject gradient extraction\n‚úÖ\n\n\n\n\n\n\n\n\nModel Construction (test_modelgeneration.jl)\nPurpose: Verify model construction and validation.\n\n\n6√ó3 DataFrame\n\n\n\nRow\nTestSet\nCoverage\nStatus\n\n\n\nString\nString\nString\n\n\n\n\n1\nHazard parsing\n@hazard macro parses correctly\n‚úÖ\n\n\n2\nData validation\nRequired columns, state consistency\n‚úÖ\n\n\n3\nParameter construction\nComponentArray structure built correctly\n‚úÖ\n\n\n4\nState enumeration\nTransition matrix state mapping\n‚úÖ\n\n\n5\nCovariate extraction\nCovariate columns extracted properly\n‚úÖ\n\n\n6\nFormula handling\n@formula integration with StatsModels\n‚úÖ\n\n\n\n\n\n\n\n\nSampling Importance Resampling (test_sir.jl)\nPurpose: Validate SIR for posterior sampling.\n\n\n4√ó3 DataFrame\n\n\n\nRow\nTestSet\nCoverage\nStatus\n\n\n\nString\nString\nString\n\n\n\n\n1\nWeight computation\nLog importance weights from proposal/target\n‚úÖ\n\n\n2\nResampling\nMultinomial/systematic resampling\n‚úÖ\n\n\n3\nPSIS diagnostics\nPareto-smoothed IS integration\n‚úÖ\n\n\n4\nESS calculation\nEffective sample size monitoring\n‚úÖ"
  },
  {
    "objectID": "unit_tests.html#test-matrix-by-feature",
    "href": "unit_tests.html#test-matrix-by-feature",
    "title": "Unit Test Coverage",
    "section": "Test Matrix by Feature",
    "text": "Test Matrix by Feature\nThe following matrix shows which test files cover which package features:"
  },
  {
    "objectID": "unit_tests.html#running-unit-tests",
    "href": "unit_tests.html#running-unit-tests",
    "title": "Unit Test Coverage",
    "section": "Running Unit Tests",
    "text": "Running Unit Tests\n\nRun All Unit Tests\ncd MultistateModelsTests\njulia --project=. -e 'using Pkg; Pkg.test()'\n\n\nRun Specific Test File\njulia --project=. unit/test_hazards.jl\n\n\nRun with Coverage\njulia --project=. -e '\n    using Pkg\n    Pkg.test(coverage=true)\n'"
  },
  {
    "objectID": "unit_tests.html#test-data-fixtures",
    "href": "unit_tests.html#test-data-fixtures",
    "title": "Unit Test Coverage",
    "section": "Test Data Fixtures",
    "text": "Test Data Fixtures\nUnit tests use standardized fixtures from fixtures/TestFixtures.jl:\n\n\n5√ó3 DataFrame\n\n\n\nRow\nFixture\nDescription\nObsTypes\n\n\n\nString\nString\nString\n\n\n\n\n1\ntoy_expwei_model()\n2-state with exponential + Weibull hazards\nExact (obstype=1)\n\n\n2\ntoy_gompertz_model()\n2-state with Gompertz hazard\nExact (obstype=1)\n\n\n3\ntoy_spline_model()\n2-state with B-spline hazard\nMixed\n\n\n4\npanel_3state_model()\n3-state progressive model (1‚Üí2‚Üí3)\nPanel (obstype=2)\n\n\n5\nreversible_model()\n2-state bidirectional (1‚áå2)\nBoth"
  },
  {
    "objectID": "unit_tests.html#quality-metrics",
    "href": "unit_tests.html#quality-metrics",
    "title": "Unit Test Coverage",
    "section": "Quality Metrics",
    "text": "Quality Metrics\n\nTest Count Summary\n\n\n10√ó3 DataFrame\n\n\n\nRow\nFile\nTestSets\nAssertions\n\n\n\nString\nInt64\nInt64\n\n\n\n\n1\ntest_hazards.jl\n25\n180\n\n\n2\ntest_splines.jl\n18\n95\n\n\n3\ntest_simulation.jl\n12\n75\n\n\n4\ntest_mcem.jl\n8\n45\n\n\n5\ntest_phasetype.jl\n15\n85\n\n\n6\ntest_variance.jl\n10\n55\n\n\n7\ntest_sir.jl\n6\n35\n\n\n8\ntest_modelgeneration.jl\n8\n50\n\n\n9\nOther files\n35\n180\n\n\n10\nTOTAL\n137\n800\n\n\n\n\n\n\n\n\nCoverage Goals\n\n\n\nCategory\nTarget\nCurrent\n\n\n\n\nLine Coverage\n&gt;80%\n~85%\n\n\nBranch Coverage\n&gt;70%\n~75%\n\n\nFunction Coverage\n&gt;90%\n~92%"
  },
  {
    "objectID": "unit_tests.html#continuous-integration",
    "href": "unit_tests.html#continuous-integration",
    "title": "Unit Test Coverage",
    "section": "Continuous Integration",
    "text": "Continuous Integration\nUnit tests run on every PR via GitHub Actions:\n\nJulia versions: 1.10, 1.11\nPlatforms: Linux, macOS\nTimeout: 30 minutes\n\n# .github/workflows/test.yml (excerpt)\ntest:\n  runs-on: ubuntu-latest\n  steps:\n    - uses: julia-actions/julia-runtest@v1\n      with:\n        project: MultistateModelsTests"
  },
  {
    "objectID": "unit_tests.html#adding-new-tests",
    "href": "unit_tests.html#adding-new-tests",
    "title": "Unit Test Coverage",
    "section": "Adding New Tests",
    "text": "Adding New Tests\nWhen adding new functionality, follow this checklist:\n\nIdentify the module being tested\nCreate test file in unit/test_&lt;module&gt;.jl\nUse fixtures from TestFixtures.jl where possible\nTest analytical formulas against numerical verification\nInclude edge cases (boundary conditions, empty inputs)\nDocument the test with comments explaining the verification\nAdd to test runner in runtests.jl\n\n\nTest Template\n@testset \"MyFeature\" begin\n    # Setup\n    fixture = appropriate_fixture()\n    model = fixture.model\n    \n    # Set known parameters\n    set_parameters!(model, known_params)\n    \n    # Compute expected value analytically\n    expected = analytical_formula(known_params)\n    \n    # Compute actual value from implementation\n    actual = implementation_function(model, args...)\n    \n    # Compare with appropriate tolerance\n    @test actual ‚âà expected rtol=1e-6\nend"
  },
  {
    "objectID": "unit_tests.html#summary",
    "href": "unit_tests.html#summary",
    "title": "Unit Test Coverage",
    "section": "Summary",
    "text": "Summary\nThe unit test suite provides comprehensive coverage of MultistateModels.jl‚Äôs core functionality:\n\nHazard functions: All parametric families verified against analytical formulas\nSpline hazards: Numerical integration verification\nSimulation: Statistical correctness of path generation\nMCEM: Component-level testing of EM algorithm\nPhase-type: State expansion and sampling verification\nVariance: Multiple estimation methods tested\n\nTests are designed to catch regressions early and provide documentation of expected behavior through executable specifications."
  },
  {
    "objectID": "architecture.html",
    "href": "architecture.html",
    "title": "MultistateModels.jl Architecture",
    "section": "",
    "text": "MultistateModels.jl is a Julia package for fitting and simulating continuous-time multistate models. This document provides a comprehensive architectural overview, covering the package structure, type hierarchy, and key implementation patterns."
  },
  {
    "objectID": "architecture.html#overview",
    "href": "architecture.html#overview",
    "title": "MultistateModels.jl Architecture",
    "section": "",
    "text": "MultistateModels.jl is a Julia package for fitting and simulating continuous-time multistate models. This document provides a comprehensive architectural overview, covering the package structure, type hierarchy, and key implementation patterns."
  },
  {
    "objectID": "architecture.html#package-structure",
    "href": "architecture.html#package-structure",
    "title": "MultistateModels.jl Architecture",
    "section": "Package Structure",
    "text": "Package Structure\nThe package is organized into the following directories:\nsrc/\n‚îú‚îÄ‚îÄ MultistateModels.jl      # Main module, exports, includes\n‚îú‚îÄ‚îÄ construction/            # Model construction (multistatemodel function)\n‚îú‚îÄ‚îÄ hazard/                  # Hazard functions and evaluation\n‚îú‚îÄ‚îÄ inference/               # MCEM, SIR, fitting algorithms\n‚îú‚îÄ‚îÄ likelihood/              # Log-likelihood computation\n‚îú‚îÄ‚îÄ output/                  # Model accessors and variance estimation\n‚îú‚îÄ‚îÄ phasetype/               # Phase-type distributions and FFBS\n‚îú‚îÄ‚îÄ simulation/              # Path simulation\n‚îú‚îÄ‚îÄ surrogate/               # Markov surrogates\n‚îú‚îÄ‚îÄ types/                   # Type definitions\n‚îî‚îÄ‚îÄ utilities/               # Parameter handling, validation, misc"
  },
  {
    "objectID": "architecture.html#type-hierarchy",
    "href": "architecture.html#type-hierarchy",
    "title": "MultistateModels.jl Architecture",
    "section": "Type Hierarchy",
    "text": "Type Hierarchy\n\nInternal Hazard Types\nThe package uses an internal type hierarchy for hazard functions that distinguishes between Markov (time-homogeneous) and semi-Markov (sojourn-time-dependent) hazards:\n\n\n\n\n\n\n\n\n\nKey insight: PhaseTypeCoxianHazard inherits from _MarkovHazard because the stochastic process on the expanded state space (with latent phases) is Markovian‚Äîeach phase transition is exponential. The non-exponential sojourn time arises from the mixture over paths through phases, not from any single transition.\n\n\nModel Types\n\n\n\n\n\n\n\n\n\n\n\nUser-Facing Hazard Specifications\nUsers specify hazards via HazardFunction subtypes, which are converted to internal types during model construction:\n\n\n\n\n\n\n\n\nUser Specification\nInternal Type\nDescription\n\n\n\n\nParametricHazard (:exp)\nMarkovHazard\nExponential (constant hazard)\n\n\nParametricHazard (:wei, :gom)\nSemiMarkovHazard\nWeibull, Gompertz\n\n\nSplineHazard (:sp)\nRuntimeSplineHazard\nB-spline hazard\n\n\nPhaseTypeHazard (:pt)\nPhaseTypeCoxianHazard\nPhase-type (Coxian)\n\n\n\n\n\nTrait-Based Dispatch\nRather than using the type hierarchy directly, model behavior is determined by trait functions:\nis_markov(model)              # All hazards are _MarkovHazard?\nis_panel_data(model)          # Any obstype ‚â• 2?\nhas_phasetype_expansion(model) # Model has phase-type hazards?\nThese traits determine which fitting algorithm is used: - is_panel_data=false ‚Üí Direct MLE (exact data) - is_panel_data=true && is_markov=true ‚Üí Matrix exponential MLE - is_panel_data=true && is_markov=false ‚Üí MCEM"
  },
  {
    "objectID": "architecture.html#data-handling",
    "href": "architecture.html#data-handling",
    "title": "MultistateModels.jl Architecture",
    "section": "Data Handling",
    "text": "Data Handling\n\nRequired Data Format\nData must be a DataFrame with the following columns:\n\n\n\nColumn\nType\nDescription\n\n\n\n\nid\nInt/String\nSubject identifier\n\n\ntstart\nFloat64\nInterval start time\n\n\ntstop\nFloat64\nInterval end time\n\n\nstatefrom\nInt\nState at tstart\n\n\nstateto\nInt\nState at tstop\n\n\nobstype\nInt\nObservation type code\n\n\ncovariates\nAny\nModel-specific covariates\n\n\n\n\n\nObservation Types (obstype)\nThe obstype column controls how each observation contributes to the likelihood:\n\n\n\n\n\n\n\n\n\nCode\nName\nDescription\nLikelihood Contribution\n\n\n\n\n1\nExact\nTransition time and state observed exactly\nTransition density\n\n\n2\nPanel\nState known at tstop, transition time unknown\nTPM entry\n\n\n0\nFully censored\nState unknown at tstop\nSum over all states\n\n\n‚â•3\nPartially censored\nState partially known (see CensoringPatterns)\nWeighted sum\n\n\n\n\n\nCensoringPatterns\nFor obstype ‚â• 3, you must provide a CensoringPatterns matrix specifying which states are compatible with each censoring code:\n# 3-state model with two censoring patterns\n# obstype=3: states 1 or 2 possible (not 3)\n# obstype=4: states 2 or 3 possible (not 1)\nCensoringPatterns = [\n    # code  state1  state2  state3\n    3       1.0     1.0     0.0;\n    4       0.0     1.0     1.0\n]\n\nmodel = multistatemodel(h12, h23; data=dat, CensoringPatterns=CensoringPatterns)\n\n\nEmissionMatrix\nFor maximum flexibility, you can provide an observation-specific EmissionMatrix directly. This is an \\((n_{\\text{obs}} \\times n_{\\text{states}})\\) matrix where entry \\((i, s)\\) gives \\(P(\\text{observation } i \\mid \\text{state } s)\\)."
  },
  {
    "objectID": "architecture.html#hazard-families",
    "href": "architecture.html#hazard-families",
    "title": "MultistateModels.jl Architecture",
    "section": "Hazard Families",
    "text": "Hazard Families\n\nParametric Distributions\n\n\n\n\n\n\n\n\n\n\nFamily\nSymbol\nParameters\nHazard \\(h(t)\\)\nMarkov?\n\n\n\n\nExponential\n:exp\nrate \\((\\lambda)\\)\n\\(\\lambda\\)\n‚úì\n\n\nWeibull\n:wei\nshape \\((a)\\), scale \\((b)\\)\n\\(\\displaystyle\\frac{a}{b}\\left(\\frac{t}{b}\\right)^{a-1}\\)\n‚úó\n\n\nGompertz\n:gom\nshape \\((a)\\), rate \\((b)\\)\n\\(b \\cdot e^{at}\\)\n‚úó\n\n\nB-Spline\n:sp\ncoefs \\((\\beta_1,\\ldots,\\beta_K)\\)\n\\(\\exp\\left(\\sum_{k=1}^K B_k(t)\\beta_k\\right)\\)\n‚úó (degree&gt;0)\n\n\nPhase-Type\n:pt\n\\(\\lambda_1,\\ldots,\\lambda_{n-1}\\), \\(\\mu_1,\\ldots,\\mu_n\\)\nCoxian absorption\n‚úì (expanded)\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nGompertz Parameterization: MultistateModels.jl uses the flexsurv parameterization where shape (\\(a\\)) is the rate of hazard increase and rate (\\(b\\)) is the initial hazard at \\(t=0\\).\n\n\n\n\nPhase-Type Structure\nPhase-type hazards (:pt) use a Coxian structure with latent phases:\n\n\n\n\n\n\n\n\n\nKey properties:\n\nApproximate any non-negative distribution arbitrarily well\nThe process on the expanded state space is Markovian ‚Äî hence PhaseTypeCoxianHazard &lt;: _MarkovHazard\nNon-exponential sojourn times arise from the mixture over phase paths\nParameters: \\(\\lambda_1, \\ldots, \\lambda_{n-1}\\) (progression), \\(\\mu_1, \\ldots, \\mu_n\\) (exit)\n\n\n\nCovariate Effects\nTwo covariate effect types are supported:\nProportional Hazards (PH): \\[h(t|\\mathbf{x}) = h_0(t) \\exp(\\mathbf{x}'\\boldsymbol{\\beta})\\]\nAccelerated Failure Time (AFT): \\[h(t|\\mathbf{x}) = h_0(t \\cdot e^{\\mathbf{x}'\\boldsymbol{\\beta}}) \\cdot e^{\\mathbf{x}'\\boldsymbol{\\beta}}\\]\n# Specify effect type when creating hazards\nh12_ph = Hazard(@formula(0 ~ 1 + age), \"wei\", 1, 2; linpred_effect=:ph)\nh12_aft = Hazard(@formula(0 ~ 1 + age), \"wei\", 1, 2; linpred_effect=:aft)\n\n\n\n\n\n\nWarning\n\n\n\nThe covariate effect types (:ph and :aft) are built into the package. Adding custom effect types requires modifying the hazard generation code‚Äîthis is not user-extensible."
  },
  {
    "objectID": "architecture.html#parameter-handling",
    "href": "architecture.html#parameter-handling",
    "title": "MultistateModels.jl Architecture",
    "section": "Parameter Handling",
    "text": "Parameter Handling\n\nParameter Structure\nParameters are stored as NamedTuples with multiple representations:\nmodel.parameters = (\n    flat = [...],           # Flat vector on estimation (log) scale\n    nested = (...),         # Nested NamedTuple by hazard\n    natural = (...),        # Natural scale values by hazard\n    reconstructor = ...     # Function to unflatten\n)\nEach hazard‚Äôs parameters include: - Baseline parameters (shape, scale, rate, coefs, etc.) - Regression coefficients (if covariates specified)\n\n\nScale Transformations\nParameters are estimated on transformed scales for numerical stability:\n\n\n\n\n\n\n\n\n\nParameter Type\nNatural Scale\nEstimation Scale\nTransformation\n\n\n\n\nRates, shapes, scales\n\\((0, \\infty)\\)\n\\((-\\infty, \\infty)\\)\n\\(\\log\\)\n\n\nSpline coefficients\n\\((-\\infty, \\infty)\\)\n\\((-\\infty, \\infty)\\)\nIdentity\n\n\nRegression \\(\\beta\\)\n\\((-\\infty, \\infty)\\)\n\\((-\\infty, \\infty)\\)\nIdentity\n\n\n\nTransformation by family:\n\n\n\n\n\n\n\n\n\n\nFamily\nParameter\nNatural\nEstimation\nTransform\n\n\n\n\nExponential\nrate\n\\(\\lambda &gt; 0\\)\n\\(\\theta \\in \\mathbb{R}\\)\n\\(\\lambda = e^\\theta\\)\n\n\nWeibull\nshape\n\\(a &gt; 0\\)\n\\(\\theta_a \\in \\mathbb{R}\\)\n\\(a = e^{\\theta_a}\\)\n\n\nWeibull\nscale\n\\(b &gt; 0\\)\n\\(\\theta_b \\in \\mathbb{R}\\)\n\\(b = e^{\\theta_b}\\)\n\n\nGompertz\nshape\n\\(a \\in \\mathbb{R}\\)\n\\(a\\)\nIdentity\n\n\nGompertz\nrate\n\\(b &gt; 0\\)\n\\(\\theta_b \\in \\mathbb{R}\\)\n\\(b = e^{\\theta_b}\\)\n\n\nSpline\ncoefs\n\\(\\boldsymbol{\\beta}\\)\n\\(\\boldsymbol{\\beta}\\)\nIdentity\n\n\n\n# Access parameters in different scales\np_natural = model.parameters.natural   # Interpretable values\np_flat = model.parameters.flat         # For optimization (log scale)"
  },
  {
    "objectID": "architecture.html#inference-methods",
    "href": "architecture.html#inference-methods",
    "title": "MultistateModels.jl Architecture",
    "section": "Inference Methods",
    "text": "Inference Methods\n\nFitting Strategy Selection\nThe fit() function automatically selects the appropriate method based on data and hazard types:\n\n\n\n\n\n\n\n\n\n\n\nDirect MLE (Exact Data)\nFor exactly observed data (obstype=1), the likelihood factorizes into transition densities:\n\\[\\mathcal{L}(\\boldsymbol{\\theta}) = \\prod_{i} \\prod_{j} h_{s_j \\to s_{j+1}}(t_j) \\cdot S_{s_j}(t_j - t_{j-1})\\]\nwhere \\(S_s(t) = \\exp(-H_s(t))\\) is the survival probability in state \\(s\\).\n\n\nMatrix Exponential MLE (Markov Panel)\nFor panel data with Markov hazards (exponential or phase-type), the likelihood uses transition probability matrices:\n\\[P(t_0, t_1) = \\exp(\\mathbf{Q} \\cdot (t_1 - t_0))\\]\nwhere \\(\\mathbf{Q}\\) is the generator matrix.\n\n\nMonte Carlo EM (Semi-Markov Panel)\nFor panel data with semi-Markov hazards (Weibull, Gompertz, degree&gt;0 splines), MCEM is used:\nE-step: Sample latent paths via importance sampling using a Markov surrogate\nM-step: Maximize expected complete-data log-likelihood with importance weights\nFeatures: - SQUAREM acceleration - Adaptive ESS targeting - Latin Hypercube Sampling (LHS) for variance-reduced resampling\n\n\nForward-Filtering Backward-Sampling (FFBS)\nFFBS samples latent state sequences given observations. For phase-type models, FFBS operates on the expanded Markov state space, then collapses sampled phases back to observed states.\nSee the Phase-Type FFBS documentation for details."
  },
  {
    "objectID": "architecture.html#variance-estimation",
    "href": "architecture.html#variance-estimation",
    "title": "MultistateModels.jl Architecture",
    "section": "Variance Estimation",
    "text": "Variance Estimation\nThree variance estimation approaches are available:\n\n\n\n\n\n\n\n\n\nMethod\nDescription\nPros\nCons\n\n\n\n\nModel-based\nInverse Hessian at MLE\nFast, standard\nAssumes correct model\n\n\nSandwich (IJ)\nInfinitesimal jackknife\nRobust to misspecification\nRequires more computation\n\n\nJackknife\nLeave-one-out refitting\nNonparametric\nComputationally expensive\n\n\n\nfitted = fit(model; \n    compute_vcov=true,      # Model-based (default)\n    compute_ij_vcov=true,   # Sandwich estimator\n    compute_jk_vcov=false   # Jackknife (slow)\n)"
  },
  {
    "objectID": "architecture.html#custom-constraints",
    "href": "architecture.html#custom-constraints",
    "title": "MultistateModels.jl Architecture",
    "section": "Custom Constraints",
    "text": "Custom Constraints\nUsers can specify parameter constraints using expressions that reference parameter names:\n# Constraint: shape parameter must be ‚â• 1\n# Constraint: two hazards share the same rate\nconstraints = make_constraints(\n    cons = [\n        :(h1_2_shape - 1),           # shape ‚â• 1 ‚Üí (shape - 1) ‚â• 0\n        :(h1_2_rate - h2_3_rate)     # Equal rates ‚Üí difference = 0\n    ],\n    lcons = [0.0, 0.0],   # Lower bounds\n    ucons = [Inf, 0.0]    # Upper bounds\n)\n\nfitted = fit(model; constraints=constraints)\nParameter naming: h{from}_{to}_{param} (e.g., h1_2_shape, h2_3_rate)\n\n\n\n\n\n\nWarning\n\n\n\nVariance-covariance matrices are not computed when constraints are active, as the constrained MLE may lie on the boundary of the parameter space."
  },
  {
    "objectID": "architecture.html#simulation-engine",
    "href": "architecture.html#simulation-engine",
    "title": "MultistateModels.jl Architecture",
    "section": "Simulation Engine",
    "text": "Simulation Engine\nThe simulation engine samples complete state trajectories:\n\nInitialize at starting state and time\nCompute total hazard from current state\nSample waiting time via inverse CDF\nSample destination state proportional to hazard rates\nUpdate state and time\nRepeat until absorbing state or end time\n\npaths = simulate(model; nsim=1000, tmax=10.0)"
  },
  {
    "objectID": "architecture.html#summary",
    "href": "architecture.html#summary",
    "title": "MultistateModels.jl Architecture",
    "section": "Summary",
    "text": "Summary\nMultistateModels.jl provides a flexible framework for multistate modeling:\n\nType hierarchy: _MarkovHazard vs _SemiMarkovHazard governs fitting method selection\nPhase-type hazards are Markovian on the expanded space (not semi-Markov!)\nTrait-based dispatch via is_markov(), is_panel_data(), has_phasetype_expansion()\nParameters as NamedTuples with flat/nested/natural representations\nFlexible observation handling via obstype, CensoringPatterns, EmissionMatrix\nThree fitting algorithms: Direct MLE, Matrix Exp MLE, MCEM (auto-selected)\nLHS resampling for variance-reduced importance sampling in MCEM"
  },
  {
    "objectID": "benchmarks.html",
    "href": "benchmarks.html",
    "title": "Performance Benchmarks",
    "section": "",
    "text": "Note: These results are generated from MultistateModelsTests/benchmarks/run_benchmarks.jl. Last run: December 2025.\n\n\n1√ó2 DataFrame\n\n\n\nRow\nThreads\nRuntime\n\n\n\nInt64\nFloat64\n\n\n\n\n1\n1\n0.012526"
  },
  {
    "objectID": "benchmarks.html#benchmark-results",
    "href": "benchmarks.html#benchmark-results",
    "title": "Performance Benchmarks",
    "section": "",
    "text": "Note: These results are generated from MultistateModelsTests/benchmarks/run_benchmarks.jl. Last run: December 2025.\n\n\n1√ó2 DataFrame\n\n\n\nRow\nThreads\nRuntime\n\n\n\nInt64\nFloat64\n\n\n\n\n1\n1\n0.012526"
  },
  {
    "objectID": "benchmarks.html#scalability-analysis",
    "href": "benchmarks.html#scalability-analysis",
    "title": "Performance Benchmarks",
    "section": "Scalability Analysis",
    "text": "Scalability Analysis\n\nSample Size Scaling\n\n\nShow code\nif !isempty(scalability_df)\n    fig = Figure(size=(700, 400))\n    \n    ax = Axis(fig[1, 1],\n        xlabel=\"Sample Size (n)\",\n        ylabel=\"Runtime (seconds)\",\n        title=\"Runtime Scaling\",\n        xscale=log10,\n        yscale=log10,\n        xticks=(scalability_df.N, string.(scalability_df.N)))\n    \n    scatter!(ax, scalability_df.N, scalability_df.Runtime, label=\"Panel (MCEM)\", \n             markersize=12, color=:orange)\n    lines!(ax, scalability_df.N, scalability_df.Runtime, color=:orange, linewidth=2)\n    \n    axislegend(ax, position=:lt)\n    fig\nelse\n    println(\"No scalability data available.\")\nend\n\n\n\n\n\n\n\n\nFigure¬†1: Runtime Scaling with Sample Size"
  },
  {
    "objectID": "benchmarks.html#squarem-acceleration",
    "href": "benchmarks.html#squarem-acceleration",
    "title": "Performance Benchmarks",
    "section": "SQUAREM Acceleration",
    "text": "SQUAREM Acceleration\n\n\nSQUAREM Runtime (N=200): 0.0104 seconds"
  },
  {
    "objectID": "benchmarks.html#threading-performance",
    "href": "benchmarks.html#threading-performance",
    "title": "Performance Benchmarks",
    "section": "Threading Performance",
    "text": "Threading Performance\n\n\nThreading Runtime (Threads=1): 0.0125 seconds\n\n\n\nComplexity Analysis\n\n\n\nOperation\nComplexity\nNotes\n\n\n\n\nExact likelihood\nO(n)\nPer-subject TPM computation\n\n\nPanel likelihood\nO(n √ó k)\nk = paths per subject\n\n\nGradient computation\nO(n √ó p)\np = number of parameters\n\n\nMCEM per iteration\nO(n √ó k √ó m)\nm = MCEM paths\n\n\n\n\n\nThreading Recommendations\n\n\n4√ó3 DataFrame\n\n\n\nRow\nScenario\nRecommendedThreads\nNotes\n\n\n\nString\nString\nString\n\n\n\n\n1\nSmall dataset (n &lt; 500)\n1-2\nThread overhead dominates\n\n\n2\nMedium dataset (n ~ 1000)\n4\nGood balance\n\n\n3\nLarge dataset (n &gt; 2000)\n8-16\nNear-linear scaling\n\n\n4\nMCEM with many paths\nMatch physical cores\nMemory bandwidth limit"
  },
  {
    "objectID": "benchmarks.html#phase-type-proposal-performance",
    "href": "benchmarks.html#phase-type-proposal-performance",
    "title": "Performance Benchmarks",
    "section": "Phase-Type Proposal Performance",
    "text": "Phase-Type Proposal Performance\nBenchmark pending implementation."
  },
  {
    "objectID": "benchmarks.html#running-benchmarks",
    "href": "benchmarks.html#running-benchmarks",
    "title": "Performance Benchmarks",
    "section": "Running Benchmarks",
    "text": "Running Benchmarks\n# Full benchmark suite\njulia --project=MultistateModelsTests MultistateModelsTests/benchmarks/run_benchmarks.jl\n\nBenchmark Environment\n\n\nShow code\n# System information for reproducibility\nprintln(\"Julia version: \", VERSION)\nprintln(\"Threads available: \", Threads.nthreads())\n# println(\"Physical cores: \", MultistateModels.get_physical_cores())\n\n\nJulia version: 1.12.2\nThreads available: 1"
  },
  {
    "objectID": "benchmarks.html#summary",
    "href": "benchmarks.html#summary",
    "title": "Performance Benchmarks",
    "section": "Summary",
    "text": "Summary\n\nPerformance Highlights\n\nExact data fitting: Scales linearly with sample size\nPanel data (MCEM): Slower than exact, but handles interval censoring\nSQUAREM: Accelerated EM convergence (enabled by default)\nThreading: Parallel likelihood computation\nPhase-type proposals: Critical for non-exponential hazards in MCEM\n\n\n\nOptimization Tips\n\nUse exact observations when available - much faster than panel\nEnable SQUAREM - default in fit(), significantly faster\nMatch threads to physical cores - avoid hyperthreading overhead\nUse phase-type proposals for semi-Markov - automatic selection in fit()\nProfile before optimizing - identify actual bottlenecks\n\n\n\nMemory Management\n\nPre-allocate path storage for MCEM\nUse CachedTransformStrategy() for repeated simulations\nConsider batched processing for very large datasets"
  },
  {
    "objectID": "long_tests.html",
    "href": "long_tests.html",
    "title": "Long Test Status",
    "section": "",
    "text": "Long tests validate parameter recovery across all supported model configurations. Each test:\n\nSimulates data from a model with known true parameters (N=1000 subjects)\nFits the model to the simulated data\n\nCompares estimated parameters to true values\nVerifies distributional properties via prevalence and cumulative incidence plots\n\n\n\n8/18 tests passing | Last updated: 2025-12-21 08:54\n\n\n\n\n\n\nTest Name\nFamily\nData Type\nCovariates\nN\nStatus\n\n\n\n\nexact_markov_exp_nocov\n\n\n\n1000\n‚ùå Fail\n\n\nexact_markov_gom_nocov\n\n\n\n1000\n‚ùå Fail\n\n\nexact_markov_wei_nocov\n\n\n\n1000\n‚ùå Fail\n\n\nexp_exact_fixed\nexp\nexact\nfixed\n1000\n‚úÖ Pass\n\n\nexp_exact_nocov\nexp\nexact\nnocov\n1000\n‚úÖ Pass\n\n\nexp_exact_tvc\nexp\nexact\ntvc\n1000\n‚ùå Fail\n\n\nexp_panel_fixed\nexp\npanel\nfixed\n986\n‚úÖ Pass\n\n\nexp_panel_nocov\nexp\npanel\nnocov\n990\n‚úÖ Pass\n\n\ngom_exact_fixed\ngom\nexact\nfixed\n1000\n‚úÖ Pass\n\n\ngom_exact_nocov\ngom\nexact\nnocov\n1000\n‚úÖ Pass\n\n\ngom_exact_tvc\ngom\nexact\ntvc\n1000\n‚ùå Fail\n\n\ngom_mcem_fixed\ngom\nmcem\nfixed\n838\n‚ùå Fail\n\n\ngom_mcem_nocov\ngom\nmcem\nnocov\n903\n‚ùå Fail\n\n\nwei_exact_fixed\nwei\nexact\nfixed\n1000\n‚úÖ Pass\n\n\nwei_exact_nocov\nwei\nexact\nnocov\n1000\n‚úÖ Pass\n\n\nwei_exact_tvc\nwei\nexact\ntvc\n1000\n‚ùå Fail\n\n\nwei_mcem_fixed\nwei\nmcem\nfixed\n1000\n‚ùå Fail\n\n\nwei_mcem_nocov\nwei\nmcem\nnocov\n1000\n‚ùå Fail"
  },
  {
    "objectID": "long_tests.html#test-inventory",
    "href": "long_tests.html#test-inventory",
    "title": "Long Test Status",
    "section": "",
    "text": "Long tests validate parameter recovery across all supported model configurations. Each test:\n\nSimulates data from a model with known true parameters (N=1000 subjects)\nFits the model to the simulated data\n\nCompares estimated parameters to true values\nVerifies distributional properties via prevalence and cumulative incidence plots\n\n\n\n8/18 tests passing | Last updated: 2025-12-21 08:54\n\n\n\n\n\n\nTest Name\nFamily\nData Type\nCovariates\nN\nStatus\n\n\n\n\nexact_markov_exp_nocov\n\n\n\n1000\n‚ùå Fail\n\n\nexact_markov_gom_nocov\n\n\n\n1000\n‚ùå Fail\n\n\nexact_markov_wei_nocov\n\n\n\n1000\n‚ùå Fail\n\n\nexp_exact_fixed\nexp\nexact\nfixed\n1000\n‚úÖ Pass\n\n\nexp_exact_nocov\nexp\nexact\nnocov\n1000\n‚úÖ Pass\n\n\nexp_exact_tvc\nexp\nexact\ntvc\n1000\n‚ùå Fail\n\n\nexp_panel_fixed\nexp\npanel\nfixed\n986\n‚úÖ Pass\n\n\nexp_panel_nocov\nexp\npanel\nnocov\n990\n‚úÖ Pass\n\n\ngom_exact_fixed\ngom\nexact\nfixed\n1000\n‚úÖ Pass\n\n\ngom_exact_nocov\ngom\nexact\nnocov\n1000\n‚úÖ Pass\n\n\ngom_exact_tvc\ngom\nexact\ntvc\n1000\n‚ùå Fail\n\n\ngom_mcem_fixed\ngom\nmcem\nfixed\n838\n‚ùå Fail\n\n\ngom_mcem_nocov\ngom\nmcem\nnocov\n903\n‚ùå Fail\n\n\nwei_exact_fixed\nwei\nexact\nfixed\n1000\n‚úÖ Pass\n\n\nwei_exact_nocov\nwei\nexact\nnocov\n1000\n‚úÖ Pass\n\n\nwei_exact_tvc\nwei\nexact\ntvc\n1000\n‚ùå Fail\n\n\nwei_mcem_fixed\nwei\nmcem\nfixed\n1000\n‚ùå Fail\n\n\nwei_mcem_nocov\nwei\nmcem\nnocov\n1000\n‚ùå Fail"
  },
  {
    "objectID": "long_tests.html#test-results-by-family",
    "href": "long_tests.html#test-results-by-family",
    "title": "Long Test Status",
    "section": "Test Results by Family",
    "text": "Test Results by Family\n\nExponential\n\nExponential - Exact Data - Fixed Covariates\nTest: exp_exact_fixed | N: 1000 | Run: 2025-12-21T08:36:37.698 on penalized_splines (b1144da)\n\n\nExponential - Exact Data - No Covariates\nTest: exp_exact_nocov | N: 1000 | Run: 2025-12-21T08:36:34.444 on penalized_splines (b1144da)\n\n\nExponential - Exact Data - Time-Varying Covariates\nTest: exp_exact_tvc | N: 1000 | Run: 2025-12-20T20:17:58.964 on penalized_splines (b1144da)\n\n\nExponential - Panel Data (Markov) - Fixed Covariates\nTest: exp_panel_fixed | N: 986 | Run: 2025-12-21T08:38:41.967 on penalized_splines (b1144da)\n\n\nExponential - Panel Data (Markov) - No Covariates\nTest: exp_panel_nocov | N: 990 | Run: 2025-12-21T08:38:31.240 on penalized_splines (b1144da)\n\n\n\nWeibull\n\nWeibull - Exact Data - Fixed Covariates\nTest: wei_exact_fixed | N: 1000 | Run: 2025-12-21T08:37:16.632 on penalized_splines (b1144da)\n\n\nWeibull - Exact Data - No Covariates\nTest: wei_exact_nocov | N: 1000 | Run: 2025-12-21T08:36:54.585 on penalized_splines (b1144da)\n\n\nWeibull - Exact Data - Time-Varying Covariates\nTest: wei_exact_tvc | N: 1000 | Run: 2025-12-20T20:04:42.887 on penalized_splines (b1144da)\n\n\nWeibull - Panel Data (MCEM) - Fixed Covariates\nTest: wei_mcem_fixed | N: 1000 | Run: 2025-12-20T23:00:34.199 on penalized_splines (b1144da)\n\n\nWeibull - Panel Data (MCEM) - No Covariates\nTest: wei_mcem_nocov | N: 1000 | Run: 2025-12-20T22:46:39.341 on penalized_splines (b1144da)\n\n\n\nGompertz\n\nGompertz - Exact Data - Fixed Covariates\nTest: gom_exact_fixed | N: 1000 | Run: 2025-12-21T08:38:20.310 on penalized_splines (b1144da)\n\n\nGompertz - Exact Data - No Covariates\nTest: gom_exact_nocov | N: 1000 | Run: 2025-12-21T08:37:32.462 on penalized_splines (b1144da)\n\n\nGompertz - Exact Data - Time-Varying Covariates\nTest: gom_exact_tvc | N: 1000 | Run: 2025-12-20T20:06:47.320 on penalized_splines (b1144da)\n\n\nGompertz - Panel Data (MCEM) - Fixed Covariates\nTest: gom_mcem_fixed | N: 838 | Run: 2025-12-20T23:02:59.276 on penalized_splines (b1144da)\n\n\nGompertz - Panel Data (MCEM) - No Covariates\nTest: gom_mcem_nocov | N: 903 | Run: 2025-12-20T23:01:08.536 on penalized_splines (b1144da)\n\n\n\n---\n\n### Exact data MLE: exp_nocov - Details\n\n\n**Parameter Recovery:**\n\n\n\n2√ó8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nh12_log_rate\n-1.38629\n-1.45202\n0.031734\n-1.51422\n-1.38982\n4.74089\n‚úó\n\n\n2\nh23_log_rate\n-1.89712\n-1.91894\n0.0336909\n-1.98498\n-1.85291\n1.15023\n‚úì\n\n\n\n\n\n\n\n---\n\n### Exact data MLE: gom_nocov - Details\n\n\n**Parameter Recovery:**\n\n\n\n4√ó8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nh12_log_rate\n-2.30259\n-2.28414\n0.0375181\n-2.35768\n-2.21061\n0.801037\n‚úì\n\n\n2\nh12_shape\n0.08\n0.073476\n0.00466369\n0.0643352\n0.0826169\n8.15494\n‚úì\n\n\n3\nh23_log_rate\n-2.52573\n-2.53441\n0.0392335\n-2.61131\n-2.45751\n0.343758\n‚úì\n\n\n4\nh23_shape\n0.06\n0.061281\n0.00414755\n0.0531518\n0.0694102\n2.135\n‚úì\n\n\n\n\n\n\n\n---\n\n### Exact data MLE: wei_nocov - Details\n\n\n**Parameter Recovery:**\n\n\n\n4√ó8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nh12_log_scale\n-1.60944\n-1.60922\n0.0590221\n-1.72491\n-1.49354\n0.0133309\n‚úì\n\n\n2\nh12_log_shape\n0.262364\n0.273965\n0.0244188\n0.226104\n0.321825\n4.42145\n‚úì\n\n\n3\nh23_log_scale\n-1.89712\n-1.87974\n0.0678816\n-2.01278\n-1.74669\n0.916285\n‚úì\n\n\n4\nh23_log_shape\n-0.105361\n-0.105892\n0.0289413\n-0.162617\n-0.0491667\n0.50412\n‚úì\n\n\n\n\n\n\n\n---\n\n### Exponential - Exact Data - Fixed Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n4√ó8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nh12_beta\n0.5\n0.526746\n0.065457\n0.39845\n0.655041\n5.34913\n‚úì\n\n\n2\nh12_log_rate\n-1.89712\n-1.88978\n0.0457869\n-1.97952\n-1.80004\n0.386995\n‚úì\n\n\n3\nh23_beta\n0.5\n0.479096\n0.0753465\n0.331417\n0.626775\n4.18081\n‚úì\n\n\n4\nh23_log_rate\n-2.12026\n-2.06702\n0.0555556\n-2.1759\n-1.95813\n2.51137\n‚úì\n\n\n\n\n\n\n\n---\n\n### Exponential - Exact Data - No Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n2√ó8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nh12_log_rate\n-1.89712\n-1.84645\n0.0332045\n-1.91154\n-1.78137\n2.67065\n‚úì\n\n\n2\nh23_log_rate\n-2.12026\n-2.09038\n0.0403567\n-2.16948\n-2.01128\n1.40959\n‚úì\n\n\n\n\n\n\n\n---\n\n### Exponential - Exact Data - Time-Varying Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n4√ó8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nh12_beta\n0.5\n0.0\n0.0\n0.0\n0.0\n100.0\n‚úó\n\n\n2\nh12_log_rate\n-1.89712\n-1.84645\n0.0332045\n-1.91154\n-1.78137\n2.67065\n‚úì\n\n\n3\nh23_beta\n0.5\n0.0\n0.0\n0.0\n0.0\n100.0\n‚úó\n\n\n4\nh23_log_rate\n-2.12026\n-2.09038\n0.0403567\n-2.16948\n-2.01128\n1.40959\n‚úì\n\n\n\n\n\n\n\n---\n\n### Exponential - Panel Data (Markov) - Fixed Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n4√ó8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nh12_beta\n0.5\n0.532568\n0.0771887\n0.381278\n0.683858\n6.51366\n‚úì\n\n\n2\nh12_log_rate\n-1.89712\n-1.85012\n0.0546095\n-1.95716\n-1.74309\n2.47726\n‚úì\n\n\n3\nh23_beta\n0.5\n0.45703\n0.0898408\n0.280942\n0.633118\n8.59399\n‚úì\n\n\n4\nh23_log_rate\n-2.12026\n-2.0921\n0.0696143\n-2.22855\n-1.95566\n1.32826\n‚úì\n\n\n\n\n\n\n\n---\n\n### Exponential - Panel Data (Markov) - No Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n2√ó8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nh12_log_rate\n-1.89712\n-1.87335\n0.0394745\n-1.95072\n-1.79598\n1.25309\n‚úì\n\n\n2\nh23_log_rate\n-2.12026\n-2.09382\n0.0503324\n-2.19247\n-1.99517\n1.24721\n‚úì\n\n\n\n\n\n\n\n---\n\n### Gompertz - Exact Data - Fixed Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n6√ó8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nh12_beta\n0.5\n0.584861\n0.0902646\n0.407942\n0.76178\n16.9722\n‚úì\n\n\n2\nh12_log_rate\n-1.89712\n-1.88435\n0.092737\n-2.06612\n-1.70259\n0.673068\n‚úì\n\n\n3\nh12_shape\n0.05\n0.00603061\n0.0820083\n-0.154706\n0.166767\n87.9388\n‚úì\n\n\n4\nh23_beta\n0.5\n0.556102\n0.134977\n0.291547\n0.820656\n11.2203\n‚úì\n\n\n5\nh23_log_rate\n-2.12026\n-2.18194\n0.151832\n-2.47953\n-1.88434\n2.90869\n‚úì\n\n\n6\nh23_shape\n0.03\n0.0663068\n0.127546\n-0.183683\n0.316297\n121.023\n‚úì\n\n\n\n\n\n\n\n---\n\n### Gompertz - Exact Data - No Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n4√ó8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nh12_log_rate\n-1.89712\n-1.80132\n0.0936246\n-1.98483\n-1.61782\n5.0495\n‚úì\n\n\n2\nh12_shape\n0.05\n0.0186752\n0.065939\n-0.110565\n0.147916\n62.6495\n‚úì\n\n\n3\nh23_log_rate\n-2.12026\n-2.08191\n0.172197\n-2.41942\n-1.74441\n1.80871\n‚úì\n\n\n4\nh23_shape\n0.03\n0.0185745\n0.106198\n-0.189574\n0.226723\n38.0851\n‚úì\n\n\n\n\n\n\n\n---\n\n### Gompertz - Exact Data - Time-Varying Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n6√ó8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nh12_beta\n0.5\n0.0\n0.0\n0.0\n0.0\n100.0\n‚úó\n\n\n2\nh12_log_rate\n-1.89712\n-1.80132\n0.0936246\n-1.98483\n-1.61782\n5.0495\n‚úì\n\n\n3\nh12_shape\n0.05\n0.0186752\n0.065939\n-0.110565\n0.147916\n62.6495\n‚úì\n\n\n4\nh23_beta\n0.5\n0.0\n0.0\n0.0\n0.0\n100.0\n‚úó\n\n\n5\nh23_log_rate\n-2.12026\n-2.08191\n0.172197\n-2.41942\n-1.74441\n1.80871\n‚úì\n\n\n6\nh23_shape\n0.03\n0.0185745\n0.106198\n-0.189574\n0.226723\n38.0851\n‚úì\n\n\n\n\n\n\n\n---\n\n### Gompertz - Panel Data (MCEM) - Fixed Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n6√ó8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nh12_beta\n0.5\n-0.0471565\n0.344318\n-0.72202\n0.627707\n109.431\n‚úì\n\n\n2\nh12_log_rate\n-1.89712\n0.737091\n0.692153\n-0.61953\n2.09371\n138.853\n‚úó\n\n\n3\nh12_shape\n0.05\n0.326248\n0.496625\n-0.647137\n1.29963\n552.496\n‚úì\n\n\n4\nh23_beta\n0.5\n0.0723904\n0.309514\n-0.534258\n0.679039\n85.5219\n‚úì\n\n\n5\nh23_log_rate\n-2.12026\n0.503514\n0.380604\n-0.242469\n1.2495\n123.748\n‚úó\n\n\n6\nh23_shape\n0.03\n0.209498\n0.387744\n-0.550481\n0.969477\n598.328\n‚úì\n\n\n\n\n\n\n\n---\n\n### Gompertz - Panel Data (MCEM) - No Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n4√ó8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nh12_log_rate\n-1.89712\n0.114879\n0.342961\n-0.557325\n0.787084\n106.055\n‚úó\n\n\n2\nh12_shape\n0.05\n0.499918\n0.279923\n-0.0487301\n1.04857\n899.837\n‚úì\n\n\n3\nh23_log_rate\n-2.12026\n-0.220047\n0.267144\n-0.743649\n0.303556\n89.6217\n‚úó\n\n\n4\nh23_shape\n0.03\n0.793044\n0.231301\n0.339695\n1.24639\n2543.48\n‚úó\n\n\n\n\n\n\n\n---\n\n### Weibull - Exact Data - Fixed Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n6√ó8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nh12_beta\n0.5\n0.440567\n0.0644436\n0.314258\n0.566876\n11.8866\n‚úì\n\n\n2\nh12_log_scale\n1.45932\n1.46481\n0.0246363\n1.41653\n1.5131\n0.376213\n‚úì\n\n\n3\nh12_log_shape\n0.262364\n0.317475\n0.0443599\n0.230529\n0.40442\n21.0053\n‚úì\n\n\n4\nh23_beta\n0.5\n0.43163\n0.0642007\n0.305796\n0.557463\n13.6741\n‚úì\n\n\n5\nh23_log_scale\n2.65033\n2.62185\n0.0244304\n2.57397\n2.66974\n1.07441\n‚úì\n\n\n6\nh23_log_shape\n-0.223144\n-0.160085\n0.0465926\n-0.251407\n-0.0687636\n28.2591\n‚úì\n\n\n\n\n\n\n\n---\n\n### Weibull - Exact Data - No Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n4√ó8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nh12_log_scale\n1.45932\n1.46478\n0.0246503\n1.41646\n1.51309\n0.373686\n‚úì\n\n\n2\nh12_log_shape\n0.262364\n0.286588\n0.0317991\n0.224261\n0.348914\n9.23273\n‚úì\n\n\n3\nh23_log_scale\n2.65033\n2.62155\n0.0244354\n2.57365\n2.66944\n1.08602\n‚úì\n\n\n4\nh23_log_shape\n-0.223144\n-0.186833\n0.0350368\n-0.255505\n-0.118161\n16.2722\n‚úì\n\n\n\n\n\n\n\n---\n\n### Weibull - Exact Data - Time-Varying Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n6√ó8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nh12_beta\n0.5\n0.0\n0.0\n0.0\n0.0\n100.0\n‚úó\n\n\n2\nh12_log_scale\n1.45932\n1.46478\n0.0246503\n1.41646\n1.51309\n0.373686\n‚úì\n\n\n3\nh12_log_shape\n0.262364\n0.286588\n0.0317991\n0.224261\n0.348914\n9.23273\n‚úì\n\n\n4\nh23_beta\n0.5\n0.0\n0.0\n0.0\n0.0\n100.0\n‚úó\n\n\n5\nh23_log_scale\n2.65033\n2.62155\n0.0244354\n2.57365\n2.66944\n1.08602\n‚úì\n\n\n6\nh23_log_shape\n-0.223144\n-0.186833\n0.0350368\n-0.255505\n-0.118161\n16.2722\n‚úì\n\n\n\n\n\n\n\n---\n\n### Weibull - Panel Data (MCEM) - Fixed Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n6√ó8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nh12_beta\n0.5\n0.8345\n0.687274\n-0.512557\n2.18156\n66.8999\n‚úì\n\n\n2\nh12_log_scale\n1.45932\n2.00901\n0.558313\n0.91472\n3.10331\n37.6675\n‚úì\n\n\n3\nh12_log_shape\n0.262364\n2.16521\n0.750666\n0.693901\n3.63651\n725.268\n‚úó\n\n\n4\nh23_beta\n0.5\n0.399131\n0.131722\n0.140956\n0.657306\n20.1738\n‚úì\n\n\n5\nh23_log_scale\n2.65033\n0.729106\n0.29099\n0.158765\n1.29945\n72.49\n‚úó\n\n\n6\nh23_log_shape\n-0.223144\n1.16784\n0.076834\n1.01724\n1.31843\n623.357\n‚úó\n\n\n\n\n\n\n\n---\n\n### Weibull - Panel Data (MCEM) - No Covariates - Details\n\n\n**Parameter Recovery:**\n\n\n\n4√ó8 DataFrame\n\n\n\nRow\nParameter\nTrue\nEstimated\nSE\nCI_Lower\nCI_Upper\nRelError_pct\nCovered\n\n\n\nString\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nFloat64\nString\n\n\n\n\n1\nh12_log_scale\n1.45932\n2.23495\nNaN\nNaN\nNaN\n53.1495\n?\n\n\n2\nh12_log_shape\n0.262364\n3.13744\nNaN\nNaN\nNaN\n1095.83\n?\n\n\n3\nh23_log_scale\n2.65033\n0.912191\nNaN\nNaN\nNaN\n65.582\n?\n\n\n4\nh23_log_shape\n-0.223144\n1.09493\nNaN\nNaN\nNaN\n590.683\n?\n\n\n\n\n\n\n\n\n\n**State Prevalence: Exact data MLE: exp_nocov**\n\nRed = true model, Blue = fitted model\n\n\n\n\n\n\n\n\n\n\n\n**State Prevalence: Exact data MLE: gom_nocov**\n\nRed = true model, Blue = fitted model\n\n\n\n\n\n\n\n\n\n\n\n**State Prevalence: Exact data MLE: wei_nocov**\n\nRed = true model, Blue = fitted model\n\n\n\n\n\n\n\n\n\n\n\n**State Prevalence: Exponential - Exact Data - Fixed Covariates**\n\nRed = true model, Blue = fitted model\n\n\n\n\n\n\n\n\n\n\n\n**State Prevalence: Exponential - Exact Data - No Covariates**\n\nRed = true model, Blue = fitted model\n\n\n\n\n\n\n\n\n\n\n\n**State Prevalence: Exponential - Exact Data - Time-Varying Covariates**\n\nRed = true model, Blue = fitted model\n\n\n\n\n\n\n\n\n\n\n\n**State Prevalence: Exponential - Panel Data (Markov) - Fixed Covariates**\n\nRed = true model, Blue = fitted model\n\n\n\n\n\n\n\n\n\n\n\n**State Prevalence: Exponential - Panel Data (Markov) - No Covariates**\n\nRed = true model, Blue = fitted model\n\n\n\n\n\n\n\n\n\n\n\n**State Prevalence: Gompertz - Exact Data - Fixed Covariates**\n\nRed = true model, Blue = fitted model\n\n\n\n\n\n\n\n\n\n\n\n**State Prevalence: Gompertz - Exact Data - No Covariates**\n\nRed = true model, Blue = fitted model\n\n\n\n\n\n\n\n\n\n\n\n**State Prevalence: Gompertz - Exact Data - Time-Varying Covariates**\n\nRed = true model, Blue = fitted model\n\n\n\n\n\n\n\n\n\n\n\n**State Prevalence: Gompertz - Panel Data (MCEM) - Fixed Covariates**\n\nRed = true model, Blue = fitted model\n\n\n\n\n\n\n\n\n\n\n\n**State Prevalence: Gompertz - Panel Data (MCEM) - No Covariates**\n\nRed = true model, Blue = fitted model\n\n\n\n\n\n\n\n\n\n\n\n**State Prevalence: Weibull - Exact Data - Fixed Covariates**\n\nRed = true model, Blue = fitted model\n\n\n\n\n\n\n\n\n\n\n\n**State Prevalence: Weibull - Exact Data - No Covariates**\n\nRed = true model, Blue = fitted model\n\n\n\n\n\n\n\n\n\n\n\n**State Prevalence: Weibull - Exact Data - Time-Varying Covariates**\n\nRed = true model, Blue = fitted model\n\n\n\n\n\n\n\n\n\n\n\n**State Prevalence: Weibull - Panel Data (MCEM) - Fixed Covariates**\n\nRed = true model, Blue = fitted model\n\n\n\n\n\n\n\n\n\n\n\n**State Prevalence: Weibull - Panel Data (MCEM) - No Covariates**\n\nRed = true model, Blue = fitted model\n\n\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Exact data MLE: exp_nocov**\n\nTransitions 1‚Üí2 and 2‚Üí3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Exact data MLE: gom_nocov**\n\nTransitions 1‚Üí2 and 2‚Üí3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Exact data MLE: wei_nocov**\n\nTransitions 1‚Üí2 and 2‚Üí3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Exponential - Exact Data - Fixed Covariates**\n\nTransitions 1‚Üí2 and 2‚Üí3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Exponential - Exact Data - No Covariates**\n\nTransitions 1‚Üí2 and 2‚Üí3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Exponential - Exact Data - Time-Varying Covariates**\n\nTransitions 1‚Üí2 and 2‚Üí3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Exponential - Panel Data (Markov) - Fixed Covariates**\n\nTransitions 1‚Üí2 and 2‚Üí3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Exponential - Panel Data (Markov) - No Covariates**\n\nTransitions 1‚Üí2 and 2‚Üí3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Gompertz - Exact Data - Fixed Covariates**\n\nTransitions 1‚Üí2 and 2‚Üí3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Gompertz - Exact Data - No Covariates**\n\nTransitions 1‚Üí2 and 2‚Üí3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Gompertz - Exact Data - Time-Varying Covariates**\n\nTransitions 1‚Üí2 and 2‚Üí3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Gompertz - Panel Data (MCEM) - Fixed Covariates**\n\nTransitions 1‚Üí2 and 2‚Üí3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Gompertz - Panel Data (MCEM) - No Covariates**\n\nTransitions 1‚Üí2 and 2‚Üí3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Weibull - Exact Data - Fixed Covariates**\n\nTransitions 1‚Üí2 and 2‚Üí3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Weibull - Exact Data - No Covariates**\n\nTransitions 1‚Üí2 and 2‚Üí3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Weibull - Exact Data - Time-Varying Covariates**\n\nTransitions 1‚Üí2 and 2‚Üí3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Weibull - Panel Data (MCEM) - Fixed Covariates**\n\nTransitions 1‚Üí2 and 2‚Üí3 only (progressive model)\n\n\n\n\n\n\n\n\n\n\n\n**Cumulative Incidence: Weibull - Panel Data (MCEM) - No Covariates**\n\nTransitions 1‚Üí2 and 2‚Üí3 only (progressive model)"
  },
  {
    "objectID": "long_tests.html#running-long-tests",
    "href": "long_tests.html#running-long-tests",
    "title": "Long Test Status",
    "section": "Running Long Tests",
    "text": "Running Long Tests\n\nFull Suite\ncd MultistateModelsTests\n\n# Via the test package API\nMSM_TEST_LEVEL=full julia --project=. -e 'using MultistateModelsTests; MultistateModelsTests.runtests()'\n\n# Or via the dedicated script\njulia --project=. scripts/run_longtests.jl\n\n\nIndividual Test Suite\n# Run only a specific suite (by key name)\nMSM_TEST_LEVEL=full MSM_LONGTEST_ONLY=parametric_suite julia --project=. -e 'using MultistateModelsTests; MultistateModelsTests.runtests()'\n\n\nAvailable Test Suites\n\n\n\n\n\n\n\nKey\nDescription\n\n\n\n\nparametric_suite\nParametric families (exp/wei/gom) √ó data types √ó covariates\n\n\nexact_data\nExact observation direct MLE\n\n\nmcem_parametric\nPanel data with parametric hazards\n\n\nmcem_splines\nPanel data with spline hazards\n\n\nphasetype\nPhase-type hazard models\n\n\nvariance_validation\nVariance estimation validation\n\n\n\n\n\nEnvironment Variables\n\n\n\n\n\n\n\n\nVariable\nValues\nDescription\n\n\n\n\nMSM_TEST_LEVEL\nquick (default), full\nControls whether long tests run\n\n\nMSM_LONGTEST_ONLY\ntest key\nRun only one specific long test suite\n\n\nMSM_SUPPRESS_WARNINGS\ntrue (default), false\nSuppress expected warnings"
  },
  {
    "objectID": "long_tests.html#troubleshooting",
    "href": "long_tests.html#troubleshooting",
    "title": "Long Test Status",
    "section": "Troubleshooting",
    "text": "Troubleshooting\n\nParameter Recovery Failures\nSymptoms: Estimated parameters far from true values\nPotential Causes: 1. Insufficient sample size: Tests use N=1000, may need more for some models 2. Poor initialization: Check initialize_parameters! settings 3. MCEM convergence: Increase iterations or tighten tolerance\n\n\nVariance Estimation Issues\nSymptoms: Coverage rates significantly below 95%\nPotential Causes: 1. Small sample bias: Need larger n 2. Boundary parameters: Transform scale may help 3. Model misspecification: Verify DGP matches fitted model"
  },
  {
    "objectID": "long_tests.html#summary-1",
    "href": "long_tests.html#summary-1",
    "title": "Long Test Status",
    "section": "Summary",
    "text": "Summary\nLong tests provide rigorous validation that MultistateModels.jl:\n\nRecovers parameters within expected tolerance (20% relative error)\nProduces valid uncertainty through variance estimation\nSimulates correctly from fitted models\nHandles all supported hazard families and observation types\n\nThe test matrix covers: - Families: Exponential, Weibull, Gompertz, Phase-Type, Spline - Data types: Exact (direct MLE), Panel (Markov/MCEM) - Covariates: None, Time-fixed, Time-varying"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MultistateModels.jl",
    "section": "",
    "text": "Branch: penalized_splines ¬† Commit: b1144da"
  },
  {
    "objectID": "index.html#overview",
    "href": "index.html#overview",
    "title": "MultistateModels.jl",
    "section": "Overview",
    "text": "Overview\nComprehensive validation and documentation for MultistateModels.jl ‚Äî a Julia package for continuous-time multistate modeling.\n\n\nüìê Architecture\nType hierarchy, hazard families, inference engine, and simulation strategies.\n\n\n‚úÖ Unit Tests\nFunction-level tests for hazards, simulation, MCEM, and model construction.\n\n\nüìä Long Tests\nStatistical recovery of parameters across hazard families and data types.\n\n\nüéØ Simulation\nVisual verification of event time distributions (CDF diagnostic plots).\n\n\n‚ö° Benchmarks\nPerformance comparison of sampling methods and optimization strategies.\n\n\nüì¶ Main Package\nSource code and documentation for MultistateModels.jl."
  },
  {
    "objectID": "index.html#test-results-summary",
    "href": "index.html#test-results-summary",
    "title": "MultistateModels.jl",
    "section": "Test Results Summary",
    "text": "Test Results Summary\n\n\n\nMetric\nValue\n\n\n\n\nPassed\n1192\n\n\nFailed\n0\n\n\nErrors\n0\n\n\nPass Rate\n100.0%\n\n\nCategories\n12\n\n\nLast Updated\n2025-12-20T08:48:07.355"
  },
  {
    "objectID": "index.html#quick-start",
    "href": "index.html#quick-start",
    "title": "MultistateModels.jl",
    "section": "Quick Start",
    "text": "Quick Start\n\nBuilding Reports Locally\ncd MultistateModelsTests/reports\nquarto render\n\n\nRunning Tests and Recording Results\n# Run full test suite with automatic cache recording\njulia --project=. -e 'using MultistateModelsTests; MultistateModelsTests.runtests()'\n\n# Or run with the dedicated script\njulia --project=. scripts/run_all_tests.jl\nTest results are automatically cached when running via runtests().\n\n\nChecking Cache Status\njulia --project=. scripts/refresh_cache.jl"
  },
  {
    "objectID": "simulation_diagnostics.html",
    "href": "simulation_diagnostics.html",
    "title": "Simulation Diagnostics",
    "section": "",
    "text": "This report validates that MultistateModels.jl correctly simulates event times by comparing:\n\nEmpirical CDFs of simulated event times against theoretical CDFs\nHazard functions computed by the package against analytical formulas\nCumulative hazard functions computed vs.¬†expected\n\nFor each hazard family (Exponential, Weibull, Gompertz) and covariate effect type (PH, AFT), we: - Simulate many event times from a 2-state model - Compare the empirical distribution to the theoretical distribution - Report the maximum absolute difference in CDF (should be ‚âà 0)"
  },
  {
    "objectID": "simulation_diagnostics.html#overview",
    "href": "simulation_diagnostics.html#overview",
    "title": "Simulation Diagnostics",
    "section": "",
    "text": "This report validates that MultistateModels.jl correctly simulates event times by comparing:\n\nEmpirical CDFs of simulated event times against theoretical CDFs\nHazard functions computed by the package against analytical formulas\nCumulative hazard functions computed vs.¬†expected\n\nFor each hazard family (Exponential, Weibull, Gompertz) and covariate effect type (PH, AFT), we: - Simulate many event times from a 2-state model - Compare the empirical distribution to the theoretical distribution - Report the maximum absolute difference in CDF (should be ‚âà 0)"
  },
  {
    "objectID": "simulation_diagnostics.html#configuration",
    "href": "simulation_diagnostics.html#configuration",
    "title": "Simulation Diagnostics",
    "section": "Configuration",
    "text": "Configuration\n\n\nShow code\nconst COVARIATE_VALUE = 1.5\nconst SIM_SAMPLES = 40_000\nconst DIST_GRID_POINTS = 400\n\n# Horizons must be large enough to ensure negligible right-truncation (&lt;0.1%)\n# For Exponential with AFT covariates: effective rate = 0.35 * exp(-0.6*1.5) ‚âà 0.14\n# Need: exp(-rate * horizon) &lt; 0.001 =&gt; horizon &gt; log(1000)/rate ‚âà 50\n# Setting horizon = 100 provides ample margin\nconst FAMILY_CONFIG = Dict(\n    \"exp\" =&gt; (; rate = 0.35, beta = 0.6, horizon = 100.0),\n    \"wei\" =&gt; (; shape = 1.35, scale = 0.4, beta = -0.35, horizon = 50.0),\n    \"gom\" =&gt; (; shape = 0.6, rate = 0.4, beta = 0.5, horizon = 10.0),  # Gompertz diverges quickly\n)\n\n\nDict{String, NamedTuple} with 3 entries:\n  \"exp\" =&gt; (rate = 0.35, beta = 0.6, horizon = 100.0)\n  \"wei\" =&gt; (shape = 1.35, scale = 0.4, beta = -0.35, horizon = 50.0)\n  \"gom\" =&gt; (shape = 0.6, rate = 0.4, beta = 0.5, horizon = 10.0)"
  },
  {
    "objectID": "simulation_diagnostics.html#analytical-reference-formulas",
    "href": "simulation_diagnostics.html#analytical-reference-formulas",
    "title": "Simulation Diagnostics",
    "section": "Analytical Reference Formulas",
    "text": "Analytical Reference Formulas\n\nExponential Distribution\n\nHazard: \\(h(t) = \\lambda\\)\nCumulative hazard: \\(H(t) = \\lambda t\\)\nCDF: \\(F(t) = 1 - e^{-\\lambda t}\\)\n\n\n\nWeibull Distribution (shape \\(\\kappa\\), scale \\(\\lambda\\))\n\nHazard: \\(h(t) = \\kappa \\lambda t^{\\kappa-1}\\)\nCumulative hazard: \\(H(t) = \\lambda t^\\kappa\\)\nCDF: \\(F(t) = 1 - e^{-\\lambda t^\\kappa}\\)\n\n\n\nGompertz Distribution (flexsurv parameterization: shape \\(a\\), rate \\(b\\))\n\nHazard: \\(h(t) = b e^{at}\\)\nCumulative hazard: \\(H(t) = \\frac{b}{a}(e^{at} - 1)\\)\nCDF: \\(F(t) = 1 - e^{-H(t)}\\)\n\n\n\nCovariate Effects\nProportional Hazards (PH): \\(h(t|x) = h_0(t) e^{\\beta x}\\)\nAccelerated Failure Time (AFT): \\(h(t|x) = h_0(t \\cdot e^{-\\beta x}) \\cdot e^{-\\beta x}\\)"
  },
  {
    "objectID": "simulation_diagnostics.html#helper-functions",
    "href": "simulation_diagnostics.html#helper-functions",
    "title": "Simulation Diagnostics",
    "section": "Helper Functions",
    "text": "Helper Functions\n\n\nShow code\n# Create a 2-state model for a given scenario\nfunction build_test_model(family::String, effect::Symbol, with_covariate::Bool)\n    cfg = FAMILY_CONFIG[family]\n    \n    # Build data frame\n    if with_covariate\n        data = DataFrame(\n            id = [1], tstart = [0.0], tstop = [cfg.horizon],\n            statefrom = [1], stateto = [2], obstype = [1],\n            x = [COVARIATE_VALUE]\n        )\n        formula = @formula(0 ~ x)\n    else\n        data = DataFrame(\n            id = [1], tstart = [0.0], tstop = [cfg.horizon],\n            statefrom = [1], stateto = [2], obstype = [1]\n        )\n        formula = @formula(0 ~ 1)\n    end\n    \n    # Build hazard\n    hazard = Hazard(formula, family, 1, 2; linpred_effect = effect)\n    model = multistatemodel(hazard; data = data)\n    \n    # Set parameters\n    if family == \"exp\"\n        base = [log(cfg.rate)]\n    elseif family == \"wei\"\n        base = [log(cfg.shape), log(cfg.scale)]\n    elseif family == \"gom\"\n        base = [cfg.shape, log(cfg.rate)]  # shape unconstrained, rate log-transformed\n    end\n    \n    pars = with_covariate ? vcat(base, [cfg.beta]) : base\n    hazname = model.hazards[1].hazname\n    set_parameters!(model, NamedTuple{(hazname,)}((pars,)))\n    \n    return model, cfg\nend\n\n# Compute expected CDF for given scenario\nfunction expected_cdf(family::String, effect::Symbol, with_covariate::Bool, t::Float64)\n    cfg = FAMILY_CONFIG[family]\n    xval = with_covariate ? COVARIATE_VALUE : 0.0\n    beta = with_covariate ? cfg.beta : 0.0\n    \n    cumhaz = if family == \"exp\"\n        rate = effect == :ph ? cfg.rate * exp(beta * xval) : cfg.rate * exp(-beta * xval)\n        rate * t\n    elseif family == \"wei\"\n        shape, scale = cfg.shape, cfg.scale\n        mult = effect == :ph ? exp(beta * xval) : exp(-shape * beta * xval)\n        scale * mult * (t^shape)\n    elseif family == \"gom\"\n        shape, rate = cfg.shape, cfg.rate\n        linpred = beta * xval\n        if effect == :ph\n            (rate / shape) * exp(linpred) * (exp(shape * t) - 1)\n        else\n            time_scale = exp(-linpred)\n            scaled_shape = shape * time_scale\n            scaled_rate = rate * time_scale\n            (scaled_rate / scaled_shape) * (exp(scaled_shape * t) - 1)\n        end\n    end\n    \n    return 1 - exp(-cumhaz)\nend\n\n# Simulate event times from model\n# WARNING: Only collects paths where a transition occurred within horizon.\n# Set horizon large enough so P(T &gt; horizon) &lt; 0.001 to avoid right-truncation bias.\nfunction simulate_event_times(model, nsim::Int; rng = Random.default_rng())\n    durations = Float64[]\n    n_censored = 0\n    strategy = CachedTransformStrategy()\n    total_attempts = 0\n    max_attempts = nsim * 20  # Safety limit\n    \n    while length(durations) &lt; nsim && total_attempts &lt; max_attempts\n        total_attempts += 1\n        path = simulate_path(model, 1; strategy = strategy, rng = rng)\n        if path.states[end] != path.states[1]\n            push!(durations, path.times[end] - path.times[1])\n        else\n            n_censored += 1\n        end\n    end\n    \n    # Warn if significant truncation detected\n    truncation_rate = n_censored / total_attempts\n    if truncation_rate &gt; 0.01\n        @warn \"High right-truncation rate: $(round(truncation_rate*100, digits=1))%. Increase horizon.\"\n    end\n    \n    return durations\nend\n\n# Compute maximum CDF difference\nfunction max_cdf_diff(durations::Vector{Float64}, cdf_func, horizon::Float64)\n    # Compute empirical CDF\n    sorted = sort(durations)\n    n = length(sorted)\n    ecdf_vals = (1:n) ./ n\n    \n    # Compute theoretical CDF at each point\n    tcdf_vals = [cdf_func(t) for t in sorted]\n    \n    # Max absolute difference\n    return maximum(abs.(ecdf_vals .- tcdf_vals))\nend\n\n\nmax_cdf_diff (generic function with 1 method)"
  },
  {
    "objectID": "simulation_diagnostics.html#diagnostic-results",
    "href": "simulation_diagnostics.html#diagnostic-results",
    "title": "Simulation Diagnostics",
    "section": "Diagnostic Results",
    "text": "Diagnostic Results\n\n\nShow code\n# Run diagnostics for all scenarios\nresults = DataFrame(\n    Family = String[],\n    Effect = String[],\n    Covariate = String[],\n    MaxCDFDiff = Float64[],\n    Status = String[]\n)\n\nscenarios = [\n    (\"exp\", :ph, false), (\"exp\", :ph, true),\n    (\"exp\", :aft, false), (\"exp\", :aft, true),\n    (\"wei\", :ph, false), (\"wei\", :ph, true),\n    (\"wei\", :aft, false), (\"wei\", :aft, true),\n    (\"gom\", :ph, false), (\"gom\", :ph, true),\n    (\"gom\", :aft, false), (\"gom\", :aft, true),\n]\n\nRandom.seed!(12345)\n\nfor (family, effect, with_cov) in scenarios\n    model, cfg = build_test_model(family, effect, with_cov)\n    \n    # Simulate event times\n    durations = simulate_event_times(model, SIM_SAMPLES)\n    \n    # Expected CDF function\n    cdf_func = t -&gt; expected_cdf(family, effect, with_cov, t)\n    \n    # Compute max difference\n    max_diff = max_cdf_diff(durations, cdf_func, cfg.horizon)\n    \n    push!(results, (\n        uppercasefirst(family),\n        uppercase(String(effect)),\n        with_cov ? \"Yes\" : \"No\",\n        round(max_diff, digits=4),\n        max_diff &lt; 0.02 ? \"‚úÖ Pass\" : \"‚ùå Fail\"\n    ))\nend\n\nresults\n\n\n\n******************************************************************************\nThis program contains Ipopt, a library for large-scale nonlinear optimization.\n Ipopt is released as open source code under the Eclipse Public License (EPL).\n         For more information visit https://github.com/coin-or/Ipopt\n******************************************************************************\n\n\n\n\n\nTable¬†1: Simulation Diagnostic Summary\n\n\n\n12√ó5 DataFrame\n\n\n\nRow\nFamily\nEffect\nCovariate\nMaxCDFDiff\nStatus\n\n\n\nString\nString\nString\nFloat64\nString\n\n\n\n\n1\nExp\nPH\nNo\n0.0042\n‚úÖ Pass\n\n\n2\nExp\nPH\nYes\n0.0034\n‚úÖ Pass\n\n\n3\nExp\nAFT\nNo\n0.0039\n‚úÖ Pass\n\n\n4\nExp\nAFT\nYes\n0.0042\n‚úÖ Pass\n\n\n5\nWei\nPH\nNo\n0.0063\n‚úÖ Pass\n\n\n6\nWei\nPH\nYes\n0.0035\n‚úÖ Pass\n\n\n7\nWei\nAFT\nNo\n0.0063\n‚úÖ Pass\n\n\n8\nWei\nAFT\nYes\n0.0031\n‚úÖ Pass\n\n\n9\nGom\nPH\nNo\n0.0088\n‚úÖ Pass\n\n\n10\nGom\nPH\nYes\n0.0045\n‚úÖ Pass\n\n\n11\nGom\nAFT\nNo\n0.0054\n‚úÖ Pass\n\n\n12\nGom\nAFT\nYes\n0.0046\n‚úÖ Pass"
  },
  {
    "objectID": "simulation_diagnostics.html#diagnostic-plots",
    "href": "simulation_diagnostics.html#diagnostic-plots",
    "title": "Simulation Diagnostics",
    "section": "Diagnostic Plots",
    "text": "Diagnostic Plots\n\nExponential Distribution\n\n\nShow code\nfig = Figure(size=(900, 700))\n\nRandom.seed!(11111)\n\n# Baseline PH\nmodel_exp_base, cfg_exp = build_test_model(\"exp\", :ph, false)\ndurations_exp_base = simulate_event_times(model_exp_base, SIM_SAMPLES)\n\nax1 = Axis(fig[1, 1], xlabel=\"Time\", ylabel=\"CDF\", title=\"Exp PH Baseline\")\nt_grid = range(0, cfg_exp.horizon, length=DIST_GRID_POINTS)\necdf_exp = ecdf(durations_exp_base)\nlines!(ax1, t_grid, [ecdf_exp(t) for t in t_grid], label=\"Empirical\", linewidth=2)\nlines!(ax1, t_grid, [expected_cdf(\"exp\", :ph, false, t) for t in t_grid], \n       label=\"Theoretical\", linestyle=:dash, linewidth=2, color=:red)\naxislegend(ax1, position=:rb)\n\n# With covariate PH\nmodel_exp_cov, _ = build_test_model(\"exp\", :ph, true)\ndurations_exp_cov = simulate_event_times(model_exp_cov, SIM_SAMPLES)\n\nax2 = Axis(fig[1, 2], xlabel=\"Time\", ylabel=\"CDF\", title=\"Exp PH with Covariate\")\necdf_exp_cov = ecdf(durations_exp_cov)\nlines!(ax2, t_grid, [ecdf_exp_cov(t) for t in t_grid], label=\"Empirical\", linewidth=2)\nlines!(ax2, t_grid, [expected_cdf(\"exp\", :ph, true, t) for t in t_grid], \n       label=\"Theoretical\", linestyle=:dash, linewidth=2, color=:red)\naxislegend(ax2, position=:rb)\n\n# AFT baseline\nmodel_exp_aft, _ = build_test_model(\"exp\", :aft, false)\ndurations_exp_aft = simulate_event_times(model_exp_aft, SIM_SAMPLES)\n\nax3 = Axis(fig[2, 1], xlabel=\"Time\", ylabel=\"CDF\", title=\"Exp AFT Baseline\")\necdf_exp_aft = ecdf(durations_exp_aft)\nlines!(ax3, t_grid, [ecdf_exp_aft(t) for t in t_grid], label=\"Empirical\", linewidth=2)\nlines!(ax3, t_grid, [expected_cdf(\"exp\", :aft, false, t) for t in t_grid], \n       label=\"Theoretical\", linestyle=:dash, linewidth=2, color=:red)\naxislegend(ax3, position=:rb)\n\n# AFT with covariate\nmodel_exp_aft_cov, _ = build_test_model(\"exp\", :aft, true)\ndurations_exp_aft_cov = simulate_event_times(model_exp_aft_cov, SIM_SAMPLES)\n\nax4 = Axis(fig[2, 2], xlabel=\"Time\", ylabel=\"CDF\", title=\"Exp AFT with Covariate\")\necdf_exp_aft_cov = ecdf(durations_exp_aft_cov)\nlines!(ax4, t_grid, [ecdf_exp_aft_cov(t) for t in t_grid], label=\"Empirical\", linewidth=2)\nlines!(ax4, t_grid, [expected_cdf(\"exp\", :aft, true, t) for t in t_grid], \n       label=\"Theoretical\", linestyle=:dash, linewidth=2, color=:red)\naxislegend(ax4, position=:rb)\n\nfig\n\n\n\n\n\n\n\n\nFigure¬†1: Exponential Hazard Diagnostics\n\n\n\n\n\n\n\nWeibull Distribution\n\n\nShow code\nfig = Figure(size=(900, 700))\n\nRandom.seed!(22222)\ncfg_wei = FAMILY_CONFIG[\"wei\"]\nt_grid_wei = range(0.02, cfg_wei.horizon, length=DIST_GRID_POINTS)  # Start &gt; 0 for Weibull\n\n# Baseline PH\nmodel_wei_base, _ = build_test_model(\"wei\", :ph, false)\ndurations_wei_base = simulate_event_times(model_wei_base, SIM_SAMPLES)\n\nax1 = Axis(fig[1, 1], xlabel=\"Time\", ylabel=\"CDF\", title=\"Weibull PH Baseline\")\necdf_wei = ecdf(durations_wei_base)\nlines!(ax1, t_grid_wei, [ecdf_wei(t) for t in t_grid_wei], label=\"Empirical\", linewidth=2)\nlines!(ax1, t_grid_wei, [expected_cdf(\"wei\", :ph, false, t) for t in t_grid_wei], \n       label=\"Theoretical\", linestyle=:dash, linewidth=2, color=:red)\naxislegend(ax1, position=:rb)\n\n# With covariate PH\nmodel_wei_cov, _ = build_test_model(\"wei\", :ph, true)\ndurations_wei_cov = simulate_event_times(model_wei_cov, SIM_SAMPLES)\n\nax2 = Axis(fig[1, 2], xlabel=\"Time\", ylabel=\"CDF\", title=\"Weibull PH with Covariate\")\necdf_wei_cov = ecdf(durations_wei_cov)\nlines!(ax2, t_grid_wei, [ecdf_wei_cov(t) for t in t_grid_wei], label=\"Empirical\", linewidth=2)\nlines!(ax2, t_grid_wei, [expected_cdf(\"wei\", :ph, true, t) for t in t_grid_wei], \n       label=\"Theoretical\", linestyle=:dash, linewidth=2, color=:red)\naxislegend(ax2, position=:rb)\n\n# AFT baseline\nmodel_wei_aft, _ = build_test_model(\"wei\", :aft, false)\ndurations_wei_aft = simulate_event_times(model_wei_aft, SIM_SAMPLES)\n\nax3 = Axis(fig[2, 1], xlabel=\"Time\", ylabel=\"CDF\", title=\"Weibull AFT Baseline\")\necdf_wei_aft = ecdf(durations_wei_aft)\nlines!(ax3, t_grid_wei, [ecdf_wei_aft(t) for t in t_grid_wei], label=\"Empirical\", linewidth=2)\nlines!(ax3, t_grid_wei, [expected_cdf(\"wei\", :aft, false, t) for t in t_grid_wei], \n       label=\"Theoretical\", linestyle=:dash, linewidth=2, color=:red)\naxislegend(ax3, position=:rb)\n\n# AFT with covariate\nmodel_wei_aft_cov, _ = build_test_model(\"wei\", :aft, true)\ndurations_wei_aft_cov = simulate_event_times(model_wei_aft_cov, SIM_SAMPLES)\n\nax4 = Axis(fig[2, 2], xlabel=\"Time\", ylabel=\"CDF\", title=\"Weibull AFT with Covariate\")\necdf_wei_aft_cov = ecdf(durations_wei_aft_cov)\nlines!(ax4, t_grid_wei, [ecdf_wei_aft_cov(t) for t in t_grid_wei], label=\"Empirical\", linewidth=2)\nlines!(ax4, t_grid_wei, [expected_cdf(\"wei\", :aft, true, t) for t in t_grid_wei], \n       label=\"Theoretical\", linestyle=:dash, linewidth=2, color=:red)\naxislegend(ax4, position=:rb)\n\nfig\n\n\n\n\n\n\n\n\nFigure¬†2: Weibull Hazard Diagnostics\n\n\n\n\n\n\n\nGompertz Distribution\n\n\nShow code\nfig = Figure(size=(900, 700))\n\nRandom.seed!(33333)\ncfg_gom = FAMILY_CONFIG[\"gom\"]\nt_grid_gom = range(0, cfg_gom.horizon, length=DIST_GRID_POINTS)\n\n# Baseline PH\nmodel_gom_base, _ = build_test_model(\"gom\", :ph, false)\ndurations_gom_base = simulate_event_times(model_gom_base, SIM_SAMPLES)\n\nax1 = Axis(fig[1, 1], xlabel=\"Time\", ylabel=\"CDF\", title=\"Gompertz PH Baseline\")\necdf_gom = ecdf(durations_gom_base)\nlines!(ax1, t_grid_gom, [ecdf_gom(t) for t in t_grid_gom], label=\"Empirical\", linewidth=2)\nlines!(ax1, t_grid_gom, [expected_cdf(\"gom\", :ph, false, t) for t in t_grid_gom], \n       label=\"Theoretical\", linestyle=:dash, linewidth=2, color=:red)\naxislegend(ax1, position=:rb)\n\n# With covariate PH\nmodel_gom_cov, _ = build_test_model(\"gom\", :ph, true)\ndurations_gom_cov = simulate_event_times(model_gom_cov, SIM_SAMPLES)\n\nax2 = Axis(fig[1, 2], xlabel=\"Time\", ylabel=\"CDF\", title=\"Gompertz PH with Covariate\")\necdf_gom_cov = ecdf(durations_gom_cov)\nlines!(ax2, t_grid_gom, [ecdf_gom_cov(t) for t in t_grid_gom], label=\"Empirical\", linewidth=2)\nlines!(ax2, t_grid_gom, [expected_cdf(\"gom\", :ph, true, t) for t in t_grid_gom], \n       label=\"Theoretical\", linestyle=:dash, linewidth=2, color=:red)\naxislegend(ax2, position=:rb)\n\n# AFT baseline\nmodel_gom_aft, _ = build_test_model(\"gom\", :aft, false)\ndurations_gom_aft = simulate_event_times(model_gom_aft, SIM_SAMPLES)\n\nax3 = Axis(fig[2, 1], xlabel=\"Time\", ylabel=\"CDF\", title=\"Gompertz AFT Baseline\")\necdf_gom_aft = ecdf(durations_gom_aft)\nlines!(ax3, t_grid_gom, [ecdf_gom_aft(t) for t in t_grid_gom], label=\"Empirical\", linewidth=2)\nlines!(ax3, t_grid_gom, [expected_cdf(\"gom\", :aft, false, t) for t in t_grid_gom], \n       label=\"Theoretical\", linestyle=:dash, linewidth=2, color=:red)\naxislegend(ax3, position=:rb)\n\n# AFT with covariate\nmodel_gom_aft_cov, _ = build_test_model(\"gom\", :aft, true)\ndurations_gom_aft_cov = simulate_event_times(model_gom_aft_cov, SIM_SAMPLES)\n\nax4 = Axis(fig[2, 2], xlabel=\"Time\", ylabel=\"CDF\", title=\"Gompertz AFT with Covariate\")\necdf_gom_aft_cov = ecdf(durations_gom_aft_cov)\nlines!(ax4, t_grid_gom, [ecdf_gom_aft_cov(t) for t in t_grid_gom], label=\"Empirical\", linewidth=2)\nlines!(ax4, t_grid_gom, [expected_cdf(\"gom\", :aft, true, t) for t in t_grid_gom], \n       label=\"Theoretical\", linestyle=:dash, linewidth=2, color=:red)\naxislegend(ax4, position=:rb)\n\nfig\n\n\n\n\n\n\n\n\nFigure¬†3: Gompertz Hazard Diagnostics"
  },
  {
    "objectID": "simulation_diagnostics.html#hazard-function-verification",
    "href": "simulation_diagnostics.html#hazard-function-verification",
    "title": "Simulation Diagnostics",
    "section": "Hazard Function Verification",
    "text": "Hazard Function Verification\nThe CDF plots above implicitly verify hazard function correctness - if the hazard functions were wrong, the simulated CDFs would not match the theoretical CDFs.\nFor explicit verification, the hazard functions use the following formulas:\n\n\n\nFamily\nHazard \\(h(t)\\)\nImplementation\n\n\n\n\nExponential\n\\(\\lambda\\)\nrate\n\n\nWeibull\n\\(a \\cdot b \\cdot t^{a-1}\\)\nshape * scale * t^(shape-1)\n\n\nGompertz\n\\(b \\cdot e^{at}\\)\nrate * exp(shape * t)\n\n\n\nWhere shape and scale (or rate) are the distribution parameters. The Gompertz uses the flexsurv parameterization."
  },
  {
    "objectID": "simulation_diagnostics.html#summary",
    "href": "simulation_diagnostics.html#summary",
    "title": "Simulation Diagnostics",
    "section": "Summary",
    "text": "Summary\nAll simulation diagnostics pass:\n\nExponential: PH and AFT baseline and with covariates ‚úÖ\nWeibull: PH and AFT baseline and with covariates ‚úÖ\nGompertz: PH and AFT baseline and with covariates ‚úÖ\n\nThe maximum CDF differences are all essentially zero (within Monte Carlo error), confirming that:\n\nEvent time simulation is statistically correct\nHazard functions are implemented correctly\nCovariate effects (PH and AFT) work as expected\nThe flexsurv Gompertz parameterization is correctly implemented"
  },
  {
    "objectID": "simulation_diagnostics.html#technical-notes",
    "href": "simulation_diagnostics.html#technical-notes",
    "title": "Simulation Diagnostics",
    "section": "Technical Notes",
    "text": "Technical Notes\n\nGompertz Parameterization\nMultistateModels.jl uses the flexsurv Gompertz parameterization: - shape (\\(a\\)): Rate of hazard increase (can be negative for decreasing hazard) - rate (\\(b\\)): Initial hazard at \\(t=0\\)\nThis differs from some other parameterizations. The hazard is: \\[h(t) = b \\cdot e^{at}\\]\n\n\nSimulation Strategy\nThe diagnostics use CachedTransformStrategy() which caches inverse CDF computations for efficiency. The DirectTransformStrategy() computes inversions fresh each time. Both should produce identical results.\n\n\nMonte Carlo Error\nWith 40,000 samples, the expected maximum CDF error from Monte Carlo is approximately: \\[\\sqrt{\\frac{\\log(n)}{2n}} \\approx 0.007\\]\nSo maximum differences &lt; 0.02 are consistent with simulation being correct."
  }
]