---
title: "Performance Benchmarks"
subtitle: "Computational Performance and Scalability Tests"
format:
  html:
    toc: true
    toc-depth: 3
    toc-expand: 2
    code-fold: true
    code-summary: "Show code"
execute:
  echo: true
  warning: false
  freeze: auto
---

```{julia}
#| echo: false
#| output: false
using Pkg
Pkg.activate(joinpath(@__DIR__, ".."))
using MultistateModels
using DataFrames
using Random
using Statistics
using CairoMakie
using Printf
```

## Benchmark Results (2025-12-19)

**Note**: These results are generated from `MultistateModelsTests/benchmarks/run_benchmarks.jl`.

```{julia}
#| echo: false
using JSON3
using DataFrames

# Load benchmark results
results_path = joinpath(@__DIR__, "assets", "benchmarks", "results.json")
if isfile(results_path)
    json_data = JSON3.read(read(results_path, String))
    
    # Helper to convert JSON columns back to DataFrame
    function json_to_df(j)
        cols = j.columns
        names = Symbol.(j.colindex.names)
        df = DataFrame()
        for (i, name) in enumerate(names)
            df[!, name] = cols[i]
        end
        return df
    end

    scalability_df = json_to_df(json_data.scalability)
    squarem_df = json_to_df(json_data.squarem)
    threading_df = json_to_df(json_data.threading)
else
    println("⚠️ Benchmark results file not found at $results_path")
    scalability_df = DataFrame(N=[], Runtime=[])
    squarem_df = DataFrame(Method=[], Runtime=[])
    threading_df = DataFrame(Threads=[], Runtime=[])
end
```

## Scalability Analysis

### Sample Size Scaling

```{julia}
#| label: fig-scalability
#| fig-cap: "Runtime Scaling with Sample Size"
#| fig-height: 5

if !isempty(scalability_df)
    fig = Figure(size=(700, 400))
    
    ax = Axis(fig[1, 1],
        xlabel="Sample Size (n)",
        ylabel="Runtime (seconds)",
        title="Runtime Scaling",
        xscale=log10,
        yscale=log10,
        xticks=(scalability_df.N, string.(scalability_df.N)))
    
    scatter!(ax, scalability_df.N, scalability_df.Runtime, label="Panel (MCEM)", 
             markersize=12, color=:orange)
    lines!(ax, scalability_df.N, scalability_df.Runtime, color=:orange, linewidth=2)
    
    axislegend(ax, position=:lt)
    fig
else
    println("No scalability data available.")
end
```

## SQUAREM Acceleration

```{julia}
#| echo: false
if !isempty(squarem_df)
    println("SQUAREM Runtime (N=200): $(round(squarem_df.Runtime[1], digits=4)) seconds")
else
    println("No SQUAREM data available.")
end
```

## Threading Performance

```{julia}
#| echo: false
if !isempty(threading_df)
    println("Threading Runtime (Threads=$(threading_df.Threads[1])): $(round(threading_df.Runtime[1], digits=4)) seconds")
else
    println("No threading data available.")
end
```

## SIR Resampling

*Benchmark pending implementation.*

## Overview

This report provides performance benchmarks for MultistateModels.jl.

Future benchmarks will cover:

1. **SIR Resampling Methods**: Comparison of importance sampling strategies
2. **SQUAREM Acceleration**: EM vs accelerated EM convergence
3. **Scalability**: Performance across different sample sizes
4. **Threading**: Parallel likelihood computation scaling

## SIR Resampling

*Benchmark pending implementation.*

## Overview

This report provides performance benchmarks for MultistateModels.jl.

Future benchmarks will cover:

1. **SIR Resampling Methods**: Comparison of importance sampling strategies
2. **SQUAREM Acceleration**: EM vs accelerated EM convergence

**Standard EM**:
- Linear convergence rate
- Stable but slow
- Simple implementation

## SQUAREM Acceleration

```{julia}
#| echo: false
if !isempty(squarem_df)
    println("SQUAREM Runtime (N=200): $(round(squarem_df.Runtime[1], digits=4)) seconds")
else
    println("No SQUAREM data available.")
end
```

## Scalability Analysis

### Sample Size Scaling

```{julia}
#| label: fig-scalability
#| fig-cap: "Runtime Scaling with Sample Size"
#| fig-height: 5

if !isempty(scalability_df)
    fig = Figure(size=(700, 400))
    
    ax = Axis(fig[1, 1],
        xlabel="Sample Size (n)",
        ylabel="Runtime (seconds)",
        title="Runtime Scaling",
        xscale=log10,
        yscale=log10,
        xticks=(scalability_df.N, string.(scalability_df.N)))
    
    scatter!(ax, scalability_df.N, scalability_df.Runtime, label="Panel (MCEM)", 
             markersize=12, color=:orange)
    lines!(ax, scalability_df.N, scalability_df.Runtime, color=:orange, linewidth=2)
    
    axislegend(ax, position=:lt)
    fig
else
    println("No scalability data available.")
end
```

### Complexity Analysis

| Operation | Complexity | Notes |
|-----------|------------|-------|
| Exact likelihood | O(n) | Per-subject TPM computation |
| Panel likelihood | O(n × k) | k = paths per subject |
| Gradient computation | O(n × p) | p = number of parameters |
| MCEM per iteration | O(n × k × m) | m = MCEM paths |

## Threading Performance

```{julia}
#| echo: false
if !isempty(threading_df)
    println("Threading Runtime (Threads=$(threading_df.Threads[1])): $(round(threading_df.Runtime[1], digits=4)) seconds")
else
    println("No threading data available.")
end
```

### Threading Recommendations

```{julia}
#| echo: false
threading_rec = DataFrame(
    Scenario = [
        "Small dataset (n < 500)",
        "Medium dataset (n ~ 1000)",
        "Large dataset (n > 2000)",
        "MCEM with many paths"
    ],
    RecommendedThreads = [
        "1-2",
        "4",
        "8-16",
        "Match physical cores"
    ],
    Notes = [
        "Thread overhead dominates",
        "Good balance",
        "Near-linear scaling",
        "Memory bandwidth limit"
    ]
)

threading_rec
```

## Phase-Type Proposal Performance

*Benchmark pending implementation.*

## Benchmark Suite

> **Warning**: The scripts referenced below (`benchmarks/run_benchmarks.jl`, etc.) do not currently exist in the repository.

### Running Benchmarks

```bash
# Full benchmark suite
julia --project=MultistateModelsTests MultistateModelsTests/benchmarks/run_benchmarks.jl
```

### Benchmark Environment

```{julia}
#| code-fold: show
# System information for reproducibility
println("Julia version: ", VERSION)
println("Threads available: ", Threads.nthreads())
# println("Physical cores: ", MultistateModels.get_physical_cores())
```

## Summary

### Performance Highlights

1. **Exact data fitting**: Scales linearly with sample size
2. **Panel data (MCEM)**: ~5x slower than exact, but handles interval censoring
3. **SQUAREM**: 2-3x speedup over standard EM
4. **Threading**: Near-linear scaling up to 8 threads
5. **Phase-type proposals**: Critical for non-exponential hazards in MCEM

### Optimization Tips

1. **Use exact observations when available** - much faster than panel
2. **Enable SQUAREM** - default in `fit()`, significantly faster
3. **Match threads to physical cores** - avoid hyperthreading overhead
4. **Use phase-type proposals for semi-Markov** - automatic selection in `fit()`
5. **Profile before optimizing** - identify actual bottlenecks

### Memory Management

- Pre-allocate path storage for MCEM
- Use `CachedTransformStrategy()` for repeated simulations
- Consider batched processing for very large datasets
