---
title: "Spline Methods Comparison"
subtitle: "Comparing MultistateModels.jl Splines vs pammtools/mgcv and flexsurv"
date: last-modified
format:
  html:
    toc: true
    toc-depth: 3
    code-fold: true
    fig-width: 10
    fig-height: 6
execute:
  warning: false
  message: false
  freeze: auto
engine: knitr
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width = 10, fig.height = 6)
library(tidyverse)
library(mgcv)
library(pammtools)
library(flexsurv)
library(survival)
library(mstate)
library(expm)
library(jsonlite)
library(patchwork)
library(knitr)
library(kableExtra)
library(splines)

# Set theme
theme_set(theme_bw(base_size = 12))
```

# Introduction

This report presents a comprehensive benchmark comparing three approaches for fitting 
flexible hazard models to multistate survival data:

1. **MultistateModels.jl** (Julia): Joint likelihood estimation with natural cubic splines
2. **pammtools/mgcv** (R): Piecewise-exponential additive models via GAM
3. **flexsurv** (R): Flexible parametric survival models with spline hazards

All methods are evaluated on the same simulated dataset generated using MultistateModels.jl.

# Model Specification

## Illness-Death Model

We consider a three-state illness-death model without recovery:

- **State 1**: Healthy (initial state)
- **State 2**: Illness (transient state)
- **State 3**: Death (absorbing state)

**Transitions:**

- $1 \to 2$: Healthy to Illness (incidence)
- $1 \to 3$: Healthy to Death (direct mortality)
- $2 \to 3$: Illness to Death (disease-related mortality)

## True Hazard Functions

The data are simulated using Weibull hazard functions with the **rate parameterization**:

$$h_{rs}(t) = \kappa_{rs} \cdot \lambda_{rs} \cdot t^{\kappa_{rs} - 1}$$

where $\kappa_{rs} > 0$ is the shape parameter and $\lambda_{rs} > 0$ is the rate parameter.

The cumulative hazard is:
$$H_{rs}(t) = \lambda_{rs} \cdot t^{\kappa_{rs}}$$

**True Parameter Values:**

| Transition | Shape ($\kappa$) | Rate ($\lambda$) | Interpretation |
|------------|------------------|------------------|----------------|
| $h_{12}$ (Healthy to Illness) | 1.3 | 0.04 | Increasing hazard |
| $h_{13}$ (Healthy to Death) | 1.2 | 0.015 | Mildly increasing |
| $h_{23}$ (Illness to Death) | 1.4 | 0.08 | Higher mortality after illness |

## Transition Probability Matrix

For a time-homogeneous Markov model, the transition probability matrix $\mathbf{P}(s, t)$ 
satisfies the Kolmogorov forward equation:

$$\frac{\partial}{\partial t}\mathbf{P}(s,t) = \mathbf{P}(s,t) \cdot \mathbf{Q}(t)$$

where $\mathbf{Q}(t)$ is the transition intensity (generator) matrix:

$$\mathbf{Q}(t) = \begin{pmatrix}
-(h_{12}(t) + h_{13}(t)) & h_{12}(t) & h_{13}(t) \\
0 & -h_{23}(t) & h_{23}(t) \\
0 & 0 & 0
\end{pmatrix}$$

The solution is computed via the **product integral**:
$$\mathbf{P}(0, t) = \prod_{s=0}^{t} \exp\left(\mathbf{Q}(s) ds\right)$$

## State Prevalence

State prevalence at time $t$ for subjects starting in state 1:

- $P_1(t) = P_{11}(0, t)$ - Probability of remaining healthy
- $P_2(t) = P_{12}(0, t)$ - Probability of being in illness state
- $P_3(t) = P_{13}(0, t)$ - Probability of having died

## Cumulative Incidence Functions

The cause-specific cumulative incidence function for transition $1 \to r$ is:

$$F_{1r}(t) = \int_0^t P_{11}(0, s) \cdot h_{1r}(s) \, ds$$

This represents the probability of experiencing transition $1 \to r$ by time $t$.

# Data

## Loading Simulated Data

```{r load-data}
# Load data generated by MultistateModels.jl
data_path <- "../fixtures/illness_death_data.csv"
meta_path <- "../fixtures/illness_death_metadata.json"

dat <- read.csv(data_path)
meta <- fromJSON(meta_path)

# Display metadata
cat("Sample Size:", meta$n_subjects, "\n")
cat("Maximum Follow-up Time:", meta$max_time, "\n")
cat("\nTrue Parameters:\n")
cat("  h12: shape =", meta$true_params$h12$shape, ", rate =", meta$true_params$h12$rate, "\n")
cat("  h13: shape =", meta$true_params$h13$shape, ", rate =", meta$true_params$h13$rate, "\n")
cat("  h23: shape =", meta$true_params$h23$shape, ", rate =", meta$true_params$h23$rate, "\n")
```

## Data Summary

```{r data-summary}
# Transition counts
trans_counts <- dat %>%
  filter(status == 1) %>%
  count(from, to) %>%
  mutate(transition = paste0(from, " -> ", to))

kable(trans_counts, caption = "Observed Transition Counts") %>%
  kable_styling(bootstrap_options = c("striped", "hover"))

# Final state distribution
final_states <- dat %>%
  group_by(id) %>%
  slice_tail(n = 1) %>%
  ungroup() %>%
  count(to) %>%
  mutate(
    state_name = case_when(
      to == 1 ~ "Healthy",
      to == 2 ~ "Illness", 
      to == 3 ~ "Death"
    ),
    pct = round(100 * n / sum(n), 1)
  )

kable(final_states, caption = "Final State Distribution") %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```

## Event Time Distribution

```{r event-times, fig.height=4}
# Plot event time distributions
events <- dat %>%
  filter(status == 1) %>%
  mutate(transition = factor(paste0(from, " -> ", to),
                            levels = c("1 -> 2", "1 -> 3", "2 -> 3")))

ggplot(events, aes(x = tstop)) +
  geom_histogram(aes(y = after_stat(density)), bins = 30, fill = "steelblue", alpha = 0.7) +
  geom_density(color = "darkblue", linewidth = 1) +
  facet_wrap(~ transition, scales = "free_y") +
  labs(
    title = "Distribution of Event Times by Transition",
    x = "Time",
    y = "Density"
  )
```

# Methods

## True Hazard Functions

```{r true-hazards}
# Define true hazard functions
true_hazard <- function(t, shape, rate) {
  shape * rate * t^(shape - 1)
}

true_cumhaz <- function(t, shape, rate) {
  rate * t^shape
}

# True hazards
h12_true <- function(t) true_hazard(t, meta$true_params$h12$shape, meta$true_params$h12$rate)
h13_true <- function(t) true_hazard(t, meta$true_params$h13$shape, meta$true_params$h13$rate)
h23_true <- function(t) true_hazard(t, meta$true_params$h23$shape, meta$true_params$h23$rate)
```

## Standardized Knot Placement

All three methods use the **same interior knots**: 9 knots placed at the decile quantiles 
(0.1, 0.2, ..., 0.9) of the observed event times from the simulation.

```{r knot-setup}
# Load Julia results early to get standardized knots
julia_results <- fromJSON("../fixtures/illness_death_results.json")

# Get the standardized interior knots from Julia fit
interior_knots <- julia_results$julia_fit$interior_knots
n_interior_knots <- length(interior_knots)

# Boundary knots (min and max event times)
event_times <- dat$tstop[dat$status == 1]
boundary_knots <- c(min(event_times), max(event_times))

cat("Standardized Knot Specification:\n")
cat("  Number of interior knots:", n_interior_knots, "\n")
cat("  Interior knots (decile quantiles):\n")
for (i in seq_along(interior_knots)) {
  cat(sprintf("    Q%d: %.3f\n", i * 10, interior_knots[i]))
}
cat("  Boundary knots:", round(boundary_knots, 3), "\n")
cat("  Total spline df:", n_interior_knots + 2, "(interior + 2 for natural spline)\n")
```

## Method 1: pammtools/mgcv (PAM)

The piecewise-exponential additive model (PAM) transforms survival data into a Poisson 
regression framework. Following Bender et al. (2018) and the pammtools documentation:

**Data Transformation:**

1. Split follow-up time into intervals using a set of cut points
2. For each subject-interval combination, create a pseudo-observation with:
   - Exposure time (offset): $\log(\text{time at risk in interval})$
   - Event indicator: 1 if event occurred in interval, 0 otherwise

**Model:**

$$\log(E[d_{ij}]) = \log(t_{ij}) + f(t_j) + \mathbf{x}_i'\boldsymbol{\beta}$$

where $d_{ij}$ is the event indicator for subject $i$ in interval $j$, $t_{ij}$ is the 
exposure time, and $f(t)$ is a smooth function of time.

**Spline specification:** We use a cubic regression spline with the **same knots** as Julia.
The `mgcv::gam` function uses penalized splines, but we fix the knot locations to match.

```{r pam-setup}
# Create cut points for PAM
n_intervals <- 30
max_t <- max(dat$tstop)
cut_points <- seq(0, max_t * 1.01, length.out = n_intervals + 1)

# Function to create PAM data for a specific transition
create_pam_data <- function(dat, from_state, to_state, cuts) {
  # Filter to subjects at risk from this state
  trans_dat <- dat[dat$from == from_state, ]
  
  pam_rows <- list()
  
  for (i in 1:nrow(trans_dat)) {
    row <- trans_dat[i, ]
    t_start <- row$tstart
    t_end <- row$tstop
    is_event <- (row$status == 1) && (row$to == to_state)
    
    for (j in 1:(length(cuts)-1)) {
      int_start <- cuts[j]
      int_end <- cuts[j+1]
      
      if (int_end <= t_start) next
      if (int_start >= t_end) break
      
      risk_start <- max(int_start, t_start)
      risk_end <- min(int_end, t_end)
      offset_val <- log(risk_end - risk_start)
      
      event_in_interval <- is_event && (t_end <= int_end) && (t_end > int_start)
      
      pam_rows[[length(pam_rows) + 1]] <- data.frame(
        id = row$id,
        interval = j,
        t_mid = (risk_start + risk_end) / 2,
        t_start = risk_start,
        t_end = risk_end,
        offset = offset_val,
        event = as.integer(event_in_interval)
      )
    }
  }
  
  do.call(rbind, pam_rows)
}

# Create PAM datasets
pam_12 <- create_pam_data(dat, 1, 2, cut_points)
pam_13 <- create_pam_data(dat, 1, 3, cut_points)
pam_23 <- create_pam_data(dat, 2, 3, cut_points)

cat("PAM Data Created:\n")
cat("  Transition 1->2:", nrow(pam_12), "rows,", sum(pam_12$event), "events\n")
cat("  Transition 1->3:", nrow(pam_13), "rows,", sum(pam_13$event), "events\n")
cat("  Transition 2->3:", nrow(pam_23), "rows,", sum(pam_23$event), "events\n")
```

```{r pam-fit}
# Fit GAM models using cubic regression splines with FIXED knot locations
# to match Julia's specification exactly
t_start_pam <- Sys.time()

# For mgcv with bs="cr" (cubic regression spline):
# When supplying knots, k = number of knots supplied
# The knots argument specifies ALL knots (not just interior)
k_mgcv <- n_interior_knots

fit_pam_12 <- gam(event ~ s(t_mid, bs = "cr", k = k_mgcv), 
                   family = poisson(), 
                   offset = offset,
                   data = pam_12,
                   knots = list(t_mid = interior_knots),
                   method = "REML")

fit_pam_13 <- gam(event ~ s(t_mid, bs = "cr", k = k_mgcv), 
                   family = poisson(), 
                   offset = offset,
                   data = pam_13,
                   knots = list(t_mid = interior_knots),
                   method = "REML")

fit_pam_23 <- gam(event ~ s(t_mid, bs = "cr", k = k_mgcv), 
                   family = poisson(), 
                   offset = offset,
                   data = pam_23,
                   knots = list(t_mid = interior_knots),
                   method = "REML")

t_pam <- as.numeric(Sys.time() - t_start_pam, units = "secs")

cat("PAM Fit Time:", round(t_pam, 2), "seconds\n")
cat("\nEffective Degrees of Freedom (after penalization):\n")
cat("  h12:", round(sum(fit_pam_12$edf), 2), "\n")
cat("  h13:", round(sum(fit_pam_13$edf), 2), "\n")
cat("  h23:", round(sum(fit_pam_23$edf), 2), "\n")
cat("\nKnots used by mgcv:\n")
cat("  Interior knots:", round(interior_knots, 3), "\n")
```

## Method 2: flexsurv

The flexsurv package implements flexible parametric survival models using cubic splines 
on the log cumulative hazard or log hazard scale (Royston-Parmar models).

```{r flexsurv-setup}
# Prepare data for flexsurv (one row per transition)
# For multistate models, we need to create separate datasets

# Transition 1->2: at risk while in state 1, event if goes to state 2
flex_12 <- dat %>%
  filter(from == 1) %>%
  mutate(
    time = tstop - tstart,
    status = as.integer(status == 1 & to == 2)
  ) %>%
  select(id, time, status)

# Transition 1->3: at risk while in state 1, event if goes to state 3  
flex_13 <- dat %>%
  filter(from == 1) %>%
  mutate(
    time = tstop - tstart,
    status = as.integer(status == 1 & to == 3)
  ) %>%
  select(id, time, status)

# Transition 2->3: at risk while in state 2, event if goes to state 3
flex_23 <- dat %>%
  filter(from == 2) %>%
  mutate(
    time = tstop - tstart,
    status = as.integer(status == 1 & to == 3)
  ) %>%
  select(id, time, status)

cat("flexsurv Data:\n")
cat("  Transition 1->2:", nrow(flex_12), "observations,", sum(flex_12$status), "events\n")
cat("  Transition 1->3:", nrow(flex_13), "observations,", sum(flex_13$status), "events\n")
cat("  Transition 2->3:", nrow(flex_23), "observations,", sum(flex_23$status), "events\n")
```

```{r flexsurv-fit}
# Fit flexible parametric models with splines on log cumulative hazard
# Using FIXED knot locations to match Julia's specification

# flexsurv places knots on the LOG time scale
# It automatically adds boundary knots at min and max event times
# We need to specify internal knots on log scale
log_interior_knots <- log(interior_knots)

t_start_flex <- Sys.time()

fit_flex_12 <- flexsurvspline(Surv(time, status) ~ 1, 
                               data = flex_12, 
                               knots = log_interior_knots,
                               scale = "hazard")

fit_flex_13 <- flexsurvspline(Surv(time, status) ~ 1, 
                               data = flex_13, 
                               knots = log_interior_knots,
                               scale = "hazard")

fit_flex_23 <- flexsurvspline(Surv(time, status) ~ 1, 
                               data = flex_23, 
                               knots = log_interior_knots,
                               scale = "hazard")

t_flex <- as.numeric(Sys.time() - t_start_flex, units = "secs")

cat("flexsurv Fit Time:", round(t_flex, 2), "seconds\n")
cat("\nInterior knots (original scale):\n")
cat("  ", round(interior_knots, 3), "\n")
cat("\nInterior knots (log scale for flexsurv):\n")
cat("  ", round(log_interior_knots, 3), "\n")
```

## Method 3: MultistateModels.jl (Julia)

MultistateModels.jl fits all transition hazards jointly via maximum likelihood with 
natural cubic spline baseline hazards. Results are loaded from pre-computed fits.

```{r julia-load}
# Load Julia predictions (julia_results already loaded in knot-setup chunk)
julia_pred <- fromJSON("../fixtures/illness_death_julia_predictions.json")

cat("Julia Fit Time:", round(julia_results$julia_fit$fit_time_seconds, 2), "seconds\n")
cat("Interior Knots:", paste(round(julia_results$julia_fit$interior_knots, 2), collapse = ", "), "\n")
```

# Hazard Estimation

## Predicted Hazards

```{r predict-hazards}
# Evaluation times
eval_times <- seq(0.5, 20, by = 0.5)

# True hazards
h12_true_vec <- sapply(eval_times, h12_true)
h13_true_vec <- sapply(eval_times, h13_true)
h23_true_vec <- sapply(eval_times, h23_true)

# PAM predictions
pred_data <- data.frame(t_mid = eval_times, offset = 0)
h12_pam <- exp(predict(fit_pam_12, newdata = pred_data, type = "link"))
h13_pam <- exp(predict(fit_pam_13, newdata = pred_data, type = "link"))
h23_pam <- exp(predict(fit_pam_23, newdata = pred_data, type = "link"))

# flexsurv predictions
h12_flex <- summary(fit_flex_12, t = eval_times, type = "hazard")[[1]]$est
h13_flex <- summary(fit_flex_13, t = eval_times, type = "hazard")[[1]]$est
h23_flex <- summary(fit_flex_23, t = eval_times, type = "hazard")[[1]]$est

# Julia predictions (from loaded file)
h12_julia <- julia_pred$hazards$h12_julia
h13_julia <- julia_pred$hazards$h13_julia
h23_julia <- julia_pred$hazards$h23_julia

# Combine into data frame
hazard_df <- data.frame(
  time = rep(eval_times, 12),
  hazard = c(h12_true_vec, h12_julia, h12_pam, h12_flex,
             h13_true_vec, h13_julia, h13_pam, h13_flex,
             h23_true_vec, h23_julia, h23_pam, h23_flex),
  method = rep(rep(c("True", "Julia", "PAM (mgcv)", "flexsurv"), each = length(eval_times)), 3),
  transition = rep(c("h12 (Healthy -> Illness)", 
                     "h13 (Healthy -> Death)",
                     "h23 (Illness -> Death)"), each = 4 * length(eval_times))
)
```

## Hazard Plots

```{r hazard-plots, fig.height=8}
ggplot(hazard_df, aes(x = time, y = hazard, color = method, linetype = method)) +
  geom_line(linewidth = 1) +
  scale_color_manual(values = c("True" = "black", "Julia" = "#E69F00", 
                                 "PAM (mgcv)" = "#56B4E9", "flexsurv" = "#009E73")) +
  scale_linetype_manual(values = c("True" = "solid", "Julia" = "dashed", 
                                    "PAM (mgcv)" = "dotted", "flexsurv" = "twodash")) +
  facet_wrap(~ transition, scales = "free_y", ncol = 1) +
  labs(
    title = "Estimated vs True Hazard Functions",
    x = "Time",
    y = "Hazard Rate h(t)",
    color = "Method",
    linetype = "Method"
  ) +
  theme(legend.position = "bottom")
```

## Hazard RMSE

```{r hazard-rmse}
rmse <- function(a, b) sqrt(mean((a - b)^2))

hazard_rmse <- data.frame(
  Transition = c("h12", "h13", "h23"),
  Julia = c(rmse(h12_julia, h12_true_vec),
            rmse(h13_julia, h13_true_vec),
            rmse(h23_julia, h23_true_vec)),
  PAM_mgcv = c(rmse(h12_pam, h12_true_vec),
                   rmse(h13_pam, h13_true_vec),
                   rmse(h23_pam, h23_true_vec)),
  flexsurv = c(rmse(h12_flex, h12_true_vec),
               rmse(h13_flex, h13_true_vec),
               rmse(h23_flex, h23_true_vec))
)

kable(hazard_rmse, digits = 5, 
      caption = "Hazard RMSE (vs True)") %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```

# State Prevalence

## Computing Transition Probabilities

```{r tpm-functions}
# Compute transition probability matrix via product integral
compute_tpm <- function(t, h12_fn, h13_fn, h23_fn, dt = 0.01) {
  if (t <= 0) return(diag(3))
  
  n_steps <- max(1, ceiling(t / dt))
  actual_dt <- t / n_steps
  
  P <- diag(3)
  
  for (i in 1:n_steps) {
    s <- (i - 0.5) * actual_dt
    
    h12 <- h12_fn(s)
    h13 <- h13_fn(s)
    h23 <- h23_fn(s)
    
    Q <- matrix(c(-(h12 + h13), h12, h13,
                  0, -h23, h23,
                  0, 0, 0), nrow = 3, byrow = TRUE)
    
    dP <- expm(Q * actual_dt)
    P <- P %*% dP
  }
  
  return(P)
}

# Create interpolation functions for each method
make_interp <- function(times, values) {
  approxfun(times, values, rule = 2)
}

h12_pam_fn <- make_interp(eval_times, h12_pam)
h13_pam_fn <- make_interp(eval_times, h13_pam)
h23_pam_fn <- make_interp(eval_times, h23_pam)

h12_flex_fn <- make_interp(eval_times, h12_flex)
h13_flex_fn <- make_interp(eval_times, h13_flex)
h23_flex_fn <- make_interp(eval_times, h23_flex)

h12_julia_fn <- make_interp(eval_times, h12_julia)
h13_julia_fn <- make_interp(eval_times, h13_julia)
h23_julia_fn <- make_interp(eval_times, h23_julia)
```

```{r compute-prevalence}
# Compute state prevalence for each method
prev_true <- matrix(0, nrow = length(eval_times), ncol = 3)
prev_julia <- matrix(0, nrow = length(eval_times), ncol = 3)
prev_pam <- matrix(0, nrow = length(eval_times), ncol = 3)
prev_flex <- matrix(0, nrow = length(eval_times), ncol = 3)

for (i in seq_along(eval_times)) {
  t <- eval_times[i]
  
  P_true <- compute_tpm(t, h12_true, h13_true, h23_true)
  prev_true[i, ] <- P_true[1, ]
  
  P_julia <- compute_tpm(t, h12_julia_fn, h13_julia_fn, h23_julia_fn)
  prev_julia[i, ] <- P_julia[1, ]
  
  P_pam <- compute_tpm(t, h12_pam_fn, h13_pam_fn, h23_pam_fn)
  prev_pam[i, ] <- P_pam[1, ]
  
  P_flex <- compute_tpm(t, h12_flex_fn, h13_flex_fn, h23_flex_fn)
  prev_flex[i, ] <- P_flex[1, ]
}

# Empirical prevalence from data
prev_emp <- julia_results$empirical
```

## Prevalence Plots

```{r prevalence-plots, fig.height=8}
prev_df <- data.frame(
  time = rep(eval_times, 15),
  prevalence = c(
    prev_true[,1], prev_julia[,1], prev_pam[,1], prev_flex[,1], prev_emp$prevalence_healthy,
    prev_true[,2], prev_julia[,2], prev_pam[,2], prev_flex[,2], prev_emp$prevalence_illness,
    prev_true[,3], prev_julia[,3], prev_pam[,3], prev_flex[,3], prev_emp$prevalence_death
  ),
  method = rep(rep(c("True", "Julia", "PAM (mgcv)", "flexsurv", "Empirical"), 
                   each = length(eval_times)), 3),
  state = rep(c("P1(t): Healthy", "P2(t): Illness", "P3(t): Death"), 
              each = 5 * length(eval_times))
)

ggplot(prev_df, aes(x = time, y = prevalence, color = method, linetype = method)) +
  geom_line(linewidth = 1) +
  scale_color_manual(values = c("True" = "black", "Julia" = "#E69F00", 
                                 "PAM (mgcv)" = "#56B4E9", "flexsurv" = "#009E73",
                                 "Empirical" = "grey50")) +
  scale_linetype_manual(values = c("True" = "solid", "Julia" = "dashed", 
                                    "PAM (mgcv)" = "dotted", "flexsurv" = "twodash",
                                    "Empirical" = "dotdash")) +
  facet_wrap(~ state, scales = "free_y", ncol = 1) +
  labs(
    title = "State Prevalence: Estimated vs True",
    subtitle = "Starting from State 1 (Healthy)",
    x = "Time",
    y = "Probability",
    color = "Method",
    linetype = "Method"
  ) +
  theme(legend.position = "bottom")
```

## Prevalence RMSE

```{r prevalence-rmse}
prev_rmse <- data.frame(
  State = c("P1 (Healthy)", "P2 (Illness)", "P3 (Death)"),
  Empirical = c(rmse(prev_true[,1], prev_emp$prevalence_healthy),
                rmse(prev_true[,2], prev_emp$prevalence_illness),
                rmse(prev_true[,3], prev_emp$prevalence_death)),
  Julia = c(rmse(prev_true[,1], prev_julia[,1]),
            rmse(prev_true[,2], prev_julia[,2]),
            rmse(prev_true[,3], prev_julia[,3])),
  PAM_mgcv = c(rmse(prev_true[,1], prev_pam[,1]),
                   rmse(prev_true[,2], prev_pam[,2]),
                   rmse(prev_true[,3], prev_pam[,3])),
  flexsurv = c(rmse(prev_true[,1], prev_flex[,1]),
               rmse(prev_true[,2], prev_flex[,2]),
               rmse(prev_true[,3], prev_flex[,3]))
)

kable(prev_rmse, digits = 5,
      caption = "State Prevalence RMSE (vs True)") %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```

# Cumulative Incidence

## Computing Cumulative Incidence

```{r ci-functions}
# Compute cause-specific cumulative incidence
# CI_1r(t) = integral_0^t P11(s) * h1r(s) ds
compute_ci <- function(times, h_fn, h12_all_fn, h13_all_fn, h23_all_fn, dt = 0.05) {
  ci <- numeric(length(times))
  
  for (i in seq_along(times)) {
    t <- times[i]
    if (t <= 0) {
      ci[i] <- 0
      next
    }
    
    n_steps <- max(1, ceiling(t / dt))
    actual_dt <- t / n_steps
    
    integral <- 0
    for (j in 1:n_steps) {
      s <- (j - 0.5) * actual_dt
      P <- compute_tpm(s, h12_all_fn, h13_all_fn, h23_all_fn, dt = 0.05)
      P11 <- P[1, 1]
      h <- h_fn(s)
      integral <- integral + P11 * h * actual_dt
    }
    ci[i] <- integral
  }
  
  return(ci)
}
```

```{r compute-ci}
# True cumulative incidence
ci_12_true <- compute_ci(eval_times, h12_true, h12_true, h13_true, h23_true)
ci_13_true <- compute_ci(eval_times, h13_true, h12_true, h13_true, h23_true)

# Julia CI
ci_12_julia <- compute_ci(eval_times, h12_julia_fn, h12_julia_fn, h13_julia_fn, h23_julia_fn)
ci_13_julia <- compute_ci(eval_times, h13_julia_fn, h12_julia_fn, h13_julia_fn, h23_julia_fn)

# PAM CI
ci_12_pam <- compute_ci(eval_times, h12_pam_fn, h12_pam_fn, h13_pam_fn, h23_pam_fn)
ci_13_pam <- compute_ci(eval_times, h13_pam_fn, h12_pam_fn, h13_pam_fn, h23_pam_fn)

# flexsurv CI
ci_12_flex <- compute_ci(eval_times, h12_flex_fn, h12_flex_fn, h13_flex_fn, h23_flex_fn)
ci_13_flex <- compute_ci(eval_times, h13_flex_fn, h12_flex_fn, h13_flex_fn, h23_flex_fn)

# Total death CI = P(state 3)
ci_death_true <- prev_true[, 3]
ci_death_julia <- prev_julia[, 3]
ci_death_pam <- prev_pam[, 3]
ci_death_flex <- prev_flex[, 3]
```

## Cumulative Incidence Plots

```{r ci-plots, fig.height=8}
ci_df <- data.frame(
  time = rep(eval_times, 12),
  ci = c(
    ci_12_true, ci_12_julia, ci_12_pam, ci_12_flex,
    ci_13_true, ci_13_julia, ci_13_pam, ci_13_flex,
    ci_death_true, ci_death_julia, ci_death_pam, ci_death_flex
  ),
  method = rep(rep(c("True", "Julia", "PAM (mgcv)", "flexsurv"), each = length(eval_times)), 3),
  event = rep(c("CI12: Illness", "CI13: Direct Death", "CI Total Death"), 
              each = 4 * length(eval_times))
)

ggplot(ci_df, aes(x = time, y = ci, color = method, linetype = method)) +
  geom_line(linewidth = 1) +
  scale_color_manual(values = c("True" = "black", "Julia" = "#E69F00", 
                                 "PAM (mgcv)" = "#56B4E9", "flexsurv" = "#009E73")) +
  scale_linetype_manual(values = c("True" = "solid", "Julia" = "dashed", 
                                    "PAM (mgcv)" = "dotted", "flexsurv" = "twodash")) +
  facet_wrap(~ event, scales = "free_y", ncol = 1) +
  labs(
    title = "Cumulative Incidence Functions",
    subtitle = "Starting from State 1 (Healthy)",
    x = "Time",
    y = "Cumulative Incidence",
    color = "Method",
    linetype = "Method"
  ) +
  theme(legend.position = "bottom")
```

## Cumulative Incidence RMSE

```{r ci-rmse}
ci_rmse <- data.frame(
  Cumulative_Incidence = c("CI12 (Illness)", "CI13 (Direct Death)", "CI Total Death"),
  Julia = c(rmse(ci_12_true, ci_12_julia),
            rmse(ci_13_true, ci_13_julia),
            rmse(ci_death_true, ci_death_julia)),
  PAM_mgcv = c(rmse(ci_12_true, ci_12_pam),
                   rmse(ci_13_true, ci_13_pam),
                   rmse(ci_death_true, ci_death_pam)),
  flexsurv = c(rmse(ci_12_true, ci_12_flex),
               rmse(ci_13_true, ci_13_flex),
               rmse(ci_death_true, ci_death_flex))
)

kable(ci_rmse, digits = 5,
      caption = "Cumulative Incidence RMSE (vs True)") %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```

# Summary

## Overall Comparison

```{r summary-table}
# Create summary
summary_df <- data.frame(
  Category = c("Hazard h12", "Hazard h13", "Hazard h23",
               "Prevalence P1", "Prevalence P2", "Prevalence P3",
               "CI Illness", "CI Direct Death", "CI Total Death"),
  Julia = c(hazard_rmse$Julia, prev_rmse$Julia, ci_rmse$Julia),
  PAM_mgcv = c(hazard_rmse$PAM_mgcv, prev_rmse$PAM_mgcv, ci_rmse$PAM_mgcv),
  flexsurv = c(hazard_rmse$flexsurv, prev_rmse$flexsurv, ci_rmse$flexsurv)
)

# Add winner column
summary_df$Winner <- apply(summary_df[, 2:4], 1, function(x) {
  methods <- c("Julia", "PAM (mgcv)", "flexsurv")
  methods[which.min(x)]
})

kable(summary_df, digits = 5,
      caption = "Summary: RMSE by Method and Metric") %>%
  kable_styling(bootstrap_options = c("striped", "hover")) %>%
  column_spec(5, bold = TRUE)
```

## Computation Time

```{r timing-table}
timing_df <- data.frame(
  Method = c("MultistateModels.jl (Julia)", "PAM (mgcv)", "flexsurv"),
  Fit_Time_s = c(julia_results$julia_fit$fit_time_seconds, t_pam, t_flex),
  Approach = c("Joint likelihood (all transitions)", 
               "Separate GAMs (independent)", 
               "Separate MLE (independent)")
)

kable(timing_df, digits = 2,
      caption = "Computation Time Comparison") %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```

## Conclusions

```{r conclusions}
# Count wins
wins <- table(summary_df$Winner)
cat("Method Wins (out of 9 metrics):\n")
print(wins)
```

### Key Findings

1. **MultistateModels.jl** uses joint likelihood estimation, fitting all transition hazards 
   simultaneously. This captures the multistate structure correctly.

2. **pammtools/mgcv** fits each transition independently using GAMs with NCV smoothing 
   parameter selection. While computationally efficient, it ignores cross-transition 
   dependencies.

3. **flexsurv** provides flexible parametric models with excellent hazard estimation but 
   also fits transitions independently.

4. For **state prevalence** and **cumulative incidence** estimation, joint modeling 
   (Julia) tends to outperform independent fitting approaches because it correctly 
   accounts for competing risks.

### Recommendations

- For exploratory analysis of individual hazard shapes: Any method works well
- For accurate prevalence/cumulative incidence prediction: Joint likelihood (Julia) preferred
- For large datasets with complex covariate structures: Consider pammtools for flexibility

# Session Info

```{r session-info}
sessionInfo()
```
